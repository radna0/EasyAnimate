[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  interpolate (/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py:4594)
  _get_pos_embed (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py:157)
  forward (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py:170)
  _call_impl (/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747)
  _wrapped_call_impl (/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736)
  forward (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py:410)
  _call_impl (/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747)
  _wrapped_call_impl (/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736)
  extract_feature (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:218)
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:396)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (870300dd4bb98225bdd68a4c6c49b085)

## BEGIN_GRAPH
HloModule IrToHlo.9, entry_computation_layout={(bf16[1,1025,1024]{2,1,0})->(f32[1,1024,32,32]{1,3,2,0})}

ENTRY %IrToHlo.9 (p0.1: bf16[1,1025,1024]) -> (f32[1,1024,32,32]) {
  %p0.1 = bf16[1,1025,1024]{2,1,0} parameter(0), sharding={devices=[1,8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %slice.2 = bf16[1,1025,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %p0.1), slice={[0:1], [0:1025], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=170}
  %slice.3 = bf16[1,1024,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %slice.2), slice={[0:1], [1:1025], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=170}
  %slice.4 = bf16[1,1024,1024]{2,1,0} slice(bf16[1,1024,1024]{2,1,0} %slice.3), slice={[0:1], [0:1024], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=170}
  %convert.5 = f32[1,1024,1024]{2,1,0} convert(bf16[1,1024,1024]{2,1,0} %slice.4), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=155}
  %reshape.6 = f32[1,32,32,1024]{3,2,1,0} reshape(f32[1,1024,1024]{2,1,0} %convert.5), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=155}
  %transpose.7 = f32[1,1024,32,32]{1,3,2,0} transpose(f32[1,32,32,1024]{3,2,1,0} %reshape.6), dimensions={0,3,1,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=156}
  ROOT %tuple.8 = (f32[1,1024,32,32]{1,3,2,0}) tuple(f32[1,1024,32,32]{1,3,2,0} %transpose.7)
}


Graph Hash: 34df536d76032c477f71bf50c9ec64af

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

f32[1,1024,32,32] {devices=[1,1,8,1]0,1,2,3,4,5,6,7}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:403)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (32a88e63cf34a3d4b5d82287f1100455)

## BEGIN_GRAPH
HloModule IrToHlo.17, entry_computation_layout={(s64[], s64[1,310]{1,0})->(pred[])}

%AddComputation.10 (x.11: s64[], y.12: s64[]) -> s64[] {
  %x.11 = s64[] parameter(0)
  %y.12 = s64[] parameter(1)
  ROOT %add.13 = s64[] add(s64[] %x.11, s64[] %y.12)
}

ENTRY %IrToHlo.17 (p0.2: s64[], p1.3: s64[1,310]) -> (pred[]) {
  %constant.9 = s32[] constant(310), metadata={op_type="aten__sum" op_name="aten__sum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  %p1.3 = s64[1,310]{1,0} parameter(1), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %reshape.4 = s64[310]{0} reshape(s64[1,310]{1,0} %p1.3), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=401}
  %p0.2 = s64[] parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  %broadcast.5 = s64[310]{0} broadcast(s64[] %p0.2), dimensions={}, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  %compare.6 = pred[310]{0} compare(s64[310]{0} %reshape.4, s64[310]{0} %broadcast.5), direction=EQ, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  %convert.7 = s64[310]{0} convert(pred[310]{0} %compare.6), metadata={op_type="aten__sum" op_name="aten__sum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  %constant.8 = s64[] constant(0), metadata={op_type="aten__sum" op_name="aten__sum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  %reduce.14 = s64[] reduce(s64[310]{0} %convert.7, s64[] %constant.8), dimensions={0}, to_apply=%AddComputation.10, metadata={op_type="aten__sum" op_name="aten__sum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  %constant.1 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  %compare.15 = pred[] compare(s64[] %reduce.14, s64[] %constant.1), direction=NE, metadata={op_type="aten__ne" op_name="aten__ne" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=403}
  ROOT %tuple.16 = (pred[]) tuple(pred[] %compare.15)
}


Graph Hash: bdcbbc31de1dafa4069bb99f26aad236

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

pred[] {replicated}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:404)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (efa30a1bdff2a01c8ac9b6c875e55e4f)

## BEGIN_GRAPH
HloModule IrToHlo.7, entry_computation_layout={(s64[], s64[1,310]{1,0})->(pred[310]{0})}

ENTRY %IrToHlo.7 (p0.1: s64[], p1.2: s64[1,310]) -> (pred[310]) {
  %p1.2 = s64[1,310]{1,0} parameter(1), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %reshape.3 = s64[310]{0} reshape(s64[1,310]{1,0} %p1.2), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=401}
  %p0.1 = s64[] parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  %broadcast.4 = s64[310]{0} broadcast(s64[] %p0.1), dimensions={}, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  %compare.5 = pred[310]{0} compare(s64[310]{0} %reshape.3, s64[310]{0} %broadcast.4), direction=EQ, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=402}
  ROOT %tuple.6 = (pred[310]{0}) tuple(pred[310]{0} %compare.5)
}


Graph Hash: af767894ff2a0d067f27b81ef6c4c6f5

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

pred[310] {replicated}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  isin_mps_friendly (/home/kojoe/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py:328)
  _prepare_special_tokens (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1658)
  generate (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1809)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:410)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (17fee3211ccd47407da74dac3217b467)

## BEGIN_GRAPH
HloModule IrToHlo.4, entry_computation_layout={(s64[])->(s64[1]{0})}

ENTRY %IrToHlo.4 (p0.1: s64[]) -> (s64[1]) {
  %p0.1 = s64[] parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1638}
  %reshape.2 = s64[1]{0} reshape(s64[] %p0.1), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1638}
  ROOT %tuple.3 = (s64[1]{0}) tuple(s64[1]{0} %reshape.2)
}


Graph Hash: 4a783c9c5bd9d987a5c0fcb220cc13b8

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

s64[1] {replicated}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  _prepare_special_tokens (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1657)
  generate (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1809)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:410)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (6e8af65a7050e1f8047c8ac0d130369f)

## BEGIN_GRAPH
HloModule IrToHlo.17, entry_computation_layout={(pred[1]{0})->(pred[])}

%AnyComputation.4 (x.5: pred[], y.6: pred[]) -> pred[] {
  %x.5 = pred[] parameter(0)
  %constant.7 = pred[] constant(false)
  %compare.10 = pred[] compare(pred[] %x.5, pred[] %constant.7), direction=NE
  %y.6 = pred[] parameter(1)
  %compare.9 = pred[] compare(pred[] %y.6, pred[] %constant.7), direction=NE
  %or.11 = pred[] or(pred[] %compare.10, pred[] %compare.9)
  %constant.8 = pred[] constant(true)
  ROOT %select.12 = pred[] select(pred[] %or.11, pred[] %constant.8, pred[] %constant.7)
}

ENTRY %IrToHlo.17 (p0.1: pred[1]) -> (pred[]) {
  %constant.2 = s32[] constant(1), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  %p0.1 = pred[1]{0} parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  %constant.3 = pred[] constant(false), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  %reduce.13 = pred[] reduce(pred[1]{0} %p0.1, pred[] %constant.3), dimensions={0}, to_apply=%AnyComputation.4, metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  %constant.14 = pred[] constant(false), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  %compare.15 = pred[] compare(pred[] %reduce.13, pred[] %constant.14), direction=NE, metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1658}
  ROOT %tuple.16 = (pred[]) tuple(pred[] %compare.15)
}


Graph Hash: 51c42aae7524c27f67412a7fc449ff0d

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

pred[] {replicated}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  _prepare_special_tokens (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1666)
  generate (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:1809)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:410)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (f217dda3bb384b8866dea60c446bdcb3)

## BEGIN_GRAPH
HloModule IrToHlo.20, entry_computation_layout={(s64[1]{0})->(pred[])}

%AnyComputation.7 (x.8: pred[], y.9: pred[]) -> pred[] {
  %x.8 = pred[] parameter(0)
  %constant.10 = pred[] constant(false)
  %compare.13 = pred[] compare(pred[] %x.8, pred[] %constant.10), direction=NE
  %y.9 = pred[] parameter(1)
  %compare.12 = pred[] compare(pred[] %y.9, pred[] %constant.10), direction=NE
  %or.14 = pred[] or(pred[] %compare.13, pred[] %compare.12)
  %constant.11 = pred[] constant(true)
  ROOT %select.15 = pred[] select(pred[] %or.14, pred[] %constant.11, pred[] %constant.10)
}

ENTRY %IrToHlo.20 (p0.2: s64[1]) -> (pred[]) {
  %constant.5 = s32[] constant(1), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %p0.2 = s64[1]{0} parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %constant.1 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %broadcast.3 = s64[1]{0} broadcast(s64[] %constant.1), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %compare.4 = pred[1]{0} compare(s64[1]{0} %p0.2, s64[1]{0} %broadcast.3), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %constant.6 = pred[] constant(false), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %reduce.16 = pred[] reduce(pred[1]{0} %compare.4, pred[] %constant.6), dimensions={0}, to_apply=%AnyComputation.7, metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %constant.17 = pred[] constant(false), metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  %compare.18 = pred[] compare(pred[] %reduce.16, pred[] %constant.17), direction=NE, metadata={op_type="aten__any" op_name="aten__any" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=1667}
  ROOT %tuple.19 = (pred[]) tuple(pred[] %compare.18)
}


Graph Hash: 9e8fabf1aa7a79580cfdd12ddf738d7

## END_GRAPH


#OUTPUT_SHARDING_BEGIN

pred[] {replicated}

#OUTPUT_SHARDING_END

[ScheduleSyncTensorsGraph]
TensorsGraphInfo:
  isin_mps_friendly (/home/kojoe/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py:328)
  __call__ (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py:466)
  __call__ (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py:475)
  _sample (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:3016)
  generate (/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py:2015)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  generate (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:410)
  decorate_context (/home/kojoe/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:116)
  chat (/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py:356)
  <module> (/home/kojoe/EasyAnimate/easyanimate/image_caption/template.py:131)

Root Hashes: (6600a75bb8b4ed107a43be5139cbae88)

## BEGIN_GRAPH
HloModule IrToHlo.13267, entry_computation_layout={(s64[], s64[], f64[], bf16[92553,4096]{1,0}, f32[], /*index=5*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=10*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=15*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=20*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=25*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=30*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=35*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=40*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=45*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=50*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=55*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=60*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=65*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=70*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=75*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=80*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=85*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=90*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=95*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=100*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=105*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=110*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, /*index=115*/bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, /*index=120*/bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, /*index=125*/bf16[4096,14336]{1,0}, bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096,14336]{1,0}, /*index=130*/bf16[14336,4096]{1,0}, bf16[4096,4096]{1,0}, bf16[6144,4096]{1,0}, bf16[4096]{0}, bf16[4096,4096]{1,0}, /*index=135*/bf16[4096]{0}, bf16[4096,4096]{1,0}, bf16[4096]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=140*/bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=145*/bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, /*index=150*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, /*index=155*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, /*index=160*/bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, /*index=165*/bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=170*/bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=175*/bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, /*index=180*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, /*index=185*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, /*index=190*/bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, /*index=195*/bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=200*/bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=205*/bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, /*index=210*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, /*index=215*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, /*index=220*/bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, /*index=225*/bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=230*/bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=235*/bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, /*index=240*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, /*index=245*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, /*index=250*/bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, /*index=255*/bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=260*/bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=265*/bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, /*index=270*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, /*index=275*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, /*index=280*/bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, /*index=285*/bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=290*/bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=295*/bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, /*index=300*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, /*index=305*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, /*index=310*/bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, /*index=315*/bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=320*/bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=325*/bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, /*index=330*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, /*index=335*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, /*index=340*/bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, /*index=345*/bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=350*/bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=355*/bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, /*index=360*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, /*index=365*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, /*index=370*/bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, /*index=375*/bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=380*/bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=385*/bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, /*index=390*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, /*index=395*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, /*index=400*/bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024,4096]{1,0}, /*index=405*/bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=410*/bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, bf16[1024]{0}, bf16[1024]{0}, /*index=415*/bf16[1024]{0}, bf16[1024,4096]{1,0}, bf16[4096]{0}, bf16[4096,1024]{1,0}, bf16[1024]{0}, /*index=420*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024,1024]{1,0}, bf16[3072]{0}, bf16[3072,1024]{1,0}, /*index=425*/bf16[1024]{0}, f32[1,1024,32,32]{1,3,2,0}, bf16[1,1025,1024]{2,1,0}, bf16[1024]{0}, bf16[1024,3,14,14]{0,3,2,1}, /*index=430*/bf16[1,3,448,448]{3,2,1,0}, bf16[1,1,1024]{2,1,0}, bf16[1024]{0}, f32[], bf16[1024]{0}, /*index=435*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=440*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=445*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=450*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=455*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=460*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=465*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=470*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=475*/bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, bf16[1024]{0}, /*index=480*/bf16[1024]{0}, bf16[4096]{0}, s64[256,1]{0,1}, s64[], s64[1,310]{1,0}, /*index=485*/bf16[92553,4096]{1,0}, bf16[4096]{0}, f32[], f64[], s64[1,310]{1,0}, /*index=490*/bf16[], bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=495*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=500*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=505*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=510*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=515*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=520*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=525*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=530*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=535*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=540*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=545*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=550*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=555*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=560*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=565*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=570*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=575*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=580*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=585*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=590*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=595*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=600*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=605*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=610*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=615*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=620*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=625*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=630*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=635*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=640*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=645*/bf16[4096]{0}, bf16[32768,128]{1,0}, bf16[32768,128]{1,0}, bf16[4096]{0}, bf16[14336,4096]{1,0}, /*index=650*/bf16[4096]{0})->(s64[1]{0})}

%MaxComputation.2158 (x.2159: bf16[], y.2160: bf16[]) -> bf16[] {
  %x.2159 = bf16[] parameter(0)
  %y.2160 = bf16[] parameter(1)
  ROOT %maximum.2161 = bf16[] maximum(bf16[] %x.2159, bf16[] %y.2160)
}

%AddComputation.2167 (x.2168: bf16[], y.2169: bf16[]) -> bf16[] {
  %x.2168 = bf16[] parameter(0)
  %y.2169 = bf16[] parameter(1)
  ROOT %add.2170 = bf16[] add(bf16[] %x.2168, bf16[] %y.2169)
}

%MaxComputation.2287 (x.2288: bf16[], y.2289: bf16[]) -> bf16[] {
  %x.2288 = bf16[] parameter(0)
  %y.2289 = bf16[] parameter(1)
  ROOT %maximum.2290 = bf16[] maximum(bf16[] %x.2288, bf16[] %y.2289)
}

%AddComputation.2296 (x.2297: bf16[], y.2298: bf16[]) -> bf16[] {
  %x.2297 = bf16[] parameter(0)
  %y.2298 = bf16[] parameter(1)
  ROOT %add.2299 = bf16[] add(bf16[] %x.2297, bf16[] %y.2298)
}

%MaxComputation.2416 (x.2417: bf16[], y.2418: bf16[]) -> bf16[] {
  %x.2417 = bf16[] parameter(0)
  %y.2418 = bf16[] parameter(1)
  ROOT %maximum.2419 = bf16[] maximum(bf16[] %x.2417, bf16[] %y.2418)
}

%AddComputation.2425 (x.2426: bf16[], y.2427: bf16[]) -> bf16[] {
  %x.2426 = bf16[] parameter(0)
  %y.2427 = bf16[] parameter(1)
  ROOT %add.2428 = bf16[] add(bf16[] %x.2426, bf16[] %y.2427)
}

%MaxComputation.2545 (x.2546: bf16[], y.2547: bf16[]) -> bf16[] {
  %x.2546 = bf16[] parameter(0)
  %y.2547 = bf16[] parameter(1)
  ROOT %maximum.2548 = bf16[] maximum(bf16[] %x.2546, bf16[] %y.2547)
}

%AddComputation.2554 (x.2555: bf16[], y.2556: bf16[]) -> bf16[] {
  %x.2555 = bf16[] parameter(0)
  %y.2556 = bf16[] parameter(1)
  ROOT %add.2557 = bf16[] add(bf16[] %x.2555, bf16[] %y.2556)
}

%MaxComputation.2674 (x.2675: bf16[], y.2676: bf16[]) -> bf16[] {
  %x.2675 = bf16[] parameter(0)
  %y.2676 = bf16[] parameter(1)
  ROOT %maximum.2677 = bf16[] maximum(bf16[] %x.2675, bf16[] %y.2676)
}

%AddComputation.2683 (x.2684: bf16[], y.2685: bf16[]) -> bf16[] {
  %x.2684 = bf16[] parameter(0)
  %y.2685 = bf16[] parameter(1)
  ROOT %add.2686 = bf16[] add(bf16[] %x.2684, bf16[] %y.2685)
}

%MaxComputation.2803 (x.2804: bf16[], y.2805: bf16[]) -> bf16[] {
  %x.2804 = bf16[] parameter(0)
  %y.2805 = bf16[] parameter(1)
  ROOT %maximum.2806 = bf16[] maximum(bf16[] %x.2804, bf16[] %y.2805)
}

%AddComputation.2812 (x.2813: bf16[], y.2814: bf16[]) -> bf16[] {
  %x.2813 = bf16[] parameter(0)
  %y.2814 = bf16[] parameter(1)
  ROOT %add.2815 = bf16[] add(bf16[] %x.2813, bf16[] %y.2814)
}

%MaxComputation.2932 (x.2933: bf16[], y.2934: bf16[]) -> bf16[] {
  %x.2933 = bf16[] parameter(0)
  %y.2934 = bf16[] parameter(1)
  ROOT %maximum.2935 = bf16[] maximum(bf16[] %x.2933, bf16[] %y.2934)
}

%AddComputation.2941 (x.2942: bf16[], y.2943: bf16[]) -> bf16[] {
  %x.2942 = bf16[] parameter(0)
  %y.2943 = bf16[] parameter(1)
  ROOT %add.2944 = bf16[] add(bf16[] %x.2942, bf16[] %y.2943)
}

%MaxComputation.3061 (x.3062: bf16[], y.3063: bf16[]) -> bf16[] {
  %x.3062 = bf16[] parameter(0)
  %y.3063 = bf16[] parameter(1)
  ROOT %maximum.3064 = bf16[] maximum(bf16[] %x.3062, bf16[] %y.3063)
}

%AddComputation.3070 (x.3071: bf16[], y.3072: bf16[]) -> bf16[] {
  %x.3071 = bf16[] parameter(0)
  %y.3072 = bf16[] parameter(1)
  ROOT %add.3073 = bf16[] add(bf16[] %x.3071, bf16[] %y.3072)
}

%MaxComputation.3190 (x.3191: bf16[], y.3192: bf16[]) -> bf16[] {
  %x.3191 = bf16[] parameter(0)
  %y.3192 = bf16[] parameter(1)
  ROOT %maximum.3193 = bf16[] maximum(bf16[] %x.3191, bf16[] %y.3192)
}

%AddComputation.3199 (x.3200: bf16[], y.3201: bf16[]) -> bf16[] {
  %x.3200 = bf16[] parameter(0)
  %y.3201 = bf16[] parameter(1)
  ROOT %add.3202 = bf16[] add(bf16[] %x.3200, bf16[] %y.3201)
}

%MaxComputation.3319 (x.3320: bf16[], y.3321: bf16[]) -> bf16[] {
  %x.3320 = bf16[] parameter(0)
  %y.3321 = bf16[] parameter(1)
  ROOT %maximum.3322 = bf16[] maximum(bf16[] %x.3320, bf16[] %y.3321)
}

%AddComputation.3328 (x.3329: bf16[], y.3330: bf16[]) -> bf16[] {
  %x.3329 = bf16[] parameter(0)
  %y.3330 = bf16[] parameter(1)
  ROOT %add.3331 = bf16[] add(bf16[] %x.3329, bf16[] %y.3330)
}

%MaxComputation.3448 (x.3449: bf16[], y.3450: bf16[]) -> bf16[] {
  %x.3449 = bf16[] parameter(0)
  %y.3450 = bf16[] parameter(1)
  ROOT %maximum.3451 = bf16[] maximum(bf16[] %x.3449, bf16[] %y.3450)
}

%AddComputation.3457 (x.3458: bf16[], y.3459: bf16[]) -> bf16[] {
  %x.3458 = bf16[] parameter(0)
  %y.3459 = bf16[] parameter(1)
  ROOT %add.3460 = bf16[] add(bf16[] %x.3458, bf16[] %y.3459)
}

%MaxComputation.3577 (x.3578: bf16[], y.3579: bf16[]) -> bf16[] {
  %x.3578 = bf16[] parameter(0)
  %y.3579 = bf16[] parameter(1)
  ROOT %maximum.3580 = bf16[] maximum(bf16[] %x.3578, bf16[] %y.3579)
}

%AddComputation.3586 (x.3587: bf16[], y.3588: bf16[]) -> bf16[] {
  %x.3587 = bf16[] parameter(0)
  %y.3588 = bf16[] parameter(1)
  ROOT %add.3589 = bf16[] add(bf16[] %x.3587, bf16[] %y.3588)
}

%MaxComputation.3706 (x.3707: bf16[], y.3708: bf16[]) -> bf16[] {
  %x.3707 = bf16[] parameter(0)
  %y.3708 = bf16[] parameter(1)
  ROOT %maximum.3709 = bf16[] maximum(bf16[] %x.3707, bf16[] %y.3708)
}

%AddComputation.3715 (x.3716: bf16[], y.3717: bf16[]) -> bf16[] {
  %x.3716 = bf16[] parameter(0)
  %y.3717 = bf16[] parameter(1)
  ROOT %add.3718 = bf16[] add(bf16[] %x.3716, bf16[] %y.3717)
}

%MaxComputation.3835 (x.3836: bf16[], y.3837: bf16[]) -> bf16[] {
  %x.3836 = bf16[] parameter(0)
  %y.3837 = bf16[] parameter(1)
  ROOT %maximum.3838 = bf16[] maximum(bf16[] %x.3836, bf16[] %y.3837)
}

%AddComputation.3844 (x.3845: bf16[], y.3846: bf16[]) -> bf16[] {
  %x.3845 = bf16[] parameter(0)
  %y.3846 = bf16[] parameter(1)
  ROOT %add.3847 = bf16[] add(bf16[] %x.3845, bf16[] %y.3846)
}

%MaxComputation.3964 (x.3965: bf16[], y.3966: bf16[]) -> bf16[] {
  %x.3965 = bf16[] parameter(0)
  %y.3966 = bf16[] parameter(1)
  ROOT %maximum.3967 = bf16[] maximum(bf16[] %x.3965, bf16[] %y.3966)
}

%AddComputation.3973 (x.3974: bf16[], y.3975: bf16[]) -> bf16[] {
  %x.3974 = bf16[] parameter(0)
  %y.3975 = bf16[] parameter(1)
  ROOT %add.3976 = bf16[] add(bf16[] %x.3974, bf16[] %y.3975)
}

%MaxComputation.4093 (x.4094: bf16[], y.4095: bf16[]) -> bf16[] {
  %x.4094 = bf16[] parameter(0)
  %y.4095 = bf16[] parameter(1)
  ROOT %maximum.4096 = bf16[] maximum(bf16[] %x.4094, bf16[] %y.4095)
}

%AddComputation.4102 (x.4103: bf16[], y.4104: bf16[]) -> bf16[] {
  %x.4103 = bf16[] parameter(0)
  %y.4104 = bf16[] parameter(1)
  ROOT %add.4105 = bf16[] add(bf16[] %x.4103, bf16[] %y.4104)
}

%MaxComputation.4222 (x.4223: bf16[], y.4224: bf16[]) -> bf16[] {
  %x.4223 = bf16[] parameter(0)
  %y.4224 = bf16[] parameter(1)
  ROOT %maximum.4225 = bf16[] maximum(bf16[] %x.4223, bf16[] %y.4224)
}

%AddComputation.4231 (x.4232: bf16[], y.4233: bf16[]) -> bf16[] {
  %x.4232 = bf16[] parameter(0)
  %y.4233 = bf16[] parameter(1)
  ROOT %add.4234 = bf16[] add(bf16[] %x.4232, bf16[] %y.4233)
}

%MaxComputation.4351 (x.4352: bf16[], y.4353: bf16[]) -> bf16[] {
  %x.4352 = bf16[] parameter(0)
  %y.4353 = bf16[] parameter(1)
  ROOT %maximum.4354 = bf16[] maximum(bf16[] %x.4352, bf16[] %y.4353)
}

%AddComputation.4360 (x.4361: bf16[], y.4362: bf16[]) -> bf16[] {
  %x.4361 = bf16[] parameter(0)
  %y.4362 = bf16[] parameter(1)
  ROOT %add.4363 = bf16[] add(bf16[] %x.4361, bf16[] %y.4362)
}

%MaxComputation.4480 (x.4481: bf16[], y.4482: bf16[]) -> bf16[] {
  %x.4481 = bf16[] parameter(0)
  %y.4482 = bf16[] parameter(1)
  ROOT %maximum.4483 = bf16[] maximum(bf16[] %x.4481, bf16[] %y.4482)
}

%AddComputation.4489 (x.4490: bf16[], y.4491: bf16[]) -> bf16[] {
  %x.4490 = bf16[] parameter(0)
  %y.4491 = bf16[] parameter(1)
  ROOT %add.4492 = bf16[] add(bf16[] %x.4490, bf16[] %y.4491)
}

%MaxComputation.4609 (x.4610: bf16[], y.4611: bf16[]) -> bf16[] {
  %x.4610 = bf16[] parameter(0)
  %y.4611 = bf16[] parameter(1)
  ROOT %maximum.4612 = bf16[] maximum(bf16[] %x.4610, bf16[] %y.4611)
}

%AddComputation.4618 (x.4619: bf16[], y.4620: bf16[]) -> bf16[] {
  %x.4619 = bf16[] parameter(0)
  %y.4620 = bf16[] parameter(1)
  ROOT %add.4621 = bf16[] add(bf16[] %x.4619, bf16[] %y.4620)
}

%MaxComputation.4738 (x.4739: bf16[], y.4740: bf16[]) -> bf16[] {
  %x.4739 = bf16[] parameter(0)
  %y.4740 = bf16[] parameter(1)
  ROOT %maximum.4741 = bf16[] maximum(bf16[] %x.4739, bf16[] %y.4740)
}

%AddComputation.4747 (x.4748: bf16[], y.4749: bf16[]) -> bf16[] {
  %x.4748 = bf16[] parameter(0)
  %y.4749 = bf16[] parameter(1)
  ROOT %add.4750 = bf16[] add(bf16[] %x.4748, bf16[] %y.4749)
}

%MaxComputation.4867 (x.4868: bf16[], y.4869: bf16[]) -> bf16[] {
  %x.4868 = bf16[] parameter(0)
  %y.4869 = bf16[] parameter(1)
  ROOT %maximum.4870 = bf16[] maximum(bf16[] %x.4868, bf16[] %y.4869)
}

%AddComputation.4876 (x.4877: bf16[], y.4878: bf16[]) -> bf16[] {
  %x.4877 = bf16[] parameter(0)
  %y.4878 = bf16[] parameter(1)
  ROOT %add.4879 = bf16[] add(bf16[] %x.4877, bf16[] %y.4878)
}

%MaxComputation.4996 (x.4997: bf16[], y.4998: bf16[]) -> bf16[] {
  %x.4997 = bf16[] parameter(0)
  %y.4998 = bf16[] parameter(1)
  ROOT %maximum.4999 = bf16[] maximum(bf16[] %x.4997, bf16[] %y.4998)
}

%AddComputation.5005 (x.5006: bf16[], y.5007: bf16[]) -> bf16[] {
  %x.5006 = bf16[] parameter(0)
  %y.5007 = bf16[] parameter(1)
  ROOT %add.5008 = bf16[] add(bf16[] %x.5006, bf16[] %y.5007)
}

%MaxComputation.5125 (x.5126: bf16[], y.5127: bf16[]) -> bf16[] {
  %x.5126 = bf16[] parameter(0)
  %y.5127 = bf16[] parameter(1)
  ROOT %maximum.5128 = bf16[] maximum(bf16[] %x.5126, bf16[] %y.5127)
}

%AddComputation.5134 (x.5135: bf16[], y.5136: bf16[]) -> bf16[] {
  %x.5135 = bf16[] parameter(0)
  %y.5136 = bf16[] parameter(1)
  ROOT %add.5137 = bf16[] add(bf16[] %x.5135, bf16[] %y.5136)
}

%ScatterCombiner.5283 (p0.5284: bf16[], p1.5285: bf16[]) -> bf16[] {
  %p0.5284 = bf16[] parameter(0)
  ROOT %p1.5285 = bf16[] parameter(1)
}

%AddComputation.5296 (x.5297: f32[], y.5298: f32[]) -> f32[] {
  %x.5297 = f32[] parameter(0)
  %y.5298 = f32[] parameter(1)
  ROOT %add.5299 = f32[] add(f32[] %x.5297, f32[] %y.5298)
}

%AddComputation.5415 (x.5416: s64[], y.5417: s64[]) -> s64[] {
  %x.5416 = s64[] parameter(0)
  %y.5417 = s64[] parameter(1)
  ROOT %add.5418 = s64[] add(s64[] %x.5416, s64[] %y.5417)
}

%MaxComputation.5532 (x.5533: f32[], y.5534: f32[]) -> f32[] {
  %x.5533 = f32[] parameter(0)
  %y.5534 = f32[] parameter(1)
  ROOT %maximum.5535 = f32[] maximum(f32[] %x.5533, f32[] %y.5534)
}

%AddComputation.5541 (x.5542: f32[], y.5543: f32[]) -> f32[] {
  %x.5542 = f32[] parameter(0)
  %y.5543 = f32[] parameter(1)
  ROOT %add.5544 = f32[] add(f32[] %x.5542, f32[] %y.5543)
}

%AddComputation.5566 (x.5567: f32[], y.5568: f32[]) -> f32[] {
  %x.5567 = f32[] parameter(0)
  %y.5568 = f32[] parameter(1)
  ROOT %add.5569 = f32[] add(f32[] %x.5567, f32[] %y.5568)
}

%AddComputation.5621 (x.5622: f32[], y.5623: f32[]) -> f32[] {
  %x.5622 = f32[] parameter(0)
  %y.5623 = f32[] parameter(1)
  ROOT %add.5624 = f32[] add(f32[] %x.5622, f32[] %y.5623)
}

%MaxComputation.5774 (x.5775: f32[], y.5776: f32[]) -> f32[] {
  %x.5775 = f32[] parameter(0)
  %y.5776 = f32[] parameter(1)
  ROOT %maximum.5777 = f32[] maximum(f32[] %x.5775, f32[] %y.5776)
}

%AddComputation.5783 (x.5784: f32[], y.5785: f32[]) -> f32[] {
  %x.5784 = f32[] parameter(0)
  %y.5785 = f32[] parameter(1)
  ROOT %add.5786 = f32[] add(f32[] %x.5784, f32[] %y.5785)
}

%AddComputation.5808 (x.5809: f32[], y.5810: f32[]) -> f32[] {
  %x.5809 = f32[] parameter(0)
  %y.5810 = f32[] parameter(1)
  ROOT %add.5811 = f32[] add(f32[] %x.5809, f32[] %y.5810)
}

%AddComputation.5863 (x.5864: f32[], y.5865: f32[]) -> f32[] {
  %x.5864 = f32[] parameter(0)
  %y.5865 = f32[] parameter(1)
  ROOT %add.5866 = f32[] add(f32[] %x.5864, f32[] %y.5865)
}

%MaxComputation.6016 (x.6017: f32[], y.6018: f32[]) -> f32[] {
  %x.6017 = f32[] parameter(0)
  %y.6018 = f32[] parameter(1)
  ROOT %maximum.6019 = f32[] maximum(f32[] %x.6017, f32[] %y.6018)
}

%AddComputation.6025 (x.6026: f32[], y.6027: f32[]) -> f32[] {
  %x.6026 = f32[] parameter(0)
  %y.6027 = f32[] parameter(1)
  ROOT %add.6028 = f32[] add(f32[] %x.6026, f32[] %y.6027)
}

%AddComputation.6050 (x.6051: f32[], y.6052: f32[]) -> f32[] {
  %x.6051 = f32[] parameter(0)
  %y.6052 = f32[] parameter(1)
  ROOT %add.6053 = f32[] add(f32[] %x.6051, f32[] %y.6052)
}

%AddComputation.6105 (x.6106: f32[], y.6107: f32[]) -> f32[] {
  %x.6106 = f32[] parameter(0)
  %y.6107 = f32[] parameter(1)
  ROOT %add.6108 = f32[] add(f32[] %x.6106, f32[] %y.6107)
}

%MaxComputation.6258 (x.6259: f32[], y.6260: f32[]) -> f32[] {
  %x.6259 = f32[] parameter(0)
  %y.6260 = f32[] parameter(1)
  ROOT %maximum.6261 = f32[] maximum(f32[] %x.6259, f32[] %y.6260)
}

%AddComputation.6267 (x.6268: f32[], y.6269: f32[]) -> f32[] {
  %x.6268 = f32[] parameter(0)
  %y.6269 = f32[] parameter(1)
  ROOT %add.6270 = f32[] add(f32[] %x.6268, f32[] %y.6269)
}

%AddComputation.6292 (x.6293: f32[], y.6294: f32[]) -> f32[] {
  %x.6293 = f32[] parameter(0)
  %y.6294 = f32[] parameter(1)
  ROOT %add.6295 = f32[] add(f32[] %x.6293, f32[] %y.6294)
}

%AddComputation.6347 (x.6348: f32[], y.6349: f32[]) -> f32[] {
  %x.6348 = f32[] parameter(0)
  %y.6349 = f32[] parameter(1)
  ROOT %add.6350 = f32[] add(f32[] %x.6348, f32[] %y.6349)
}

%MaxComputation.6500 (x.6501: f32[], y.6502: f32[]) -> f32[] {
  %x.6501 = f32[] parameter(0)
  %y.6502 = f32[] parameter(1)
  ROOT %maximum.6503 = f32[] maximum(f32[] %x.6501, f32[] %y.6502)
}

%AddComputation.6509 (x.6510: f32[], y.6511: f32[]) -> f32[] {
  %x.6510 = f32[] parameter(0)
  %y.6511 = f32[] parameter(1)
  ROOT %add.6512 = f32[] add(f32[] %x.6510, f32[] %y.6511)
}

%AddComputation.6534 (x.6535: f32[], y.6536: f32[]) -> f32[] {
  %x.6535 = f32[] parameter(0)
  %y.6536 = f32[] parameter(1)
  ROOT %add.6537 = f32[] add(f32[] %x.6535, f32[] %y.6536)
}

%AddComputation.6589 (x.6590: f32[], y.6591: f32[]) -> f32[] {
  %x.6590 = f32[] parameter(0)
  %y.6591 = f32[] parameter(1)
  ROOT %add.6592 = f32[] add(f32[] %x.6590, f32[] %y.6591)
}

%MaxComputation.6742 (x.6743: f32[], y.6744: f32[]) -> f32[] {
  %x.6743 = f32[] parameter(0)
  %y.6744 = f32[] parameter(1)
  ROOT %maximum.6745 = f32[] maximum(f32[] %x.6743, f32[] %y.6744)
}

%AddComputation.6751 (x.6752: f32[], y.6753: f32[]) -> f32[] {
  %x.6752 = f32[] parameter(0)
  %y.6753 = f32[] parameter(1)
  ROOT %add.6754 = f32[] add(f32[] %x.6752, f32[] %y.6753)
}

%AddComputation.6776 (x.6777: f32[], y.6778: f32[]) -> f32[] {
  %x.6777 = f32[] parameter(0)
  %y.6778 = f32[] parameter(1)
  ROOT %add.6779 = f32[] add(f32[] %x.6777, f32[] %y.6778)
}

%AddComputation.6831 (x.6832: f32[], y.6833: f32[]) -> f32[] {
  %x.6832 = f32[] parameter(0)
  %y.6833 = f32[] parameter(1)
  ROOT %add.6834 = f32[] add(f32[] %x.6832, f32[] %y.6833)
}

%MaxComputation.6984 (x.6985: f32[], y.6986: f32[]) -> f32[] {
  %x.6985 = f32[] parameter(0)
  %y.6986 = f32[] parameter(1)
  ROOT %maximum.6987 = f32[] maximum(f32[] %x.6985, f32[] %y.6986)
}

%AddComputation.6993 (x.6994: f32[], y.6995: f32[]) -> f32[] {
  %x.6994 = f32[] parameter(0)
  %y.6995 = f32[] parameter(1)
  ROOT %add.6996 = f32[] add(f32[] %x.6994, f32[] %y.6995)
}

%AddComputation.7018 (x.7019: f32[], y.7020: f32[]) -> f32[] {
  %x.7019 = f32[] parameter(0)
  %y.7020 = f32[] parameter(1)
  ROOT %add.7021 = f32[] add(f32[] %x.7019, f32[] %y.7020)
}

%AddComputation.7073 (x.7074: f32[], y.7075: f32[]) -> f32[] {
  %x.7074 = f32[] parameter(0)
  %y.7075 = f32[] parameter(1)
  ROOT %add.7076 = f32[] add(f32[] %x.7074, f32[] %y.7075)
}

%MaxComputation.7226 (x.7227: f32[], y.7228: f32[]) -> f32[] {
  %x.7227 = f32[] parameter(0)
  %y.7228 = f32[] parameter(1)
  ROOT %maximum.7229 = f32[] maximum(f32[] %x.7227, f32[] %y.7228)
}

%AddComputation.7235 (x.7236: f32[], y.7237: f32[]) -> f32[] {
  %x.7236 = f32[] parameter(0)
  %y.7237 = f32[] parameter(1)
  ROOT %add.7238 = f32[] add(f32[] %x.7236, f32[] %y.7237)
}

%AddComputation.7260 (x.7261: f32[], y.7262: f32[]) -> f32[] {
  %x.7261 = f32[] parameter(0)
  %y.7262 = f32[] parameter(1)
  ROOT %add.7263 = f32[] add(f32[] %x.7261, f32[] %y.7262)
}

%AddComputation.7315 (x.7316: f32[], y.7317: f32[]) -> f32[] {
  %x.7316 = f32[] parameter(0)
  %y.7317 = f32[] parameter(1)
  ROOT %add.7318 = f32[] add(f32[] %x.7316, f32[] %y.7317)
}

%MaxComputation.7468 (x.7469: f32[], y.7470: f32[]) -> f32[] {
  %x.7469 = f32[] parameter(0)
  %y.7470 = f32[] parameter(1)
  ROOT %maximum.7471 = f32[] maximum(f32[] %x.7469, f32[] %y.7470)
}

%AddComputation.7477 (x.7478: f32[], y.7479: f32[]) -> f32[] {
  %x.7478 = f32[] parameter(0)
  %y.7479 = f32[] parameter(1)
  ROOT %add.7480 = f32[] add(f32[] %x.7478, f32[] %y.7479)
}

%AddComputation.7502 (x.7503: f32[], y.7504: f32[]) -> f32[] {
  %x.7503 = f32[] parameter(0)
  %y.7504 = f32[] parameter(1)
  ROOT %add.7505 = f32[] add(f32[] %x.7503, f32[] %y.7504)
}

%AddComputation.7557 (x.7558: f32[], y.7559: f32[]) -> f32[] {
  %x.7558 = f32[] parameter(0)
  %y.7559 = f32[] parameter(1)
  ROOT %add.7560 = f32[] add(f32[] %x.7558, f32[] %y.7559)
}

%MaxComputation.7710 (x.7711: f32[], y.7712: f32[]) -> f32[] {
  %x.7711 = f32[] parameter(0)
  %y.7712 = f32[] parameter(1)
  ROOT %maximum.7713 = f32[] maximum(f32[] %x.7711, f32[] %y.7712)
}

%AddComputation.7719 (x.7720: f32[], y.7721: f32[]) -> f32[] {
  %x.7720 = f32[] parameter(0)
  %y.7721 = f32[] parameter(1)
  ROOT %add.7722 = f32[] add(f32[] %x.7720, f32[] %y.7721)
}

%AddComputation.7744 (x.7745: f32[], y.7746: f32[]) -> f32[] {
  %x.7745 = f32[] parameter(0)
  %y.7746 = f32[] parameter(1)
  ROOT %add.7747 = f32[] add(f32[] %x.7745, f32[] %y.7746)
}

%AddComputation.7799 (x.7800: f32[], y.7801: f32[]) -> f32[] {
  %x.7800 = f32[] parameter(0)
  %y.7801 = f32[] parameter(1)
  ROOT %add.7802 = f32[] add(f32[] %x.7800, f32[] %y.7801)
}

%MaxComputation.7952 (x.7953: f32[], y.7954: f32[]) -> f32[] {
  %x.7953 = f32[] parameter(0)
  %y.7954 = f32[] parameter(1)
  ROOT %maximum.7955 = f32[] maximum(f32[] %x.7953, f32[] %y.7954)
}

%AddComputation.7961 (x.7962: f32[], y.7963: f32[]) -> f32[] {
  %x.7962 = f32[] parameter(0)
  %y.7963 = f32[] parameter(1)
  ROOT %add.7964 = f32[] add(f32[] %x.7962, f32[] %y.7963)
}

%AddComputation.7986 (x.7987: f32[], y.7988: f32[]) -> f32[] {
  %x.7987 = f32[] parameter(0)
  %y.7988 = f32[] parameter(1)
  ROOT %add.7989 = f32[] add(f32[] %x.7987, f32[] %y.7988)
}

%AddComputation.8041 (x.8042: f32[], y.8043: f32[]) -> f32[] {
  %x.8042 = f32[] parameter(0)
  %y.8043 = f32[] parameter(1)
  ROOT %add.8044 = f32[] add(f32[] %x.8042, f32[] %y.8043)
}

%MaxComputation.8194 (x.8195: f32[], y.8196: f32[]) -> f32[] {
  %x.8195 = f32[] parameter(0)
  %y.8196 = f32[] parameter(1)
  ROOT %maximum.8197 = f32[] maximum(f32[] %x.8195, f32[] %y.8196)
}

%AddComputation.8203 (x.8204: f32[], y.8205: f32[]) -> f32[] {
  %x.8204 = f32[] parameter(0)
  %y.8205 = f32[] parameter(1)
  ROOT %add.8206 = f32[] add(f32[] %x.8204, f32[] %y.8205)
}

%AddComputation.8228 (x.8229: f32[], y.8230: f32[]) -> f32[] {
  %x.8229 = f32[] parameter(0)
  %y.8230 = f32[] parameter(1)
  ROOT %add.8231 = f32[] add(f32[] %x.8229, f32[] %y.8230)
}

%AddComputation.8283 (x.8284: f32[], y.8285: f32[]) -> f32[] {
  %x.8284 = f32[] parameter(0)
  %y.8285 = f32[] parameter(1)
  ROOT %add.8286 = f32[] add(f32[] %x.8284, f32[] %y.8285)
}

%MaxComputation.8436 (x.8437: f32[], y.8438: f32[]) -> f32[] {
  %x.8437 = f32[] parameter(0)
  %y.8438 = f32[] parameter(1)
  ROOT %maximum.8439 = f32[] maximum(f32[] %x.8437, f32[] %y.8438)
}

%AddComputation.8445 (x.8446: f32[], y.8447: f32[]) -> f32[] {
  %x.8446 = f32[] parameter(0)
  %y.8447 = f32[] parameter(1)
  ROOT %add.8448 = f32[] add(f32[] %x.8446, f32[] %y.8447)
}

%AddComputation.8470 (x.8471: f32[], y.8472: f32[]) -> f32[] {
  %x.8471 = f32[] parameter(0)
  %y.8472 = f32[] parameter(1)
  ROOT %add.8473 = f32[] add(f32[] %x.8471, f32[] %y.8472)
}

%AddComputation.8525 (x.8526: f32[], y.8527: f32[]) -> f32[] {
  %x.8526 = f32[] parameter(0)
  %y.8527 = f32[] parameter(1)
  ROOT %add.8528 = f32[] add(f32[] %x.8526, f32[] %y.8527)
}

%MaxComputation.8678 (x.8679: f32[], y.8680: f32[]) -> f32[] {
  %x.8679 = f32[] parameter(0)
  %y.8680 = f32[] parameter(1)
  ROOT %maximum.8681 = f32[] maximum(f32[] %x.8679, f32[] %y.8680)
}

%AddComputation.8687 (x.8688: f32[], y.8689: f32[]) -> f32[] {
  %x.8688 = f32[] parameter(0)
  %y.8689 = f32[] parameter(1)
  ROOT %add.8690 = f32[] add(f32[] %x.8688, f32[] %y.8689)
}

%AddComputation.8712 (x.8713: f32[], y.8714: f32[]) -> f32[] {
  %x.8713 = f32[] parameter(0)
  %y.8714 = f32[] parameter(1)
  ROOT %add.8715 = f32[] add(f32[] %x.8713, f32[] %y.8714)
}

%AddComputation.8767 (x.8768: f32[], y.8769: f32[]) -> f32[] {
  %x.8768 = f32[] parameter(0)
  %y.8769 = f32[] parameter(1)
  ROOT %add.8770 = f32[] add(f32[] %x.8768, f32[] %y.8769)
}

%MaxComputation.8920 (x.8921: f32[], y.8922: f32[]) -> f32[] {
  %x.8921 = f32[] parameter(0)
  %y.8922 = f32[] parameter(1)
  ROOT %maximum.8923 = f32[] maximum(f32[] %x.8921, f32[] %y.8922)
}

%AddComputation.8929 (x.8930: f32[], y.8931: f32[]) -> f32[] {
  %x.8930 = f32[] parameter(0)
  %y.8931 = f32[] parameter(1)
  ROOT %add.8932 = f32[] add(f32[] %x.8930, f32[] %y.8931)
}

%AddComputation.8954 (x.8955: f32[], y.8956: f32[]) -> f32[] {
  %x.8955 = f32[] parameter(0)
  %y.8956 = f32[] parameter(1)
  ROOT %add.8957 = f32[] add(f32[] %x.8955, f32[] %y.8956)
}

%AddComputation.9009 (x.9010: f32[], y.9011: f32[]) -> f32[] {
  %x.9010 = f32[] parameter(0)
  %y.9011 = f32[] parameter(1)
  ROOT %add.9012 = f32[] add(f32[] %x.9010, f32[] %y.9011)
}

%MaxComputation.9162 (x.9163: f32[], y.9164: f32[]) -> f32[] {
  %x.9163 = f32[] parameter(0)
  %y.9164 = f32[] parameter(1)
  ROOT %maximum.9165 = f32[] maximum(f32[] %x.9163, f32[] %y.9164)
}

%AddComputation.9171 (x.9172: f32[], y.9173: f32[]) -> f32[] {
  %x.9172 = f32[] parameter(0)
  %y.9173 = f32[] parameter(1)
  ROOT %add.9174 = f32[] add(f32[] %x.9172, f32[] %y.9173)
}

%AddComputation.9196 (x.9197: f32[], y.9198: f32[]) -> f32[] {
  %x.9197 = f32[] parameter(0)
  %y.9198 = f32[] parameter(1)
  ROOT %add.9199 = f32[] add(f32[] %x.9197, f32[] %y.9198)
}

%AddComputation.9251 (x.9252: f32[], y.9253: f32[]) -> f32[] {
  %x.9252 = f32[] parameter(0)
  %y.9253 = f32[] parameter(1)
  ROOT %add.9254 = f32[] add(f32[] %x.9252, f32[] %y.9253)
}

%MaxComputation.9404 (x.9405: f32[], y.9406: f32[]) -> f32[] {
  %x.9405 = f32[] parameter(0)
  %y.9406 = f32[] parameter(1)
  ROOT %maximum.9407 = f32[] maximum(f32[] %x.9405, f32[] %y.9406)
}

%AddComputation.9413 (x.9414: f32[], y.9415: f32[]) -> f32[] {
  %x.9414 = f32[] parameter(0)
  %y.9415 = f32[] parameter(1)
  ROOT %add.9416 = f32[] add(f32[] %x.9414, f32[] %y.9415)
}

%AddComputation.9438 (x.9439: f32[], y.9440: f32[]) -> f32[] {
  %x.9439 = f32[] parameter(0)
  %y.9440 = f32[] parameter(1)
  ROOT %add.9441 = f32[] add(f32[] %x.9439, f32[] %y.9440)
}

%AddComputation.9493 (x.9494: f32[], y.9495: f32[]) -> f32[] {
  %x.9494 = f32[] parameter(0)
  %y.9495 = f32[] parameter(1)
  ROOT %add.9496 = f32[] add(f32[] %x.9494, f32[] %y.9495)
}

%MaxComputation.9646 (x.9647: f32[], y.9648: f32[]) -> f32[] {
  %x.9647 = f32[] parameter(0)
  %y.9648 = f32[] parameter(1)
  ROOT %maximum.9649 = f32[] maximum(f32[] %x.9647, f32[] %y.9648)
}

%AddComputation.9655 (x.9656: f32[], y.9657: f32[]) -> f32[] {
  %x.9656 = f32[] parameter(0)
  %y.9657 = f32[] parameter(1)
  ROOT %add.9658 = f32[] add(f32[] %x.9656, f32[] %y.9657)
}

%AddComputation.9680 (x.9681: f32[], y.9682: f32[]) -> f32[] {
  %x.9681 = f32[] parameter(0)
  %y.9682 = f32[] parameter(1)
  ROOT %add.9683 = f32[] add(f32[] %x.9681, f32[] %y.9682)
}

%AddComputation.9735 (x.9736: f32[], y.9737: f32[]) -> f32[] {
  %x.9736 = f32[] parameter(0)
  %y.9737 = f32[] parameter(1)
  ROOT %add.9738 = f32[] add(f32[] %x.9736, f32[] %y.9737)
}

%MaxComputation.9888 (x.9889: f32[], y.9890: f32[]) -> f32[] {
  %x.9889 = f32[] parameter(0)
  %y.9890 = f32[] parameter(1)
  ROOT %maximum.9891 = f32[] maximum(f32[] %x.9889, f32[] %y.9890)
}

%AddComputation.9897 (x.9898: f32[], y.9899: f32[]) -> f32[] {
  %x.9898 = f32[] parameter(0)
  %y.9899 = f32[] parameter(1)
  ROOT %add.9900 = f32[] add(f32[] %x.9898, f32[] %y.9899)
}

%AddComputation.9922 (x.9923: f32[], y.9924: f32[]) -> f32[] {
  %x.9923 = f32[] parameter(0)
  %y.9924 = f32[] parameter(1)
  ROOT %add.9925 = f32[] add(f32[] %x.9923, f32[] %y.9924)
}

%AddComputation.9977 (x.9978: f32[], y.9979: f32[]) -> f32[] {
  %x.9978 = f32[] parameter(0)
  %y.9979 = f32[] parameter(1)
  ROOT %add.9980 = f32[] add(f32[] %x.9978, f32[] %y.9979)
}

%MaxComputation.10130 (x.10131: f32[], y.10132: f32[]) -> f32[] {
  %x.10131 = f32[] parameter(0)
  %y.10132 = f32[] parameter(1)
  ROOT %maximum.10133 = f32[] maximum(f32[] %x.10131, f32[] %y.10132)
}

%AddComputation.10139 (x.10140: f32[], y.10141: f32[]) -> f32[] {
  %x.10140 = f32[] parameter(0)
  %y.10141 = f32[] parameter(1)
  ROOT %add.10142 = f32[] add(f32[] %x.10140, f32[] %y.10141)
}

%AddComputation.10164 (x.10165: f32[], y.10166: f32[]) -> f32[] {
  %x.10165 = f32[] parameter(0)
  %y.10166 = f32[] parameter(1)
  ROOT %add.10167 = f32[] add(f32[] %x.10165, f32[] %y.10166)
}

%AddComputation.10219 (x.10220: f32[], y.10221: f32[]) -> f32[] {
  %x.10220 = f32[] parameter(0)
  %y.10221 = f32[] parameter(1)
  ROOT %add.10222 = f32[] add(f32[] %x.10220, f32[] %y.10221)
}

%MaxComputation.10372 (x.10373: f32[], y.10374: f32[]) -> f32[] {
  %x.10373 = f32[] parameter(0)
  %y.10374 = f32[] parameter(1)
  ROOT %maximum.10375 = f32[] maximum(f32[] %x.10373, f32[] %y.10374)
}

%AddComputation.10381 (x.10382: f32[], y.10383: f32[]) -> f32[] {
  %x.10382 = f32[] parameter(0)
  %y.10383 = f32[] parameter(1)
  ROOT %add.10384 = f32[] add(f32[] %x.10382, f32[] %y.10383)
}

%AddComputation.10406 (x.10407: f32[], y.10408: f32[]) -> f32[] {
  %x.10407 = f32[] parameter(0)
  %y.10408 = f32[] parameter(1)
  ROOT %add.10409 = f32[] add(f32[] %x.10407, f32[] %y.10408)
}

%AddComputation.10461 (x.10462: f32[], y.10463: f32[]) -> f32[] {
  %x.10462 = f32[] parameter(0)
  %y.10463 = f32[] parameter(1)
  ROOT %add.10464 = f32[] add(f32[] %x.10462, f32[] %y.10463)
}

%MaxComputation.10614 (x.10615: f32[], y.10616: f32[]) -> f32[] {
  %x.10615 = f32[] parameter(0)
  %y.10616 = f32[] parameter(1)
  ROOT %maximum.10617 = f32[] maximum(f32[] %x.10615, f32[] %y.10616)
}

%AddComputation.10623 (x.10624: f32[], y.10625: f32[]) -> f32[] {
  %x.10624 = f32[] parameter(0)
  %y.10625 = f32[] parameter(1)
  ROOT %add.10626 = f32[] add(f32[] %x.10624, f32[] %y.10625)
}

%AddComputation.10648 (x.10649: f32[], y.10650: f32[]) -> f32[] {
  %x.10649 = f32[] parameter(0)
  %y.10650 = f32[] parameter(1)
  ROOT %add.10651 = f32[] add(f32[] %x.10649, f32[] %y.10650)
}

%AddComputation.10703 (x.10704: f32[], y.10705: f32[]) -> f32[] {
  %x.10704 = f32[] parameter(0)
  %y.10705 = f32[] parameter(1)
  ROOT %add.10706 = f32[] add(f32[] %x.10704, f32[] %y.10705)
}

%MaxComputation.10856 (x.10857: f32[], y.10858: f32[]) -> f32[] {
  %x.10857 = f32[] parameter(0)
  %y.10858 = f32[] parameter(1)
  ROOT %maximum.10859 = f32[] maximum(f32[] %x.10857, f32[] %y.10858)
}

%AddComputation.10865 (x.10866: f32[], y.10867: f32[]) -> f32[] {
  %x.10866 = f32[] parameter(0)
  %y.10867 = f32[] parameter(1)
  ROOT %add.10868 = f32[] add(f32[] %x.10866, f32[] %y.10867)
}

%AddComputation.10890 (x.10891: f32[], y.10892: f32[]) -> f32[] {
  %x.10891 = f32[] parameter(0)
  %y.10892 = f32[] parameter(1)
  ROOT %add.10893 = f32[] add(f32[] %x.10891, f32[] %y.10892)
}

%AddComputation.10945 (x.10946: f32[], y.10947: f32[]) -> f32[] {
  %x.10946 = f32[] parameter(0)
  %y.10947 = f32[] parameter(1)
  ROOT %add.10948 = f32[] add(f32[] %x.10946, f32[] %y.10947)
}

%MaxComputation.11098 (x.11099: f32[], y.11100: f32[]) -> f32[] {
  %x.11099 = f32[] parameter(0)
  %y.11100 = f32[] parameter(1)
  ROOT %maximum.11101 = f32[] maximum(f32[] %x.11099, f32[] %y.11100)
}

%AddComputation.11107 (x.11108: f32[], y.11109: f32[]) -> f32[] {
  %x.11108 = f32[] parameter(0)
  %y.11109 = f32[] parameter(1)
  ROOT %add.11110 = f32[] add(f32[] %x.11108, f32[] %y.11109)
}

%AddComputation.11132 (x.11133: f32[], y.11134: f32[]) -> f32[] {
  %x.11133 = f32[] parameter(0)
  %y.11134 = f32[] parameter(1)
  ROOT %add.11135 = f32[] add(f32[] %x.11133, f32[] %y.11134)
}

%AddComputation.11187 (x.11188: f32[], y.11189: f32[]) -> f32[] {
  %x.11188 = f32[] parameter(0)
  %y.11189 = f32[] parameter(1)
  ROOT %add.11190 = f32[] add(f32[] %x.11188, f32[] %y.11189)
}

%MaxComputation.11340 (x.11341: f32[], y.11342: f32[]) -> f32[] {
  %x.11341 = f32[] parameter(0)
  %y.11342 = f32[] parameter(1)
  ROOT %maximum.11343 = f32[] maximum(f32[] %x.11341, f32[] %y.11342)
}

%AddComputation.11349 (x.11350: f32[], y.11351: f32[]) -> f32[] {
  %x.11350 = f32[] parameter(0)
  %y.11351 = f32[] parameter(1)
  ROOT %add.11352 = f32[] add(f32[] %x.11350, f32[] %y.11351)
}

%AddComputation.11374 (x.11375: f32[], y.11376: f32[]) -> f32[] {
  %x.11375 = f32[] parameter(0)
  %y.11376 = f32[] parameter(1)
  ROOT %add.11377 = f32[] add(f32[] %x.11375, f32[] %y.11376)
}

%AddComputation.11429 (x.11430: f32[], y.11431: f32[]) -> f32[] {
  %x.11430 = f32[] parameter(0)
  %y.11431 = f32[] parameter(1)
  ROOT %add.11432 = f32[] add(f32[] %x.11430, f32[] %y.11431)
}

%MaxComputation.11582 (x.11583: f32[], y.11584: f32[]) -> f32[] {
  %x.11583 = f32[] parameter(0)
  %y.11584 = f32[] parameter(1)
  ROOT %maximum.11585 = f32[] maximum(f32[] %x.11583, f32[] %y.11584)
}

%AddComputation.11591 (x.11592: f32[], y.11593: f32[]) -> f32[] {
  %x.11592 = f32[] parameter(0)
  %y.11593 = f32[] parameter(1)
  ROOT %add.11594 = f32[] add(f32[] %x.11592, f32[] %y.11593)
}

%AddComputation.11616 (x.11617: f32[], y.11618: f32[]) -> f32[] {
  %x.11617 = f32[] parameter(0)
  %y.11618 = f32[] parameter(1)
  ROOT %add.11619 = f32[] add(f32[] %x.11617, f32[] %y.11618)
}

%AddComputation.11671 (x.11672: f32[], y.11673: f32[]) -> f32[] {
  %x.11672 = f32[] parameter(0)
  %y.11673 = f32[] parameter(1)
  ROOT %add.11674 = f32[] add(f32[] %x.11672, f32[] %y.11673)
}

%MaxComputation.11824 (x.11825: f32[], y.11826: f32[]) -> f32[] {
  %x.11825 = f32[] parameter(0)
  %y.11826 = f32[] parameter(1)
  ROOT %maximum.11827 = f32[] maximum(f32[] %x.11825, f32[] %y.11826)
}

%AddComputation.11833 (x.11834: f32[], y.11835: f32[]) -> f32[] {
  %x.11834 = f32[] parameter(0)
  %y.11835 = f32[] parameter(1)
  ROOT %add.11836 = f32[] add(f32[] %x.11834, f32[] %y.11835)
}

%AddComputation.11858 (x.11859: f32[], y.11860: f32[]) -> f32[] {
  %x.11859 = f32[] parameter(0)
  %y.11860 = f32[] parameter(1)
  ROOT %add.11861 = f32[] add(f32[] %x.11859, f32[] %y.11860)
}

%AddComputation.11913 (x.11914: f32[], y.11915: f32[]) -> f32[] {
  %x.11914 = f32[] parameter(0)
  %y.11915 = f32[] parameter(1)
  ROOT %add.11916 = f32[] add(f32[] %x.11914, f32[] %y.11915)
}

%MaxComputation.12066 (x.12067: f32[], y.12068: f32[]) -> f32[] {
  %x.12067 = f32[] parameter(0)
  %y.12068 = f32[] parameter(1)
  ROOT %maximum.12069 = f32[] maximum(f32[] %x.12067, f32[] %y.12068)
}

%AddComputation.12075 (x.12076: f32[], y.12077: f32[]) -> f32[] {
  %x.12076 = f32[] parameter(0)
  %y.12077 = f32[] parameter(1)
  ROOT %add.12078 = f32[] add(f32[] %x.12076, f32[] %y.12077)
}

%AddComputation.12100 (x.12101: f32[], y.12102: f32[]) -> f32[] {
  %x.12101 = f32[] parameter(0)
  %y.12102 = f32[] parameter(1)
  ROOT %add.12103 = f32[] add(f32[] %x.12101, f32[] %y.12102)
}

%AddComputation.12155 (x.12156: f32[], y.12157: f32[]) -> f32[] {
  %x.12156 = f32[] parameter(0)
  %y.12157 = f32[] parameter(1)
  ROOT %add.12158 = f32[] add(f32[] %x.12156, f32[] %y.12157)
}

%MaxComputation.12308 (x.12309: f32[], y.12310: f32[]) -> f32[] {
  %x.12309 = f32[] parameter(0)
  %y.12310 = f32[] parameter(1)
  ROOT %maximum.12311 = f32[] maximum(f32[] %x.12309, f32[] %y.12310)
}

%AddComputation.12317 (x.12318: f32[], y.12319: f32[]) -> f32[] {
  %x.12318 = f32[] parameter(0)
  %y.12319 = f32[] parameter(1)
  ROOT %add.12320 = f32[] add(f32[] %x.12318, f32[] %y.12319)
}

%AddComputation.12342 (x.12343: f32[], y.12344: f32[]) -> f32[] {
  %x.12343 = f32[] parameter(0)
  %y.12344 = f32[] parameter(1)
  ROOT %add.12345 = f32[] add(f32[] %x.12343, f32[] %y.12344)
}

%AddComputation.12397 (x.12398: f32[], y.12399: f32[]) -> f32[] {
  %x.12398 = f32[] parameter(0)
  %y.12399 = f32[] parameter(1)
  ROOT %add.12400 = f32[] add(f32[] %x.12398, f32[] %y.12399)
}

%MaxComputation.12550 (x.12551: f32[], y.12552: f32[]) -> f32[] {
  %x.12551 = f32[] parameter(0)
  %y.12552 = f32[] parameter(1)
  ROOT %maximum.12553 = f32[] maximum(f32[] %x.12551, f32[] %y.12552)
}

%AddComputation.12559 (x.12560: f32[], y.12561: f32[]) -> f32[] {
  %x.12560 = f32[] parameter(0)
  %y.12561 = f32[] parameter(1)
  ROOT %add.12562 = f32[] add(f32[] %x.12560, f32[] %y.12561)
}

%AddComputation.12584 (x.12585: f32[], y.12586: f32[]) -> f32[] {
  %x.12585 = f32[] parameter(0)
  %y.12586 = f32[] parameter(1)
  ROOT %add.12587 = f32[] add(f32[] %x.12585, f32[] %y.12586)
}

%AddComputation.12639 (x.12640: f32[], y.12641: f32[]) -> f32[] {
  %x.12640 = f32[] parameter(0)
  %y.12641 = f32[] parameter(1)
  ROOT %add.12642 = f32[] add(f32[] %x.12640, f32[] %y.12641)
}

%MaxComputation.12792 (x.12793: f32[], y.12794: f32[]) -> f32[] {
  %x.12793 = f32[] parameter(0)
  %y.12794 = f32[] parameter(1)
  ROOT %maximum.12795 = f32[] maximum(f32[] %x.12793, f32[] %y.12794)
}

%AddComputation.12801 (x.12802: f32[], y.12803: f32[]) -> f32[] {
  %x.12802 = f32[] parameter(0)
  %y.12803 = f32[] parameter(1)
  ROOT %add.12804 = f32[] add(f32[] %x.12802, f32[] %y.12803)
}

%AddComputation.12826 (x.12827: f32[], y.12828: f32[]) -> f32[] {
  %x.12827 = f32[] parameter(0)
  %y.12828 = f32[] parameter(1)
  ROOT %add.12829 = f32[] add(f32[] %x.12827, f32[] %y.12828)
}

%AddComputation.12881 (x.12882: f32[], y.12883: f32[]) -> f32[] {
  %x.12882 = f32[] parameter(0)
  %y.12883 = f32[] parameter(1)
  ROOT %add.12884 = f32[] add(f32[] %x.12882, f32[] %y.12883)
}

%MaxComputation.13034 (x.13035: f32[], y.13036: f32[]) -> f32[] {
  %x.13035 = f32[] parameter(0)
  %y.13036 = f32[] parameter(1)
  ROOT %maximum.13037 = f32[] maximum(f32[] %x.13035, f32[] %y.13036)
}

%AddComputation.13043 (x.13044: f32[], y.13045: f32[]) -> f32[] {
  %x.13044 = f32[] parameter(0)
  %y.13045 = f32[] parameter(1)
  ROOT %add.13046 = f32[] add(f32[] %x.13044, f32[] %y.13045)
}

%AddComputation.13068 (x.13069: f32[], y.13070: f32[]) -> f32[] {
  %x.13069 = f32[] parameter(0)
  %y.13070 = f32[] parameter(1)
  ROOT %add.13071 = f32[] add(f32[] %x.13069, f32[] %y.13070)
}

%AddComputation.13123 (x.13124: f32[], y.13125: f32[]) -> f32[] {
  %x.13124 = f32[] parameter(0)
  %y.13125 = f32[] parameter(1)
  ROOT %add.13126 = f32[] add(f32[] %x.13124, f32[] %y.13125)
}

%compare-greater-than.13162 (p.0.lhs.13163: f32[], p.0.rhs.13164: f32[], p.1.lhs.13165: s32[], p.1.rhs.13166: s32[]) -> pred[] {
  %p.1.lhs.13165 = s32[] parameter(2)
  %p.1.rhs.13166 = s32[] parameter(3)
  %p.0.lhs.13163 = f32[] parameter(0)
  %p.0.rhs.13164 = f32[] parameter(1)
  ROOT %compare.13167 = pred[] compare(f32[] %p.0.lhs.13163, f32[] %p.0.rhs.13164), direction=GT, type=TOTALORDER
}

%MaxComputation.13189 (x.13190: f32[], y.13191: f32[]) -> f32[] {
  %x.13190 = f32[] parameter(0)
  %y.13191 = f32[] parameter(1)
  ROOT %maximum.13192 = f32[] maximum(f32[] %x.13190, f32[] %y.13191)
}

%AddComputation.13198 (x.13199: f32[], y.13200: f32[]) -> f32[] {
  %x.13199 = f32[] parameter(0)
  %y.13200 = f32[] parameter(1)
  ROOT %add.13201 = f32[] add(f32[] %x.13199, f32[] %y.13200)
}

%AddComputation.13207 (x.13208: f32[], y.13209: f32[]) -> f32[] {
  %x.13208 = f32[] parameter(0)
  %y.13209 = f32[] parameter(1)
  ROOT %add.13210 = f32[] add(f32[] %x.13208, f32[] %y.13209)
}

%AddComputation.13245 (x.13246: s64[], y.13247: s64[]) -> s64[] {
  %x.13246 = s64[] parameter(0)
  %y.13247 = s64[] parameter(1)
  ROOT %add.13248 = s64[] add(s64[] %x.13246, s64[] %y.13247)
}

ENTRY %IrToHlo.13267 (p0.11: s64[], p1.14: s64[], p2.19: f64[], p3.20: bf16[92553,4096], p4.23: f32[], p5.26: bf16[4096,14336], p6.28: bf16[14336,4096], p7.33: bf16[4096,4096], p8.35: bf16[6144,4096], p9.40: bf16[4096,14336], p10.42: bf16[14336,4096], p11.47: bf16[4096,4096], p12.49: bf16[6144,4096], p13.54: bf16[4096,14336], p14.56: bf16[14336,4096], p15.61: bf16[4096,4096], p16.63: bf16[6144,4096], p17.68: bf16[4096,14336], p18.70: bf16[14336,4096], p19.75: bf16[4096,4096], p20.77: bf16[6144,4096], p21.82: bf16[4096,14336], p22.84: bf16[14336,4096], p23.89: bf16[4096,4096], p24.91: bf16[6144,4096], p25.96: bf16[4096,14336], p26.98: bf16[14336,4096], p27.103: bf16[4096,4096], p28.105: bf16[6144,4096], p29.110: bf16[4096,14336], p30.112: bf16[14336,4096], p31.117: bf16[4096,4096], p32.119: bf16[6144,4096], p33.124: bf16[4096,14336], p34.126: bf16[14336,4096], p35.131: bf16[4096,4096], p36.133: bf16[6144,4096], p37.138: bf16[4096,14336], p38.140: bf16[14336,4096], p39.145: bf16[4096,4096], p40.147: bf16[6144,4096], p41.152: bf16[4096,14336], p42.154: bf16[14336,4096], p43.159: bf16[4096,4096], p44.161: bf16[6144,4096], p45.166: bf16[4096,14336], p46.168: bf16[14336,4096], p47.173: bf16[4096,4096], p48.175: bf16[6144,4096], p49.180: bf16[4096,14336], p50.182: bf16[14336,4096], p51.187: bf16[4096,4096], p52.189: bf16[6144,4096], p53.194: bf16[4096,14336], p54.196: bf16[14336,4096], p55.201: bf16[4096,4096], p56.203: bf16[6144,4096], p57.208: bf16[4096,14336], p58.210: bf16[14336,4096], p59.215: bf16[4096,4096], p60.217: bf16[6144,4096], p61.222: bf16[4096,14336], p62.224: bf16[14336,4096], p63.229: bf16[4096,4096], p64.231: bf16[6144,4096], p65.236: bf16[4096,14336], p66.238: bf16[14336,4096], p67.243: bf16[4096,4096], p68.245: bf16[6144,4096], p69.250: bf16[4096,14336], p70.252: bf16[14336,4096], p71.257: bf16[4096,4096], p72.259: bf16[6144,4096], p73.264: bf16[4096,14336], p74.266: bf16[14336,4096], p75.271: bf16[4096,4096], p76.273: bf16[6144,4096], p77.278: bf16[4096,14336], p78.280: bf16[14336,4096], p79.285: bf16[4096,4096], p80.287: bf16[6144,4096], p81.292: bf16[4096,14336], p82.294: bf16[14336,4096], p83.299: bf16[4096,4096], p84.301: bf16[6144,4096], p85.306: bf16[4096,14336], p86.308: bf16[14336,4096], p87.313: bf16[4096,4096], p88.315: bf16[6144,4096], p89.320: bf16[4096,14336], p90.322: bf16[14336,4096], p91.327: bf16[4096,4096], p92.329: bf16[6144,4096], p93.334: bf16[4096,14336], p94.336: bf16[14336,4096], p95.341: bf16[4096,4096], p96.343: bf16[6144,4096], p97.348: bf16[4096,14336], p98.350: bf16[14336,4096], p99.355: bf16[4096,4096], p100.357: bf16[6144,4096], p101.362: bf16[4096,14336], p102.364: bf16[14336,4096], p103.369: bf16[4096,4096], p104.371: bf16[6144,4096], p105.376: bf16[4096,14336], p106.378: bf16[14336,4096], p107.383: bf16[4096,4096], p108.385: bf16[6144,4096], p109.390: bf16[4096,14336], p110.392: bf16[14336,4096], p111.397: bf16[4096,4096], p112.399: bf16[6144,4096], p113.404: bf16[4096,14336], p114.406: bf16[14336,4096], p115.411: bf16[4096,4096], p116.413: bf16[6144,4096], p117.418: bf16[4096,14336], p118.420: bf16[14336,4096], p119.425: bf16[4096,4096], p120.427: bf16[6144,4096], p121.432: bf16[4096,14336], p122.434: bf16[14336,4096], p123.439: bf16[4096,4096], p124.441: bf16[6144,4096], p125.446: bf16[4096,14336], p126.448: bf16[14336,4096], p127.453: bf16[4096,4096], p128.455: bf16[6144,4096], p129.460: bf16[4096,14336], p130.462: bf16[14336,4096], p131.467: bf16[4096,4096], p132.469: bf16[6144,4096], p133.474: bf16[4096], p134.475: bf16[4096,4096], p135.478: bf16[4096], p136.479: bf16[4096,4096], p137.482: bf16[4096], p138.504: bf16[1024], p139.507: bf16[1024], p140.508: bf16[1024,4096], p141.511: bf16[4096], p142.512: bf16[4096,1024], p143.515: bf16[1024], p144.537: bf16[1024], p145.540: bf16[1024], p146.541: bf16[1024,1024], p147.544: bf16[3072], p148.545: bf16[3072,1024], p149.548: bf16[1024], p150.570: bf16[1024], p151.573: bf16[1024], p152.574: bf16[1024,4096], p153.577: bf16[4096], p154.578: bf16[4096,1024], p155.581: bf16[1024], p156.603: bf16[1024], p157.606: bf16[1024], p158.607: bf16[1024,1024], p159.610: bf16[3072], p160.611: bf16[3072,1024], p161.614: bf16[1024], p162.636: bf16[1024], p163.639: bf16[1024], p164.640: bf16[1024,4096], p165.643: bf16[4096], p166.644: bf16[4096,1024], p167.647: bf16[1024], p168.669: bf16[1024], p169.672: bf16[1024], p170.673: bf16[1024,1024], p171.676: bf16[3072], p172.677: bf16[3072,1024], p173.680: bf16[1024], p174.702: bf16[1024], p175.705: bf16[1024], p176.706: bf16[1024,4096], p177.709: bf16[4096], p178.710: bf16[4096,1024], p179.713: bf16[1024], p180.735: bf16[1024], p181.738: bf16[1024], p182.739: bf16[1024,1024], p183.742: bf16[3072], p184.743: bf16[3072,1024], p185.746: bf16[1024], p186.768: bf16[1024], p187.771: bf16[1024], p188.772: bf16[1024,4096], p189.775: bf16[4096], p190.776: bf16[4096,1024], p191.779: bf16[1024], p192.801: bf16[1024], p193.804: bf16[1024], p194.805: bf16[1024,1024], p195.808: bf16[3072], p196.809: bf16[3072,1024], p197.812: bf16[1024], p198.834: bf16[1024], p199.837: bf16[1024], p200.838: bf16[1024,4096], p201.841: bf16[4096], p202.842: bf16[4096,1024], p203.845: bf16[1024], p204.867: bf16[1024], p205.870: bf16[1024], p206.871: bf16[1024,1024], p207.874: bf16[3072], p208.875: bf16[3072,1024], p209.878: bf16[1024], p210.900: bf16[1024], p211.903: bf16[1024], p212.904: bf16[1024,4096], p213.907: bf16[4096], p214.908: bf16[4096,1024], p215.911: bf16[1024], p216.933: bf16[1024], p217.936: bf16[1024], p218.937: bf16[1024,1024], p219.940: bf16[3072], p220.941: bf16[3072,1024], p221.944: bf16[1024], p222.966: bf16[1024], p223.969: bf16[1024], p224.970: bf16[1024,4096], p225.973: bf16[4096], p226.974: bf16[4096,1024], p227.977: bf16[1024], p228.999: bf16[1024], p229.1002: bf16[1024], p230.1003: bf16[1024,1024], p231.1006: bf16[3072], p232.1007: bf16[3072,1024], p233.1010: bf16[1024], p234.1032: bf16[1024], p235.1035: bf16[1024], p236.1036: bf16[1024,4096], p237.1039: bf16[4096], p238.1040: bf16[4096,1024], p239.1043: bf16[1024], p240.1065: bf16[1024], p241.1068: bf16[1024], p242.1069: bf16[1024,1024], p243.1072: bf16[3072], p244.1073: bf16[3072,1024], p245.1076: bf16[1024], p246.1098: bf16[1024], p247.1101: bf16[1024], p248.1102: bf16[1024,4096], p249.1105: bf16[4096], p250.1106: bf16[4096,1024], p251.1109: bf16[1024], p252.1131: bf16[1024], p253.1134: bf16[1024], p254.1135: bf16[1024,1024], p255.1138: bf16[3072], p256.1139: bf16[3072,1024], p257.1142: bf16[1024], p258.1164: bf16[1024], p259.1167: bf16[1024], p260.1168: bf16[1024,4096], p261.1171: bf16[4096], p262.1172: bf16[4096,1024], p263.1175: bf16[1024], p264.1197: bf16[1024], p265.1200: bf16[1024], p266.1201: bf16[1024,1024], p267.1204: bf16[3072], p268.1205: bf16[3072,1024], p269.1208: bf16[1024], p270.1230: bf16[1024], p271.1233: bf16[1024], p272.1234: bf16[1024,4096], p273.1237: bf16[4096], p274.1238: bf16[4096,1024], p275.1241: bf16[1024], p276.1263: bf16[1024], p277.1266: bf16[1024], p278.1267: bf16[1024,1024], p279.1270: bf16[3072], p280.1271: bf16[3072,1024], p281.1274: bf16[1024], p282.1296: bf16[1024], p283.1299: bf16[1024], p284.1300: bf16[1024,4096], p285.1303: bf16[4096], p286.1304: bf16[4096,1024], p287.1307: bf16[1024], p288.1329: bf16[1024], p289.1332: bf16[1024], p290.1333: bf16[1024,1024], p291.1336: bf16[3072], p292.1337: bf16[3072,1024], p293.1340: bf16[1024], p294.1362: bf16[1024], p295.1365: bf16[1024], p296.1366: bf16[1024,4096], p297.1369: bf16[4096], p298.1370: bf16[4096,1024], p299.1373: bf16[1024], p300.1395: bf16[1024], p301.1398: bf16[1024], p302.1399: bf16[1024,1024], p303.1402: bf16[3072], p304.1403: bf16[3072,1024], p305.1406: bf16[1024], p306.1428: bf16[1024], p307.1431: bf16[1024], p308.1432: bf16[1024,4096], p309.1435: bf16[4096], p310.1436: bf16[4096,1024], p311.1439: bf16[1024], p312.1461: bf16[1024], p313.1464: bf16[1024], p314.1465: bf16[1024,1024], p315.1468: bf16[3072], p316.1469: bf16[3072,1024], p317.1472: bf16[1024], p318.1494: bf16[1024], p319.1497: bf16[1024], p320.1498: bf16[1024,4096], p321.1501: bf16[4096], p322.1502: bf16[4096,1024], p323.1505: bf16[1024], p324.1527: bf16[1024], p325.1530: bf16[1024], p326.1531: bf16[1024,1024], p327.1534: bf16[3072], p328.1535: bf16[3072,1024], p329.1538: bf16[1024], p330.1560: bf16[1024], p331.1563: bf16[1024], p332.1564: bf16[1024,4096], p333.1567: bf16[4096], p334.1568: bf16[4096,1024], p335.1571: bf16[1024], p336.1593: bf16[1024], p337.1596: bf16[1024], p338.1597: bf16[1024,1024], p339.1600: bf16[3072], p340.1601: bf16[3072,1024], p341.1604: bf16[1024], p342.1626: bf16[1024], p343.1629: bf16[1024], p344.1630: bf16[1024,4096], p345.1633: bf16[4096], p346.1634: bf16[4096,1024], p347.1637: bf16[1024], p348.1659: bf16[1024], p349.1662: bf16[1024], p350.1663: bf16[1024,1024], p351.1666: bf16[3072], p352.1667: bf16[3072,1024], p353.1670: bf16[1024], p354.1692: bf16[1024], p355.1695: bf16[1024], p356.1696: bf16[1024,4096], p357.1699: bf16[4096], p358.1700: bf16[4096,1024], p359.1703: bf16[1024], p360.1725: bf16[1024], p361.1728: bf16[1024], p362.1729: bf16[1024,1024], p363.1732: bf16[3072], p364.1733: bf16[3072,1024], p365.1736: bf16[1024], p366.1758: bf16[1024], p367.1761: bf16[1024], p368.1762: bf16[1024,4096], p369.1765: bf16[4096], p370.1766: bf16[4096,1024], p371.1769: bf16[1024], p372.1791: bf16[1024], p373.1794: bf16[1024], p374.1795: bf16[1024,1024], p375.1798: bf16[3072], p376.1799: bf16[3072,1024], p377.1802: bf16[1024], p378.1824: bf16[1024], p379.1827: bf16[1024], p380.1828: bf16[1024,4096], p381.1831: bf16[4096], p382.1832: bf16[4096,1024], p383.1835: bf16[1024], p384.1857: bf16[1024], p385.1860: bf16[1024], p386.1861: bf16[1024,1024], p387.1864: bf16[3072], p388.1865: bf16[3072,1024], p389.1868: bf16[1024], p390.1890: bf16[1024], p391.1893: bf16[1024], p392.1894: bf16[1024,4096], p393.1897: bf16[4096], p394.1898: bf16[4096,1024], p395.1901: bf16[1024], p396.1923: bf16[1024], p397.1926: bf16[1024], p398.1927: bf16[1024,1024], p399.1930: bf16[3072], p400.1931: bf16[3072,1024], p401.1934: bf16[1024], p402.1956: bf16[1024], p403.1959: bf16[1024], p404.1960: bf16[1024,4096], p405.1963: bf16[4096], p406.1964: bf16[4096,1024], p407.1967: bf16[1024], p408.1989: bf16[1024], p409.1992: bf16[1024], p410.1993: bf16[1024,1024], p411.1996: bf16[3072], p412.1997: bf16[3072,1024], p413.2000: bf16[1024], p414.2022: bf16[1024], p415.2025: bf16[1024], p416.2026: bf16[1024,4096], p417.2029: bf16[4096], p418.2030: bf16[4096,1024], p419.2033: bf16[1024], p420.2055: bf16[1024], p421.2058: bf16[1024], p422.2059: bf16[1024,1024], p423.2062: bf16[3072], p424.2063: bf16[3072,1024], p425.2066: bf16[1024], p426.2088: f32[1,1024,32,32], p427.2092: bf16[1,1025,1024], p428.2097: bf16[1024], p429.2098: bf16[1024,3,14,14], p430.2099: bf16[1,3,448,448], p431.2106: bf16[1,1,1024], p432.2120: bf16[1024], p433.2146: f32[], p434.2202: bf16[1024], p435.2250: bf16[1024], p436.2331: bf16[1024], p437.2379: bf16[1024], p438.2460: bf16[1024], p439.2508: bf16[1024], p440.2589: bf16[1024], p441.2637: bf16[1024], p442.2718: bf16[1024], p443.2766: bf16[1024], p444.2847: bf16[1024], p445.2895: bf16[1024], p446.2976: bf16[1024], p447.3024: bf16[1024], p448.3105: bf16[1024], p449.3153: bf16[1024], p450.3234: bf16[1024], p451.3282: bf16[1024], p452.3363: bf16[1024], p453.3411: bf16[1024], p454.3492: bf16[1024], p455.3540: bf16[1024], p456.3621: bf16[1024], p457.3669: bf16[1024], p458.3750: bf16[1024], p459.3798: bf16[1024], p460.3879: bf16[1024], p461.3927: bf16[1024], p462.4008: bf16[1024], p463.4056: bf16[1024], p464.4137: bf16[1024], p465.4185: bf16[1024], p466.4266: bf16[1024], p467.4314: bf16[1024], p468.4395: bf16[1024], p469.4443: bf16[1024], p470.4524: bf16[1024], p471.4572: bf16[1024], p472.4653: bf16[1024], p473.4701: bf16[1024], p474.4782: bf16[1024], p475.4830: bf16[1024], p476.4911: bf16[1024], p477.4959: bf16[1024], p478.5040: bf16[1024], p479.5088: bf16[1024], p480.5169: bf16[1024], p481.5226: bf16[4096], p482.5260: s64[256,1], p483.5263: s64[], p484.5275: s64[1,310], p485.5277: bf16[92553,4096], p486.5321: bf16[4096], p487.5359: f32[], p488.5378: f64[], p489.5381: s64[1,310], p490.5406: bf16[], p491.5441: bf16[32768,128], p492.5470: bf16[32768,128], p493.5591: bf16[4096], p494.5600: bf16[14336,4096], p495.5646: bf16[4096], p496.5683: bf16[32768,128], p497.5712: bf16[32768,128], p498.5833: bf16[4096], p499.5842: bf16[14336,4096], p500.5888: bf16[4096], p501.5925: bf16[32768,128], p502.5954: bf16[32768,128], p503.6075: bf16[4096], p504.6084: bf16[14336,4096], p505.6130: bf16[4096], p506.6167: bf16[32768,128], p507.6196: bf16[32768,128], p508.6317: bf16[4096], p509.6326: bf16[14336,4096], p510.6372: bf16[4096], p511.6409: bf16[32768,128], p512.6438: bf16[32768,128], p513.6559: bf16[4096], p514.6568: bf16[14336,4096], p515.6614: bf16[4096], p516.6651: bf16[32768,128], p517.6680: bf16[32768,128], p518.6801: bf16[4096], p519.6810: bf16[14336,4096], p520.6856: bf16[4096], p521.6893: bf16[32768,128], p522.6922: bf16[32768,128], p523.7043: bf16[4096], p524.7052: bf16[14336,4096], p525.7098: bf16[4096], p526.7135: bf16[32768,128], p527.7164: bf16[32768,128], p528.7285: bf16[4096], p529.7294: bf16[14336,4096], p530.7340: bf16[4096], p531.7377: bf16[32768,128], p532.7406: bf16[32768,128], p533.7527: bf16[4096], p534.7536: bf16[14336,4096], p535.7582: bf16[4096], p536.7619: bf16[32768,128], p537.7648: bf16[32768,128], p538.7769: bf16[4096], p539.7778: bf16[14336,4096], p540.7824: bf16[4096], p541.7861: bf16[32768,128], p542.7890: bf16[32768,128], p543.8011: bf16[4096], p544.8020: bf16[14336,4096], p545.8066: bf16[4096], p546.8103: bf16[32768,128], p547.8132: bf16[32768,128], p548.8253: bf16[4096], p549.8262: bf16[14336,4096], p550.8308: bf16[4096], p551.8345: bf16[32768,128], p552.8374: bf16[32768,128], p553.8495: bf16[4096], p554.8504: bf16[14336,4096], p555.8550: bf16[4096], p556.8587: bf16[32768,128], p557.8616: bf16[32768,128], p558.8737: bf16[4096], p559.8746: bf16[14336,4096], p560.8792: bf16[4096], p561.8829: bf16[32768,128], p562.8858: bf16[32768,128], p563.8979: bf16[4096], p564.8988: bf16[14336,4096], p565.9034: bf16[4096], p566.9071: bf16[32768,128], p567.9100: bf16[32768,128], p568.9221: bf16[4096], p569.9230: bf16[14336,4096], p570.9276: bf16[4096], p571.9313: bf16[32768,128], p572.9342: bf16[32768,128], p573.9463: bf16[4096], p574.9472: bf16[14336,4096], p575.9518: bf16[4096], p576.9555: bf16[32768,128], p577.9584: bf16[32768,128], p578.9705: bf16[4096], p579.9714: bf16[14336,4096], p580.9760: bf16[4096], p581.9797: bf16[32768,128], p582.9826: bf16[32768,128], p583.9947: bf16[4096], p584.9956: bf16[14336,4096], p585.10002: bf16[4096], p586.10039: bf16[32768,128], p587.10068: bf16[32768,128], p588.10189: bf16[4096], p589.10198: bf16[14336,4096], p590.10244: bf16[4096], p591.10281: bf16[32768,128], p592.10310: bf16[32768,128], p593.10431: bf16[4096], p594.10440: bf16[14336,4096], p595.10486: bf16[4096], p596.10523: bf16[32768,128], p597.10552: bf16[32768,128], p598.10673: bf16[4096], p599.10682: bf16[14336,4096], p600.10728: bf16[4096], p601.10765: bf16[32768,128], p602.10794: bf16[32768,128], p603.10915: bf16[4096], p604.10924: bf16[14336,4096], p605.10970: bf16[4096], p606.11007: bf16[32768,128], p607.11036: bf16[32768,128], p608.11157: bf16[4096], p609.11166: bf16[14336,4096], p610.11212: bf16[4096], p611.11249: bf16[32768,128], p612.11278: bf16[32768,128], p613.11399: bf16[4096], p614.11408: bf16[14336,4096], p615.11454: bf16[4096], p616.11491: bf16[32768,128], p617.11520: bf16[32768,128], p618.11641: bf16[4096], p619.11650: bf16[14336,4096], p620.11696: bf16[4096], p621.11733: bf16[32768,128], p622.11762: bf16[32768,128], p623.11883: bf16[4096], p624.11892: bf16[14336,4096], p625.11938: bf16[4096], p626.11975: bf16[32768,128], p627.12004: bf16[32768,128], p628.12125: bf16[4096], p629.12134: bf16[14336,4096], p630.12180: bf16[4096], p631.12217: bf16[32768,128], p632.12246: bf16[32768,128], p633.12367: bf16[4096], p634.12376: bf16[14336,4096], p635.12422: bf16[4096], p636.12459: bf16[32768,128], p637.12488: bf16[32768,128], p638.12609: bf16[4096], p639.12618: bf16[14336,4096], p640.12664: bf16[4096], p641.12701: bf16[32768,128], p642.12730: bf16[32768,128], p643.12851: bf16[4096], p644.12860: bf16[14336,4096], p645.12906: bf16[4096], p646.12943: bf16[32768,128], p647.12972: bf16[32768,128], p648.13093: bf16[4096], p649.13102: bf16[14336,4096], p650.13148: bf16[4096]) -> (s64[1]) {
  %constant.483 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.484 = bf16[1]{0} reshape(bf16[] %constant.483), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.485 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.484), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.486 = bf16[] reshape(bf16[1]{0} %broadcast.485), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.487 = bf16[256]{0} broadcast(bf16[] %reshape.486), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.488 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.489 = bf16[1]{0} reshape(bf16[] %constant.488), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.490 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.489), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.491 = bf16[] reshape(bf16[1]{0} %broadcast.490), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.492 = bf16[256]{0} broadcast(bf16[] %reshape.491), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.516 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.517 = bf16[1]{0} reshape(bf16[] %constant.516), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.518 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.517), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.519 = bf16[] reshape(bf16[1]{0} %broadcast.518), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.520 = bf16[1025]{0} broadcast(bf16[] %reshape.519), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.521 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.522 = bf16[1]{0} reshape(bf16[] %constant.521), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.523 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.522), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.524 = bf16[] reshape(bf16[1]{0} %broadcast.523), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.525 = bf16[1025]{0} broadcast(bf16[] %reshape.524), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.549 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.550 = bf16[1]{0} reshape(bf16[] %constant.549), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.551 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.550), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.552 = bf16[] reshape(bf16[1]{0} %broadcast.551), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.553 = bf16[1025]{0} broadcast(bf16[] %reshape.552), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.554 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.555 = bf16[1]{0} reshape(bf16[] %constant.554), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.556 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.555), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.557 = bf16[] reshape(bf16[1]{0} %broadcast.556), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.558 = bf16[1025]{0} broadcast(bf16[] %reshape.557), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.582 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.583 = bf16[1]{0} reshape(bf16[] %constant.582), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.584 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.583), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.585 = bf16[] reshape(bf16[1]{0} %broadcast.584), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.586 = bf16[1025]{0} broadcast(bf16[] %reshape.585), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.587 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.588 = bf16[1]{0} reshape(bf16[] %constant.587), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.589 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.588), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.590 = bf16[] reshape(bf16[1]{0} %broadcast.589), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.591 = bf16[1025]{0} broadcast(bf16[] %reshape.590), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.615 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.616 = bf16[1]{0} reshape(bf16[] %constant.615), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.617 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.616), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.618 = bf16[] reshape(bf16[1]{0} %broadcast.617), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.619 = bf16[1025]{0} broadcast(bf16[] %reshape.618), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.620 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.621 = bf16[1]{0} reshape(bf16[] %constant.620), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.622 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.621), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.623 = bf16[] reshape(bf16[1]{0} %broadcast.622), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.624 = bf16[1025]{0} broadcast(bf16[] %reshape.623), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.648 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.649 = bf16[1]{0} reshape(bf16[] %constant.648), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.650 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.649), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.651 = bf16[] reshape(bf16[1]{0} %broadcast.650), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.652 = bf16[1025]{0} broadcast(bf16[] %reshape.651), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.653 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.654 = bf16[1]{0} reshape(bf16[] %constant.653), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.655 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.654), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.656 = bf16[] reshape(bf16[1]{0} %broadcast.655), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.657 = bf16[1025]{0} broadcast(bf16[] %reshape.656), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.681 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.682 = bf16[1]{0} reshape(bf16[] %constant.681), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.683 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.682), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.684 = bf16[] reshape(bf16[1]{0} %broadcast.683), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.685 = bf16[1025]{0} broadcast(bf16[] %reshape.684), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.686 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.687 = bf16[1]{0} reshape(bf16[] %constant.686), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.688 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.687), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.689 = bf16[] reshape(bf16[1]{0} %broadcast.688), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.690 = bf16[1025]{0} broadcast(bf16[] %reshape.689), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.714 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.715 = bf16[1]{0} reshape(bf16[] %constant.714), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.716 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.715), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.717 = bf16[] reshape(bf16[1]{0} %broadcast.716), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.718 = bf16[1025]{0} broadcast(bf16[] %reshape.717), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.719 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.720 = bf16[1]{0} reshape(bf16[] %constant.719), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.721 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.720), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.722 = bf16[] reshape(bf16[1]{0} %broadcast.721), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.723 = bf16[1025]{0} broadcast(bf16[] %reshape.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.747 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.748 = bf16[1]{0} reshape(bf16[] %constant.747), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.749 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.748), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.750 = bf16[] reshape(bf16[1]{0} %broadcast.749), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.751 = bf16[1025]{0} broadcast(bf16[] %reshape.750), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.752 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.753 = bf16[1]{0} reshape(bf16[] %constant.752), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.754 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.753), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.755 = bf16[] reshape(bf16[1]{0} %broadcast.754), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.756 = bf16[1025]{0} broadcast(bf16[] %reshape.755), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.780 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.781 = bf16[1]{0} reshape(bf16[] %constant.780), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.782 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.781), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.783 = bf16[] reshape(bf16[1]{0} %broadcast.782), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.784 = bf16[1025]{0} broadcast(bf16[] %reshape.783), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.785 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.786 = bf16[1]{0} reshape(bf16[] %constant.785), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.787 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.786), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.788 = bf16[] reshape(bf16[1]{0} %broadcast.787), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.789 = bf16[1025]{0} broadcast(bf16[] %reshape.788), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.813 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.814 = bf16[1]{0} reshape(bf16[] %constant.813), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.815 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.814), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.816 = bf16[] reshape(bf16[1]{0} %broadcast.815), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.817 = bf16[1025]{0} broadcast(bf16[] %reshape.816), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.818 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.819 = bf16[1]{0} reshape(bf16[] %constant.818), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.820 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.819), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.821 = bf16[] reshape(bf16[1]{0} %broadcast.820), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.822 = bf16[1025]{0} broadcast(bf16[] %reshape.821), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.846 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.847 = bf16[1]{0} reshape(bf16[] %constant.846), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.848 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.847), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.849 = bf16[] reshape(bf16[1]{0} %broadcast.848), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.850 = bf16[1025]{0} broadcast(bf16[] %reshape.849), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.851 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.852 = bf16[1]{0} reshape(bf16[] %constant.851), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.853 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.852), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.854 = bf16[] reshape(bf16[1]{0} %broadcast.853), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.855 = bf16[1025]{0} broadcast(bf16[] %reshape.854), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.879 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.880 = bf16[1]{0} reshape(bf16[] %constant.879), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.881 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.880), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.882 = bf16[] reshape(bf16[1]{0} %broadcast.881), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.883 = bf16[1025]{0} broadcast(bf16[] %reshape.882), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.884 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.885 = bf16[1]{0} reshape(bf16[] %constant.884), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.886 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.885), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.887 = bf16[] reshape(bf16[1]{0} %broadcast.886), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.888 = bf16[1025]{0} broadcast(bf16[] %reshape.887), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.912 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.913 = bf16[1]{0} reshape(bf16[] %constant.912), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.914 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.913), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.915 = bf16[] reshape(bf16[1]{0} %broadcast.914), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.916 = bf16[1025]{0} broadcast(bf16[] %reshape.915), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.917 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.918 = bf16[1]{0} reshape(bf16[] %constant.917), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.919 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.918), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.920 = bf16[] reshape(bf16[1]{0} %broadcast.919), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.921 = bf16[1025]{0} broadcast(bf16[] %reshape.920), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.945 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.946 = bf16[1]{0} reshape(bf16[] %constant.945), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.947 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.946), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.948 = bf16[] reshape(bf16[1]{0} %broadcast.947), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.949 = bf16[1025]{0} broadcast(bf16[] %reshape.948), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.950 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.951 = bf16[1]{0} reshape(bf16[] %constant.950), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.952 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.951), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.953 = bf16[] reshape(bf16[1]{0} %broadcast.952), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.954 = bf16[1025]{0} broadcast(bf16[] %reshape.953), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.978 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.979 = bf16[1]{0} reshape(bf16[] %constant.978), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.980 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.979), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.981 = bf16[] reshape(bf16[1]{0} %broadcast.980), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.982 = bf16[1025]{0} broadcast(bf16[] %reshape.981), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.983 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.984 = bf16[1]{0} reshape(bf16[] %constant.983), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.985 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.984), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.986 = bf16[] reshape(bf16[1]{0} %broadcast.985), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.987 = bf16[1025]{0} broadcast(bf16[] %reshape.986), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1011 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1012 = bf16[1]{0} reshape(bf16[] %constant.1011), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1013 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1012), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1014 = bf16[] reshape(bf16[1]{0} %broadcast.1013), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1015 = bf16[1025]{0} broadcast(bf16[] %reshape.1014), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1016 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1017 = bf16[1]{0} reshape(bf16[] %constant.1016), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1018 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1017), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1019 = bf16[] reshape(bf16[1]{0} %broadcast.1018), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1020 = bf16[1025]{0} broadcast(bf16[] %reshape.1019), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1044 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1045 = bf16[1]{0} reshape(bf16[] %constant.1044), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1046 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1045), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1047 = bf16[] reshape(bf16[1]{0} %broadcast.1046), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1048 = bf16[1025]{0} broadcast(bf16[] %reshape.1047), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1049 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1050 = bf16[1]{0} reshape(bf16[] %constant.1049), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1051 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1050), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1052 = bf16[] reshape(bf16[1]{0} %broadcast.1051), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1053 = bf16[1025]{0} broadcast(bf16[] %reshape.1052), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1077 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1078 = bf16[1]{0} reshape(bf16[] %constant.1077), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1079 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1078), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1080 = bf16[] reshape(bf16[1]{0} %broadcast.1079), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1081 = bf16[1025]{0} broadcast(bf16[] %reshape.1080), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1082 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1083 = bf16[1]{0} reshape(bf16[] %constant.1082), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1084 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1083), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1085 = bf16[] reshape(bf16[1]{0} %broadcast.1084), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1086 = bf16[1025]{0} broadcast(bf16[] %reshape.1085), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1110 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1111 = bf16[1]{0} reshape(bf16[] %constant.1110), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1112 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1111), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1113 = bf16[] reshape(bf16[1]{0} %broadcast.1112), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1114 = bf16[1025]{0} broadcast(bf16[] %reshape.1113), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1115 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1116 = bf16[1]{0} reshape(bf16[] %constant.1115), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1117 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1116), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1118 = bf16[] reshape(bf16[1]{0} %broadcast.1117), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1119 = bf16[1025]{0} broadcast(bf16[] %reshape.1118), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1143 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1144 = bf16[1]{0} reshape(bf16[] %constant.1143), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1145 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1144), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1146 = bf16[] reshape(bf16[1]{0} %broadcast.1145), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1147 = bf16[1025]{0} broadcast(bf16[] %reshape.1146), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1148 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1149 = bf16[1]{0} reshape(bf16[] %constant.1148), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1150 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1149), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1151 = bf16[] reshape(bf16[1]{0} %broadcast.1150), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1152 = bf16[1025]{0} broadcast(bf16[] %reshape.1151), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1176 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1177 = bf16[1]{0} reshape(bf16[] %constant.1176), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1178 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1177), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1179 = bf16[] reshape(bf16[1]{0} %broadcast.1178), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1180 = bf16[1025]{0} broadcast(bf16[] %reshape.1179), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1181 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1182 = bf16[1]{0} reshape(bf16[] %constant.1181), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1183 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1182), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1184 = bf16[] reshape(bf16[1]{0} %broadcast.1183), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1185 = bf16[1025]{0} broadcast(bf16[] %reshape.1184), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1209 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1210 = bf16[1]{0} reshape(bf16[] %constant.1209), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1211 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1210), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1212 = bf16[] reshape(bf16[1]{0} %broadcast.1211), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1213 = bf16[1025]{0} broadcast(bf16[] %reshape.1212), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1214 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1215 = bf16[1]{0} reshape(bf16[] %constant.1214), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1216 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1215), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1217 = bf16[] reshape(bf16[1]{0} %broadcast.1216), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1218 = bf16[1025]{0} broadcast(bf16[] %reshape.1217), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1242 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1243 = bf16[1]{0} reshape(bf16[] %constant.1242), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1244 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1243), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1245 = bf16[] reshape(bf16[1]{0} %broadcast.1244), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1246 = bf16[1025]{0} broadcast(bf16[] %reshape.1245), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1247 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1248 = bf16[1]{0} reshape(bf16[] %constant.1247), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1249 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1248), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1250 = bf16[] reshape(bf16[1]{0} %broadcast.1249), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1251 = bf16[1025]{0} broadcast(bf16[] %reshape.1250), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1275 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1276 = bf16[1]{0} reshape(bf16[] %constant.1275), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1277 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1276), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1278 = bf16[] reshape(bf16[1]{0} %broadcast.1277), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1279 = bf16[1025]{0} broadcast(bf16[] %reshape.1278), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1280 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1281 = bf16[1]{0} reshape(bf16[] %constant.1280), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1282 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1281), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1283 = bf16[] reshape(bf16[1]{0} %broadcast.1282), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1284 = bf16[1025]{0} broadcast(bf16[] %reshape.1283), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1308 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1309 = bf16[1]{0} reshape(bf16[] %constant.1308), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1310 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1309), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1311 = bf16[] reshape(bf16[1]{0} %broadcast.1310), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1312 = bf16[1025]{0} broadcast(bf16[] %reshape.1311), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1313 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1314 = bf16[1]{0} reshape(bf16[] %constant.1313), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1315 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1314), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1316 = bf16[] reshape(bf16[1]{0} %broadcast.1315), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1317 = bf16[1025]{0} broadcast(bf16[] %reshape.1316), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1341 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1342 = bf16[1]{0} reshape(bf16[] %constant.1341), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1343 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1342), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1344 = bf16[] reshape(bf16[1]{0} %broadcast.1343), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1345 = bf16[1025]{0} broadcast(bf16[] %reshape.1344), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1346 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1347 = bf16[1]{0} reshape(bf16[] %constant.1346), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1348 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1347), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1349 = bf16[] reshape(bf16[1]{0} %broadcast.1348), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1350 = bf16[1025]{0} broadcast(bf16[] %reshape.1349), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1374 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1375 = bf16[1]{0} reshape(bf16[] %constant.1374), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1376 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1375), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1377 = bf16[] reshape(bf16[1]{0} %broadcast.1376), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1378 = bf16[1025]{0} broadcast(bf16[] %reshape.1377), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1379 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1380 = bf16[1]{0} reshape(bf16[] %constant.1379), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1381 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1380), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1382 = bf16[] reshape(bf16[1]{0} %broadcast.1381), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1383 = bf16[1025]{0} broadcast(bf16[] %reshape.1382), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1407 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1408 = bf16[1]{0} reshape(bf16[] %constant.1407), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1409 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1408), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1410 = bf16[] reshape(bf16[1]{0} %broadcast.1409), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1411 = bf16[1025]{0} broadcast(bf16[] %reshape.1410), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1412 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1413 = bf16[1]{0} reshape(bf16[] %constant.1412), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1414 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1413), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1415 = bf16[] reshape(bf16[1]{0} %broadcast.1414), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1416 = bf16[1025]{0} broadcast(bf16[] %reshape.1415), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1440 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1441 = bf16[1]{0} reshape(bf16[] %constant.1440), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1442 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1441), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1443 = bf16[] reshape(bf16[1]{0} %broadcast.1442), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1444 = bf16[1025]{0} broadcast(bf16[] %reshape.1443), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1445 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1446 = bf16[1]{0} reshape(bf16[] %constant.1445), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1447 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1446), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1448 = bf16[] reshape(bf16[1]{0} %broadcast.1447), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1449 = bf16[1025]{0} broadcast(bf16[] %reshape.1448), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1473 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1474 = bf16[1]{0} reshape(bf16[] %constant.1473), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1475 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1474), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1476 = bf16[] reshape(bf16[1]{0} %broadcast.1475), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1477 = bf16[1025]{0} broadcast(bf16[] %reshape.1476), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1478 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1479 = bf16[1]{0} reshape(bf16[] %constant.1478), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1480 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1479), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1481 = bf16[] reshape(bf16[1]{0} %broadcast.1480), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1482 = bf16[1025]{0} broadcast(bf16[] %reshape.1481), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1506 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1507 = bf16[1]{0} reshape(bf16[] %constant.1506), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1508 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1507), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1509 = bf16[] reshape(bf16[1]{0} %broadcast.1508), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1510 = bf16[1025]{0} broadcast(bf16[] %reshape.1509), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1511 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1512 = bf16[1]{0} reshape(bf16[] %constant.1511), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1513 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1512), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1514 = bf16[] reshape(bf16[1]{0} %broadcast.1513), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1515 = bf16[1025]{0} broadcast(bf16[] %reshape.1514), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1539 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1540 = bf16[1]{0} reshape(bf16[] %constant.1539), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1541 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1540), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1542 = bf16[] reshape(bf16[1]{0} %broadcast.1541), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1543 = bf16[1025]{0} broadcast(bf16[] %reshape.1542), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1544 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1545 = bf16[1]{0} reshape(bf16[] %constant.1544), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1546 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1545), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1547 = bf16[] reshape(bf16[1]{0} %broadcast.1546), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1548 = bf16[1025]{0} broadcast(bf16[] %reshape.1547), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1572 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1573 = bf16[1]{0} reshape(bf16[] %constant.1572), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1574 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1573), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1575 = bf16[] reshape(bf16[1]{0} %broadcast.1574), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1576 = bf16[1025]{0} broadcast(bf16[] %reshape.1575), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1577 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1578 = bf16[1]{0} reshape(bf16[] %constant.1577), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1579 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1578), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1580 = bf16[] reshape(bf16[1]{0} %broadcast.1579), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1581 = bf16[1025]{0} broadcast(bf16[] %reshape.1580), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1605 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1606 = bf16[1]{0} reshape(bf16[] %constant.1605), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1607 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1606), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1608 = bf16[] reshape(bf16[1]{0} %broadcast.1607), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1609 = bf16[1025]{0} broadcast(bf16[] %reshape.1608), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1610 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1611 = bf16[1]{0} reshape(bf16[] %constant.1610), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1612 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1611), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1613 = bf16[] reshape(bf16[1]{0} %broadcast.1612), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1614 = bf16[1025]{0} broadcast(bf16[] %reshape.1613), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1638 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1639 = bf16[1]{0} reshape(bf16[] %constant.1638), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1640 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1639), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1641 = bf16[] reshape(bf16[1]{0} %broadcast.1640), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1642 = bf16[1025]{0} broadcast(bf16[] %reshape.1641), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1643 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1644 = bf16[1]{0} reshape(bf16[] %constant.1643), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1645 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1644), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1646 = bf16[] reshape(bf16[1]{0} %broadcast.1645), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1647 = bf16[1025]{0} broadcast(bf16[] %reshape.1646), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1671 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1672 = bf16[1]{0} reshape(bf16[] %constant.1671), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1673 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1672), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1674 = bf16[] reshape(bf16[1]{0} %broadcast.1673), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1675 = bf16[1025]{0} broadcast(bf16[] %reshape.1674), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1676 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1677 = bf16[1]{0} reshape(bf16[] %constant.1676), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1678 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1677), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1679 = bf16[] reshape(bf16[1]{0} %broadcast.1678), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1680 = bf16[1025]{0} broadcast(bf16[] %reshape.1679), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1704 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1705 = bf16[1]{0} reshape(bf16[] %constant.1704), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1706 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1705), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1707 = bf16[] reshape(bf16[1]{0} %broadcast.1706), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1708 = bf16[1025]{0} broadcast(bf16[] %reshape.1707), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1709 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1710 = bf16[1]{0} reshape(bf16[] %constant.1709), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1711 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1710), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1712 = bf16[] reshape(bf16[1]{0} %broadcast.1711), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1713 = bf16[1025]{0} broadcast(bf16[] %reshape.1712), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1737 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1738 = bf16[1]{0} reshape(bf16[] %constant.1737), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1739 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1738), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1740 = bf16[] reshape(bf16[1]{0} %broadcast.1739), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1741 = bf16[1025]{0} broadcast(bf16[] %reshape.1740), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1742 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1743 = bf16[1]{0} reshape(bf16[] %constant.1742), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1744 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1743), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1745 = bf16[] reshape(bf16[1]{0} %broadcast.1744), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1746 = bf16[1025]{0} broadcast(bf16[] %reshape.1745), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1770 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1771 = bf16[1]{0} reshape(bf16[] %constant.1770), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1772 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1771), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1773 = bf16[] reshape(bf16[1]{0} %broadcast.1772), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1774 = bf16[1025]{0} broadcast(bf16[] %reshape.1773), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1775 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1776 = bf16[1]{0} reshape(bf16[] %constant.1775), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1777 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1776), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1778 = bf16[] reshape(bf16[1]{0} %broadcast.1777), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1779 = bf16[1025]{0} broadcast(bf16[] %reshape.1778), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1803 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1804 = bf16[1]{0} reshape(bf16[] %constant.1803), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1805 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1804), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1806 = bf16[] reshape(bf16[1]{0} %broadcast.1805), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1807 = bf16[1025]{0} broadcast(bf16[] %reshape.1806), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1808 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1809 = bf16[1]{0} reshape(bf16[] %constant.1808), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1810 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1809), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1811 = bf16[] reshape(bf16[1]{0} %broadcast.1810), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1812 = bf16[1025]{0} broadcast(bf16[] %reshape.1811), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1836 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1837 = bf16[1]{0} reshape(bf16[] %constant.1836), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1838 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1837), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1839 = bf16[] reshape(bf16[1]{0} %broadcast.1838), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1840 = bf16[1025]{0} broadcast(bf16[] %reshape.1839), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1841 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1842 = bf16[1]{0} reshape(bf16[] %constant.1841), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1843 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1842), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1844 = bf16[] reshape(bf16[1]{0} %broadcast.1843), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1845 = bf16[1025]{0} broadcast(bf16[] %reshape.1844), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1869 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1870 = bf16[1]{0} reshape(bf16[] %constant.1869), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1871 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1870), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1872 = bf16[] reshape(bf16[1]{0} %broadcast.1871), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1873 = bf16[1025]{0} broadcast(bf16[] %reshape.1872), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1874 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1875 = bf16[1]{0} reshape(bf16[] %constant.1874), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1876 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1875), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1877 = bf16[] reshape(bf16[1]{0} %broadcast.1876), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1878 = bf16[1025]{0} broadcast(bf16[] %reshape.1877), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1902 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1903 = bf16[1]{0} reshape(bf16[] %constant.1902), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1904 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1903), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1905 = bf16[] reshape(bf16[1]{0} %broadcast.1904), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1906 = bf16[1025]{0} broadcast(bf16[] %reshape.1905), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1907 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1908 = bf16[1]{0} reshape(bf16[] %constant.1907), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1909 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1908), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1910 = bf16[] reshape(bf16[1]{0} %broadcast.1909), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1911 = bf16[1025]{0} broadcast(bf16[] %reshape.1910), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1935 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1936 = bf16[1]{0} reshape(bf16[] %constant.1935), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1937 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1936), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1938 = bf16[] reshape(bf16[1]{0} %broadcast.1937), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1939 = bf16[1025]{0} broadcast(bf16[] %reshape.1938), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1940 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1941 = bf16[1]{0} reshape(bf16[] %constant.1940), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1942 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1941), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1943 = bf16[] reshape(bf16[1]{0} %broadcast.1942), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1944 = bf16[1025]{0} broadcast(bf16[] %reshape.1943), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1968 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1969 = bf16[1]{0} reshape(bf16[] %constant.1968), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1970 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1969), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1971 = bf16[] reshape(bf16[1]{0} %broadcast.1970), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1972 = bf16[1025]{0} broadcast(bf16[] %reshape.1971), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1973 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1974 = bf16[1]{0} reshape(bf16[] %constant.1973), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1975 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1974), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1976 = bf16[] reshape(bf16[1]{0} %broadcast.1975), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1977 = bf16[1025]{0} broadcast(bf16[] %reshape.1976), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2001 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2002 = bf16[1]{0} reshape(bf16[] %constant.2001), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2003 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2002), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2004 = bf16[] reshape(bf16[1]{0} %broadcast.2003), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2005 = bf16[1025]{0} broadcast(bf16[] %reshape.2004), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2006 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2007 = bf16[1]{0} reshape(bf16[] %constant.2006), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2008 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2007), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2009 = bf16[] reshape(bf16[1]{0} %broadcast.2008), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2010 = bf16[1025]{0} broadcast(bf16[] %reshape.2009), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2034 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2035 = bf16[1]{0} reshape(bf16[] %constant.2034), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2036 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2035), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2037 = bf16[] reshape(bf16[1]{0} %broadcast.2036), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2038 = bf16[1025]{0} broadcast(bf16[] %reshape.2037), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2039 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2040 = bf16[1]{0} reshape(bf16[] %constant.2039), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2041 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2040), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2042 = bf16[] reshape(bf16[1]{0} %broadcast.2041), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2043 = bf16[1025]{0} broadcast(bf16[] %reshape.2042), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2067 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2068 = bf16[1]{0} reshape(bf16[] %constant.2067), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2069 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2068), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2070 = bf16[] reshape(bf16[1]{0} %broadcast.2069), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2071 = bf16[1025]{0} broadcast(bf16[] %reshape.2070), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2072 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2073 = bf16[1]{0} reshape(bf16[] %constant.2072), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2074 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2073), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2075 = bf16[] reshape(bf16[1]{0} %broadcast.2074), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2076 = bf16[1025]{0} broadcast(bf16[] %reshape.2075), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p431.2106 = bf16[1,1,1024]{2,1,0} parameter(431), sharding={devices=[1,1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2107 = bf16[1,1,1024]{2,1,0} broadcast(bf16[1,1,1024]{2,1,0} %p431.2106), dimensions={0,1,2}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=166}
  %p430.2099 = bf16[1,3,448,448]{3,2,1,0} parameter(430), sharding={devices=[1,1,8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %p429.2098 = bf16[1024,3,14,14]{0,3,2,1} parameter(429), sharding={devices=[8,1,1,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convolution.2100 = bf16[1,1024,32,32]{3,2,1,0} convolution(bf16[1,3,448,448]{3,2,1,0} %p430.2099, bf16[1024,3,14,14]{0,3,2,1} %p429.2098), window={size=14x14 stride=14x14}, dim_labels=bf01_oi01->bf01, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py" source_line=549}
  %p428.2097 = bf16[1024]{0} parameter(428), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2101 = bf16[1,32,32,1024]{3,2,1,0} broadcast(bf16[1024]{0} %p428.2097), dimensions={3}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py" source_line=549}
  %transpose.2102 = bf16[1,1024,32,32]{1,3,2,0} transpose(bf16[1,32,32,1024]{3,2,1,0} %broadcast.2101), dimensions={0,3,1,2}, metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py" source_line=549}
  %add.2103 = bf16[1,1024,32,32]{3,2,1,0} add(bf16[1,1024,32,32]{3,2,1,0} %convolution.2100, bf16[1,1024,32,32]{1,3,2,0} %transpose.2102), metadata={op_type="aten__convolution_overrideable" op_name="aten__convolution_overrideable" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py" source_line=549}
  %reshape.2104 = bf16[1,1024,1024]{2,1,0} reshape(bf16[1,1024,32,32]{3,2,1,0} %add.2103), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=165}
  %transpose.2105 = bf16[1,1024,1024]{1,2,0} transpose(bf16[1,1024,1024]{2,1,0} %reshape.2104), dimensions={0,2,1}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=165}
  %concatenate.2108 = bf16[1,1025,1024]{2,1,0} concatenate(bf16[1,1,1024]{2,1,0} %broadcast.2107, bf16[1,1024,1024]{1,2,0} %transpose.2105), dimensions={1}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=167}
  %p427.2092 = bf16[1,1025,1024]{2,1,0} parameter(427), sharding={devices=[1,8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %slice.2093 = bf16[1,1025,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %p427.2092), slice={[0:1], [0:1025], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=169}
  %slice.2094 = bf16[1,1,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %slice.2093), slice={[0:1], [0:1], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=169}
  %slice.2095 = bf16[1,1,1024]{2,1,0} slice(bf16[1,1,1024]{2,1,0} %slice.2094), slice={[0:1], [0:1], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=169}
  %p426.2088 = f32[1,1024,32,32]{1,3,2,0} parameter(426), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=158}
  %reshape.2089 = f32[1,1024,1024]{2,1,0} reshape(f32[1,1024,32,32]{1,3,2,0} %p426.2088), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=158}
  %transpose.2090 = f32[1,1024,1024]{1,2,0} transpose(f32[1,1024,1024]{2,1,0} %reshape.2089), dimensions={0,2,1}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=158}
  %convert.2091 = bf16[1,1024,1024]{1,2,0} convert(f32[1,1024,1024]{1,2,0} %transpose.2090), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=158}
  %concatenate.2096 = bf16[1,1025,1024]{2,1,0} concatenate(bf16[1,1,1024]{2,1,0} %slice.2095, bf16[1,1024,1024]{1,2,0} %convert.2091), dimensions={1}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=168}
  %constant.2087 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=172}
  %broadcast.2109 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.2087), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.1/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=172}
  %multiply.2110 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %concatenate.2096, bf16[1,1025,1024]{2,1,0} %broadcast.2109), metadata={op_type="aten__add" op_name="aten__add.1/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=172}
  %add.2111 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %concatenate.2108, bf16[1,1025,1024]{2,1,0} %multiply.2110), metadata={op_type="aten__add" op_name="aten__add.1/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=172}
  %constant.2082 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2083 = bf16[1]{0} reshape(bf16[] %constant.2082), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2084 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2083), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2085 = bf16[] reshape(bf16[1]{0} %broadcast.2084), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2086 = bf16[1025]{0} broadcast(bf16[] %reshape.2085), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2077 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2078 = bf16[1]{0} reshape(bf16[] %constant.2077), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2079 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2078), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2080 = bf16[] reshape(bf16[1]{0} %broadcast.2079), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2081 = bf16[1025]{0} broadcast(bf16[] %reshape.2080), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2112 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2111, bf16[1025]{0} %broadcast.2086, bf16[1025]{0} %broadcast.2081), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2114 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2112), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2115 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2112), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2116 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2117 = bf16[1025]{0} broadcast(bf16[] %constant.2116), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2118 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2115, bf16[1025]{0} %broadcast.2117), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2119 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2118), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p432.2120 = bf16[1024]{0} parameter(432), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2126 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p432.2120), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2113 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2112), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p425.2066 = bf16[1024]{0} parameter(425), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2122 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p425.2066), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2123 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2113, bf16[1,1025,1024]{2,1,0} %broadcast.2122), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2065 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2121 = bf16[] convert(s64[] %constant.2065), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2124 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2121), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2125 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2123, bf16[1,1025,1024]{2,1,0} %broadcast.2124), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2127 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2126, bf16[1,1025,1024]{2,1,0} %multiply.2125), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2128 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2127), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p424.2063 = bf16[3072,1024]{1,0} parameter(424), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.2064 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p424.2063), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2129 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2128, bf16[1024,3072]{0,1} %transpose.2064), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2130 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2129), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p423.2062 = bf16[3072]{0} parameter(423), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.2061 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2131 = bf16[3072]{0} broadcast(bf16[] %constant.2061), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.2/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2132 = bf16[3072]{0} multiply(bf16[3072]{0} %p423.2062, bf16[3072]{0} %broadcast.2131), metadata={op_type="aten__add" op_name="aten__add.2/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2133 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2132), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.2/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2134 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2130, bf16[1,1025,3072]{2,1,0} %broadcast.2133), metadata={op_type="aten__add" op_name="aten__add.2/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2135 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2134), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2136 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2135), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2147 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2136), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2148 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2147), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2149 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2148), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %p433.2146 = f32[] parameter(433), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2150 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.3/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2151 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2149, f32[1,16,1025,64]{3,2,1,0} %broadcast.2150), metadata={op_type="aten__mul" op_name="aten__mul.3/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2152 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2151), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2153 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2152), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2154 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2153), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2141 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2136), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2142 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2141), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2143 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2142), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2144 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2143), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2145 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2144), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2155 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2154, bf16[16,64,1025]{2,1,0} %reshape.2145), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2156 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2155), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2157 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2162 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2156, bf16[] %constant.2157), dimensions={3}, to_apply=%MaxComputation.2158, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2163 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2162), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2164 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2156, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2163), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2165 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2164), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2166 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2171 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2165, bf16[] %constant.2166), dimensions={3}, to_apply=%AddComputation.2167, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2172 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2171), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2173 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2165, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2172), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2174 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2173), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2175 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2174), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2137 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2136), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2138 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2137), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2139 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2138), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2140 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2139), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2176 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2175, bf16[16,1025,64]{2,1,0} %reshape.2140), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2177 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2176), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2178 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2177), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2179 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2178), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2180 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2179), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p422.2059 = bf16[1024,1024]{1,0} parameter(422), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.2060 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p422.2059), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2181 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2180, bf16[1024,1024]{0,1} %transpose.2060), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2182 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2181), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p421.2058 = bf16[1024]{0} parameter(421), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.2057 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2183 = bf16[1024]{0} broadcast(bf16[] %constant.2057), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.4/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2184 = bf16[1024]{0} multiply(bf16[1024]{0} %p421.2058, bf16[1024]{0} %broadcast.2183), metadata={op_type="aten__add" op_name="aten__add.4/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2185 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2184), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.4/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2186 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2182, bf16[1,1025,1024]{2,1,0} %broadcast.2185), metadata={op_type="aten__add" op_name="aten__add.4/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2187 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2186), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p420.2055 = bf16[1024]{0} parameter(420), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.2056 = f32[1024]{0} convert(bf16[1024]{0} %p420.2055), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2188 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.2056), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.5/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2189 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2187, f32[1,1025,1024]{2,1,0} %broadcast.2188), metadata={op_type="aten__mul" op_name="aten__mul.5/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2190 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2189), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.2054 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2191 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.2054), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.6/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2192 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2190, bf16[1,1025,1024]{2,1,0} %broadcast.2191), metadata={op_type="aten__add" op_name="aten__add.6/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2193 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2111, bf16[1,1025,1024]{2,1,0} %multiply.2192), metadata={op_type="aten__add" op_name="aten__add.6/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.2049 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2050 = bf16[1]{0} reshape(bf16[] %constant.2049), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2051 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2050), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2052 = bf16[] reshape(bf16[1]{0} %broadcast.2051), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2053 = bf16[1025]{0} broadcast(bf16[] %reshape.2052), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2044 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2045 = bf16[1]{0} reshape(bf16[] %constant.2044), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2046 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2045), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2047 = bf16[] reshape(bf16[1]{0} %broadcast.2046), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2048 = bf16[1025]{0} broadcast(bf16[] %reshape.2047), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2194 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2193, bf16[1025]{0} %broadcast.2053, bf16[1025]{0} %broadcast.2048), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2196 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2194), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2197 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2194), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2198 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2199 = bf16[1025]{0} broadcast(bf16[] %constant.2198), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2200 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2197, bf16[1025]{0} %broadcast.2199), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2201 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2200), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p434.2202 = bf16[1024]{0} parameter(434), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2208 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p434.2202), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2195 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2194), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p419.2033 = bf16[1024]{0} parameter(419), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2204 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p419.2033), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2205 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2195, bf16[1,1025,1024]{2,1,0} %broadcast.2204), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2032 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2203 = bf16[] convert(s64[] %constant.2032), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2206 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2203), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2207 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2205, bf16[1,1025,1024]{2,1,0} %broadcast.2206), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2209 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2208, bf16[1,1025,1024]{2,1,0} %multiply.2207), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2210 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2209), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p418.2030 = bf16[4096,1024]{1,0} parameter(418), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.2031 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p418.2030), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2211 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2210, bf16[1024,4096]{0,1} %transpose.2031), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2212 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2211), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p417.2029 = bf16[4096]{0} parameter(417), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.2028 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2213 = bf16[4096]{0} broadcast(bf16[] %constant.2028), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.7/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2214 = bf16[4096]{0} multiply(bf16[4096]{0} %p417.2029, bf16[4096]{0} %broadcast.2213), metadata={op_type="aten__add" op_name="aten__add.7/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2215 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2214), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.7/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2216 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2212, bf16[1,1025,4096]{2,1,0} %broadcast.2215), metadata={op_type="aten__add" op_name="aten__add.7/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2217 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2225 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2217), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2226 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2216, bf16[1,1025,4096]{2,1,0} %broadcast.2225), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2219 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2220 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2219), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2221 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2216, bf16[1,1025,4096]{2,1,0} %broadcast.2220), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2222 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2221), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2218 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2223 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2218), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2224 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2222, bf16[1,1025,4096]{2,1,0} %broadcast.2223), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2227 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2226, bf16[1,1025,4096]{2,1,0} %add.2224), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2228 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2227), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p416.2026 = bf16[1024,4096]{1,0} parameter(416), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.2027 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p416.2026), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2229 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2228, bf16[4096,1024]{0,1} %transpose.2027), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2230 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2229), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p415.2025 = bf16[1024]{0} parameter(415), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.2024 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2231 = bf16[1024]{0} broadcast(bf16[] %constant.2024), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.8/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2232 = bf16[1024]{0} multiply(bf16[1024]{0} %p415.2025, bf16[1024]{0} %broadcast.2231), metadata={op_type="aten__add" op_name="aten__add.8/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2233 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2232), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.8/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2234 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2230, bf16[1,1025,1024]{2,1,0} %broadcast.2233), metadata={op_type="aten__add" op_name="aten__add.8/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2235 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2234), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p414.2022 = bf16[1024]{0} parameter(414), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.2023 = f32[1024]{0} convert(bf16[1024]{0} %p414.2022), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2236 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.2023), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.9/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2237 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2235, f32[1,1025,1024]{2,1,0} %broadcast.2236), metadata={op_type="aten__mul" op_name="aten__mul.9/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2238 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2237), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.2021 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2239 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.2021), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.10/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2240 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2238, bf16[1,1025,1024]{2,1,0} %broadcast.2239), metadata={op_type="aten__add" op_name="aten__add.10/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2241 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2193, bf16[1,1025,1024]{2,1,0} %multiply.2240), metadata={op_type="aten__add" op_name="aten__add.10/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.2016 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2017 = bf16[1]{0} reshape(bf16[] %constant.2016), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2018 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2017), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2019 = bf16[] reshape(bf16[1]{0} %broadcast.2018), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2020 = bf16[1025]{0} broadcast(bf16[] %reshape.2019), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2011 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2012 = bf16[1]{0} reshape(bf16[] %constant.2011), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2013 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.2012), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2014 = bf16[] reshape(bf16[1]{0} %broadcast.2013), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2015 = bf16[1025]{0} broadcast(bf16[] %reshape.2014), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2242 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2241, bf16[1025]{0} %broadcast.2020, bf16[1025]{0} %broadcast.2015), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2244 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2242), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2245 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2242), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2246 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2247 = bf16[1025]{0} broadcast(bf16[] %constant.2246), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2248 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2245, bf16[1025]{0} %broadcast.2247), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2249 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2248), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p435.2250 = bf16[1024]{0} parameter(435), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2256 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p435.2250), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2243 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2242), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p413.2000 = bf16[1024]{0} parameter(413), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2252 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p413.2000), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2253 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2243, bf16[1,1025,1024]{2,1,0} %broadcast.2252), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1999 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2251 = bf16[] convert(s64[] %constant.1999), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2254 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2251), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2255 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2253, bf16[1,1025,1024]{2,1,0} %broadcast.2254), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2257 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2256, bf16[1,1025,1024]{2,1,0} %multiply.2255), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2258 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2257), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p412.1997 = bf16[3072,1024]{1,0} parameter(412), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1998 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p412.1997), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2259 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2258, bf16[1024,3072]{0,1} %transpose.1998), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2260 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2259), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p411.1996 = bf16[3072]{0} parameter(411), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1995 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2261 = bf16[3072]{0} broadcast(bf16[] %constant.1995), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.11/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2262 = bf16[3072]{0} multiply(bf16[3072]{0} %p411.1996, bf16[3072]{0} %broadcast.2261), metadata={op_type="aten__add" op_name="aten__add.11/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2263 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2262), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.11/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2264 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2260, bf16[1,1025,3072]{2,1,0} %broadcast.2263), metadata={op_type="aten__add" op_name="aten__add.11/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2265 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2264), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2266 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2265), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2276 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2266), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2277 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2276), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2278 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2277), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2279 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.12/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2280 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2278, f32[1,16,1025,64]{3,2,1,0} %broadcast.2279), metadata={op_type="aten__mul" op_name="aten__mul.12/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2281 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2280), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2282 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2281), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2283 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2282), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2271 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2266), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2272 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2271), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2273 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2272), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2274 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2273), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2275 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2274), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2284 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2283, bf16[16,64,1025]{2,1,0} %reshape.2275), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2285 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2284), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2286 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2291 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2285, bf16[] %constant.2286), dimensions={3}, to_apply=%MaxComputation.2287, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2292 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2291), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2293 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2285, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2292), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2294 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2293), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2295 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2300 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2294, bf16[] %constant.2295), dimensions={3}, to_apply=%AddComputation.2296, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2301 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2300), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2302 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2294, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2301), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2303 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2302), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2304 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2303), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2267 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2266), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2268 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2267), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2269 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2268), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2270 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2269), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2305 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2304, bf16[16,1025,64]{2,1,0} %reshape.2270), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2306 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2305), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2307 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2306), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2308 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2307), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2309 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2308), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p410.1993 = bf16[1024,1024]{1,0} parameter(410), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1994 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p410.1993), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2310 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2309, bf16[1024,1024]{0,1} %transpose.1994), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2311 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2310), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p409.1992 = bf16[1024]{0} parameter(409), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1991 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2312 = bf16[1024]{0} broadcast(bf16[] %constant.1991), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2313 = bf16[1024]{0} multiply(bf16[1024]{0} %p409.1992, bf16[1024]{0} %broadcast.2312), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2314 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2313), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2315 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2311, bf16[1,1025,1024]{2,1,0} %broadcast.2314), metadata={op_type="aten__add" op_name="aten__add.13/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2316 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2315), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p408.1989 = bf16[1024]{0} parameter(408), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1990 = f32[1024]{0} convert(bf16[1024]{0} %p408.1989), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2317 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1990), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.14/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2318 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2316, f32[1,1025,1024]{2,1,0} %broadcast.2317), metadata={op_type="aten__mul" op_name="aten__mul.14/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2319 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2318), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1988 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2320 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1988), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.15/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2321 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2319, bf16[1,1025,1024]{2,1,0} %broadcast.2320), metadata={op_type="aten__add" op_name="aten__add.15/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2322 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2241, bf16[1,1025,1024]{2,1,0} %multiply.2321), metadata={op_type="aten__add" op_name="aten__add.15/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1983 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1984 = bf16[1]{0} reshape(bf16[] %constant.1983), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1985 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1984), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1986 = bf16[] reshape(bf16[1]{0} %broadcast.1985), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1987 = bf16[1025]{0} broadcast(bf16[] %reshape.1986), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1978 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1979 = bf16[1]{0} reshape(bf16[] %constant.1978), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1980 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1979), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1981 = bf16[] reshape(bf16[1]{0} %broadcast.1980), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1982 = bf16[1025]{0} broadcast(bf16[] %reshape.1981), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2323 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2322, bf16[1025]{0} %broadcast.1987, bf16[1025]{0} %broadcast.1982), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2325 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2323), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2326 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2323), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2327 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2328 = bf16[1025]{0} broadcast(bf16[] %constant.2327), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2329 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2326, bf16[1025]{0} %broadcast.2328), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2330 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2329), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p436.2331 = bf16[1024]{0} parameter(436), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2337 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p436.2331), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2324 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2323), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p407.1967 = bf16[1024]{0} parameter(407), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2333 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p407.1967), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2334 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2324, bf16[1,1025,1024]{2,1,0} %broadcast.2333), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1966 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2332 = bf16[] convert(s64[] %constant.1966), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2335 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2332), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2336 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2334, bf16[1,1025,1024]{2,1,0} %broadcast.2335), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2338 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2337, bf16[1,1025,1024]{2,1,0} %multiply.2336), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2339 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2338), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p406.1964 = bf16[4096,1024]{1,0} parameter(406), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1965 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p406.1964), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2340 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2339, bf16[1024,4096]{0,1} %transpose.1965), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2341 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2340), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p405.1963 = bf16[4096]{0} parameter(405), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1962 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2342 = bf16[4096]{0} broadcast(bf16[] %constant.1962), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.16/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2343 = bf16[4096]{0} multiply(bf16[4096]{0} %p405.1963, bf16[4096]{0} %broadcast.2342), metadata={op_type="aten__add" op_name="aten__add.16/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2344 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2343), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.16/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2345 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2341, bf16[1,1025,4096]{2,1,0} %broadcast.2344), metadata={op_type="aten__add" op_name="aten__add.16/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2346 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2354 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2346), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2355 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2345, bf16[1,1025,4096]{2,1,0} %broadcast.2354), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2348 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2349 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2348), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2350 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2345, bf16[1,1025,4096]{2,1,0} %broadcast.2349), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2351 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2350), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2347 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2352 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2347), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2353 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2351, bf16[1,1025,4096]{2,1,0} %broadcast.2352), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2356 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2355, bf16[1,1025,4096]{2,1,0} %add.2353), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2357 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2356), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p404.1960 = bf16[1024,4096]{1,0} parameter(404), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1961 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p404.1960), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2358 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2357, bf16[4096,1024]{0,1} %transpose.1961), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2359 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2358), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p403.1959 = bf16[1024]{0} parameter(403), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1958 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2360 = bf16[1024]{0} broadcast(bf16[] %constant.1958), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.17/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2361 = bf16[1024]{0} multiply(bf16[1024]{0} %p403.1959, bf16[1024]{0} %broadcast.2360), metadata={op_type="aten__add" op_name="aten__add.17/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2362 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2361), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.17/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2363 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2359, bf16[1,1025,1024]{2,1,0} %broadcast.2362), metadata={op_type="aten__add" op_name="aten__add.17/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2364 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2363), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p402.1956 = bf16[1024]{0} parameter(402), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1957 = f32[1024]{0} convert(bf16[1024]{0} %p402.1956), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2365 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1957), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.18/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2366 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2364, f32[1,1025,1024]{2,1,0} %broadcast.2365), metadata={op_type="aten__mul" op_name="aten__mul.18/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2367 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2366), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1955 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2368 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1955), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.19/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2369 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2367, bf16[1,1025,1024]{2,1,0} %broadcast.2368), metadata={op_type="aten__add" op_name="aten__add.19/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2370 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2322, bf16[1,1025,1024]{2,1,0} %multiply.2369), metadata={op_type="aten__add" op_name="aten__add.19/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1950 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1951 = bf16[1]{0} reshape(bf16[] %constant.1950), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1952 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1951), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1953 = bf16[] reshape(bf16[1]{0} %broadcast.1952), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1954 = bf16[1025]{0} broadcast(bf16[] %reshape.1953), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1945 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1946 = bf16[1]{0} reshape(bf16[] %constant.1945), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1947 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1946), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1948 = bf16[] reshape(bf16[1]{0} %broadcast.1947), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1949 = bf16[1025]{0} broadcast(bf16[] %reshape.1948), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2371 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2370, bf16[1025]{0} %broadcast.1954, bf16[1025]{0} %broadcast.1949), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2373 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2371), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2374 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2371), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2375 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2376 = bf16[1025]{0} broadcast(bf16[] %constant.2375), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2377 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2374, bf16[1025]{0} %broadcast.2376), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2378 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2377), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p437.2379 = bf16[1024]{0} parameter(437), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2385 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p437.2379), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2372 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2371), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p401.1934 = bf16[1024]{0} parameter(401), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2381 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p401.1934), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2382 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2372, bf16[1,1025,1024]{2,1,0} %broadcast.2381), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1933 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2380 = bf16[] convert(s64[] %constant.1933), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2383 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2380), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2384 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2382, bf16[1,1025,1024]{2,1,0} %broadcast.2383), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2386 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2385, bf16[1,1025,1024]{2,1,0} %multiply.2384), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2387 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2386), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p400.1931 = bf16[3072,1024]{1,0} parameter(400), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1932 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p400.1931), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2388 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2387, bf16[1024,3072]{0,1} %transpose.1932), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2389 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2388), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p399.1930 = bf16[3072]{0} parameter(399), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1929 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2390 = bf16[3072]{0} broadcast(bf16[] %constant.1929), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.20/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2391 = bf16[3072]{0} multiply(bf16[3072]{0} %p399.1930, bf16[3072]{0} %broadcast.2390), metadata={op_type="aten__add" op_name="aten__add.20/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2392 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2391), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.20/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2393 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2389, bf16[1,1025,3072]{2,1,0} %broadcast.2392), metadata={op_type="aten__add" op_name="aten__add.20/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2394 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2393), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2395 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2394), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2405 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2395), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2406 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2405), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2407 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2406), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2408 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.21/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2409 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2407, f32[1,16,1025,64]{3,2,1,0} %broadcast.2408), metadata={op_type="aten__mul" op_name="aten__mul.21/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2410 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2409), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2411 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2410), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2412 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2411), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2400 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2395), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2401 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2400), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2402 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2401), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2403 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2402), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2404 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2403), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2413 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2412, bf16[16,64,1025]{2,1,0} %reshape.2404), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2414 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2413), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2415 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2420 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2414, bf16[] %constant.2415), dimensions={3}, to_apply=%MaxComputation.2416, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2421 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2420), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2422 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2414, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2421), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2423 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2422), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2424 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2429 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2423, bf16[] %constant.2424), dimensions={3}, to_apply=%AddComputation.2425, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2430 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2429), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2431 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2423, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2430), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2432 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2431), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2433 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2432), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2396 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2395), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2397 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2396), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2398 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2397), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2399 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2398), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2434 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2433, bf16[16,1025,64]{2,1,0} %reshape.2399), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2435 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2434), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2436 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2435), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2437 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2436), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2438 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2437), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p398.1927 = bf16[1024,1024]{1,0} parameter(398), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1928 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p398.1927), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2439 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2438, bf16[1024,1024]{0,1} %transpose.1928), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2440 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2439), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p397.1926 = bf16[1024]{0} parameter(397), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1925 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2441 = bf16[1024]{0} broadcast(bf16[] %constant.1925), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.22/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2442 = bf16[1024]{0} multiply(bf16[1024]{0} %p397.1926, bf16[1024]{0} %broadcast.2441), metadata={op_type="aten__add" op_name="aten__add.22/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2443 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2442), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.22/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2444 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2440, bf16[1,1025,1024]{2,1,0} %broadcast.2443), metadata={op_type="aten__add" op_name="aten__add.22/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2445 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2444), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p396.1923 = bf16[1024]{0} parameter(396), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1924 = f32[1024]{0} convert(bf16[1024]{0} %p396.1923), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2446 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1924), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.23/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2447 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2445, f32[1,1025,1024]{2,1,0} %broadcast.2446), metadata={op_type="aten__mul" op_name="aten__mul.23/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2448 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2447), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1922 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2449 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1922), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.24/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2450 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2448, bf16[1,1025,1024]{2,1,0} %broadcast.2449), metadata={op_type="aten__add" op_name="aten__add.24/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2451 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2370, bf16[1,1025,1024]{2,1,0} %multiply.2450), metadata={op_type="aten__add" op_name="aten__add.24/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1917 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1918 = bf16[1]{0} reshape(bf16[] %constant.1917), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1919 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1918), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1920 = bf16[] reshape(bf16[1]{0} %broadcast.1919), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1921 = bf16[1025]{0} broadcast(bf16[] %reshape.1920), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1912 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1913 = bf16[1]{0} reshape(bf16[] %constant.1912), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1914 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1913), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1915 = bf16[] reshape(bf16[1]{0} %broadcast.1914), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1916 = bf16[1025]{0} broadcast(bf16[] %reshape.1915), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2452 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2451, bf16[1025]{0} %broadcast.1921, bf16[1025]{0} %broadcast.1916), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2454 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2452), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2455 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2452), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2456 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2457 = bf16[1025]{0} broadcast(bf16[] %constant.2456), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2458 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2455, bf16[1025]{0} %broadcast.2457), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2459 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2458), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p438.2460 = bf16[1024]{0} parameter(438), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2466 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p438.2460), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2453 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2452), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p395.1901 = bf16[1024]{0} parameter(395), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2462 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p395.1901), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2463 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2453, bf16[1,1025,1024]{2,1,0} %broadcast.2462), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1900 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2461 = bf16[] convert(s64[] %constant.1900), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2464 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2461), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2465 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2463, bf16[1,1025,1024]{2,1,0} %broadcast.2464), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2467 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2466, bf16[1,1025,1024]{2,1,0} %multiply.2465), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2468 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2467), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p394.1898 = bf16[4096,1024]{1,0} parameter(394), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1899 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p394.1898), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2469 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2468, bf16[1024,4096]{0,1} %transpose.1899), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2470 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2469), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p393.1897 = bf16[4096]{0} parameter(393), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1896 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2471 = bf16[4096]{0} broadcast(bf16[] %constant.1896), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.25/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2472 = bf16[4096]{0} multiply(bf16[4096]{0} %p393.1897, bf16[4096]{0} %broadcast.2471), metadata={op_type="aten__add" op_name="aten__add.25/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2473 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2472), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.25/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2474 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2470, bf16[1,1025,4096]{2,1,0} %broadcast.2473), metadata={op_type="aten__add" op_name="aten__add.25/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2475 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2483 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2475), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2484 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2474, bf16[1,1025,4096]{2,1,0} %broadcast.2483), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2477 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2478 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2477), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2479 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2474, bf16[1,1025,4096]{2,1,0} %broadcast.2478), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2480 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2479), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2476 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2481 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2476), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2482 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2480, bf16[1,1025,4096]{2,1,0} %broadcast.2481), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2485 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2484, bf16[1,1025,4096]{2,1,0} %add.2482), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2486 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2485), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p392.1894 = bf16[1024,4096]{1,0} parameter(392), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1895 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p392.1894), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2487 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2486, bf16[4096,1024]{0,1} %transpose.1895), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2488 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2487), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p391.1893 = bf16[1024]{0} parameter(391), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1892 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2489 = bf16[1024]{0} broadcast(bf16[] %constant.1892), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.26/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2490 = bf16[1024]{0} multiply(bf16[1024]{0} %p391.1893, bf16[1024]{0} %broadcast.2489), metadata={op_type="aten__add" op_name="aten__add.26/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2491 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2490), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.26/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2492 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2488, bf16[1,1025,1024]{2,1,0} %broadcast.2491), metadata={op_type="aten__add" op_name="aten__add.26/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2493 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2492), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p390.1890 = bf16[1024]{0} parameter(390), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1891 = f32[1024]{0} convert(bf16[1024]{0} %p390.1890), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2494 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1891), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.27/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2495 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2493, f32[1,1025,1024]{2,1,0} %broadcast.2494), metadata={op_type="aten__mul" op_name="aten__mul.27/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2496 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2495), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1889 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2497 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1889), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.28/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2498 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2496, bf16[1,1025,1024]{2,1,0} %broadcast.2497), metadata={op_type="aten__add" op_name="aten__add.28/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2499 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2451, bf16[1,1025,1024]{2,1,0} %multiply.2498), metadata={op_type="aten__add" op_name="aten__add.28/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1884 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1885 = bf16[1]{0} reshape(bf16[] %constant.1884), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1886 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1885), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1887 = bf16[] reshape(bf16[1]{0} %broadcast.1886), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1888 = bf16[1025]{0} broadcast(bf16[] %reshape.1887), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1879 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1880 = bf16[1]{0} reshape(bf16[] %constant.1879), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1881 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1880), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1882 = bf16[] reshape(bf16[1]{0} %broadcast.1881), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1883 = bf16[1025]{0} broadcast(bf16[] %reshape.1882), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2500 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2499, bf16[1025]{0} %broadcast.1888, bf16[1025]{0} %broadcast.1883), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2502 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2500), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2503 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2500), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2504 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2505 = bf16[1025]{0} broadcast(bf16[] %constant.2504), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2506 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2503, bf16[1025]{0} %broadcast.2505), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2507 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2506), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p439.2508 = bf16[1024]{0} parameter(439), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2514 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p439.2508), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2501 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2500), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p389.1868 = bf16[1024]{0} parameter(389), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2510 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p389.1868), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2511 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2501, bf16[1,1025,1024]{2,1,0} %broadcast.2510), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1867 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2509 = bf16[] convert(s64[] %constant.1867), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2512 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2509), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2513 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2511, bf16[1,1025,1024]{2,1,0} %broadcast.2512), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2515 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2514, bf16[1,1025,1024]{2,1,0} %multiply.2513), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2516 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2515), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p388.1865 = bf16[3072,1024]{1,0} parameter(388), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1866 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p388.1865), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2517 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2516, bf16[1024,3072]{0,1} %transpose.1866), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2518 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2517), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p387.1864 = bf16[3072]{0} parameter(387), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1863 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2519 = bf16[3072]{0} broadcast(bf16[] %constant.1863), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.29/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2520 = bf16[3072]{0} multiply(bf16[3072]{0} %p387.1864, bf16[3072]{0} %broadcast.2519), metadata={op_type="aten__add" op_name="aten__add.29/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2521 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2520), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.29/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2522 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2518, bf16[1,1025,3072]{2,1,0} %broadcast.2521), metadata={op_type="aten__add" op_name="aten__add.29/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2523 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2522), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2524 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2523), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2534 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2524), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2535 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2534), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2536 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2535), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2537 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.30/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2538 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2536, f32[1,16,1025,64]{3,2,1,0} %broadcast.2537), metadata={op_type="aten__mul" op_name="aten__mul.30/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2539 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2538), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2540 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2539), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2541 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2540), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2529 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2524), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2530 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2529), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2531 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2530), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2532 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2531), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2533 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2532), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2542 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2541, bf16[16,64,1025]{2,1,0} %reshape.2533), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2543 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2542), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2544 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2549 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2543, bf16[] %constant.2544), dimensions={3}, to_apply=%MaxComputation.2545, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2550 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2549), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2551 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2543, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2550), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2552 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2551), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2553 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2558 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2552, bf16[] %constant.2553), dimensions={3}, to_apply=%AddComputation.2554, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2559 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2558), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2560 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2552, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2559), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2561 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2560), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2562 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2561), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2525 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2524), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2526 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2525), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2527 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2526), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2528 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2527), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2563 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2562, bf16[16,1025,64]{2,1,0} %reshape.2528), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2564 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2563), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2565 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2564), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2566 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2565), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2567 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2566), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p386.1861 = bf16[1024,1024]{1,0} parameter(386), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1862 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p386.1861), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2568 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2567, bf16[1024,1024]{0,1} %transpose.1862), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2569 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2568), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p385.1860 = bf16[1024]{0} parameter(385), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1859 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2570 = bf16[1024]{0} broadcast(bf16[] %constant.1859), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2571 = bf16[1024]{0} multiply(bf16[1024]{0} %p385.1860, bf16[1024]{0} %broadcast.2570), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2572 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2571), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2573 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2569, bf16[1,1025,1024]{2,1,0} %broadcast.2572), metadata={op_type="aten__add" op_name="aten__add.31/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2574 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2573), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p384.1857 = bf16[1024]{0} parameter(384), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1858 = f32[1024]{0} convert(bf16[1024]{0} %p384.1857), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2575 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1858), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.32/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2576 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2574, f32[1,1025,1024]{2,1,0} %broadcast.2575), metadata={op_type="aten__mul" op_name="aten__mul.32/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2577 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2576), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1856 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2578 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1856), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.33/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2579 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2577, bf16[1,1025,1024]{2,1,0} %broadcast.2578), metadata={op_type="aten__add" op_name="aten__add.33/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2580 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2499, bf16[1,1025,1024]{2,1,0} %multiply.2579), metadata={op_type="aten__add" op_name="aten__add.33/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1851 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1852 = bf16[1]{0} reshape(bf16[] %constant.1851), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1853 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1852), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1854 = bf16[] reshape(bf16[1]{0} %broadcast.1853), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1855 = bf16[1025]{0} broadcast(bf16[] %reshape.1854), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1846 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1847 = bf16[1]{0} reshape(bf16[] %constant.1846), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1848 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1847), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1849 = bf16[] reshape(bf16[1]{0} %broadcast.1848), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1850 = bf16[1025]{0} broadcast(bf16[] %reshape.1849), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2581 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2580, bf16[1025]{0} %broadcast.1855, bf16[1025]{0} %broadcast.1850), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2583 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2581), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2584 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2581), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2585 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2586 = bf16[1025]{0} broadcast(bf16[] %constant.2585), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2587 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2584, bf16[1025]{0} %broadcast.2586), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2588 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2587), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p440.2589 = bf16[1024]{0} parameter(440), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2595 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p440.2589), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2582 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2581), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p383.1835 = bf16[1024]{0} parameter(383), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2591 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p383.1835), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2592 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2582, bf16[1,1025,1024]{2,1,0} %broadcast.2591), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1834 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2590 = bf16[] convert(s64[] %constant.1834), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2593 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2590), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2594 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2592, bf16[1,1025,1024]{2,1,0} %broadcast.2593), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2596 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2595, bf16[1,1025,1024]{2,1,0} %multiply.2594), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2597 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2596), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p382.1832 = bf16[4096,1024]{1,0} parameter(382), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1833 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p382.1832), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2598 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2597, bf16[1024,4096]{0,1} %transpose.1833), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2599 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2598), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p381.1831 = bf16[4096]{0} parameter(381), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1830 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2600 = bf16[4096]{0} broadcast(bf16[] %constant.1830), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.34/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2601 = bf16[4096]{0} multiply(bf16[4096]{0} %p381.1831, bf16[4096]{0} %broadcast.2600), metadata={op_type="aten__add" op_name="aten__add.34/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2602 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2601), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.34/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2603 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2599, bf16[1,1025,4096]{2,1,0} %broadcast.2602), metadata={op_type="aten__add" op_name="aten__add.34/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2604 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2612 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2604), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2613 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2603, bf16[1,1025,4096]{2,1,0} %broadcast.2612), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2606 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2607 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2606), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2608 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2603, bf16[1,1025,4096]{2,1,0} %broadcast.2607), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2609 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2608), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2605 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2610 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2605), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2611 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2609, bf16[1,1025,4096]{2,1,0} %broadcast.2610), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2614 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2613, bf16[1,1025,4096]{2,1,0} %add.2611), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2615 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2614), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p380.1828 = bf16[1024,4096]{1,0} parameter(380), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1829 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p380.1828), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2616 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2615, bf16[4096,1024]{0,1} %transpose.1829), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2617 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2616), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p379.1827 = bf16[1024]{0} parameter(379), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1826 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2618 = bf16[1024]{0} broadcast(bf16[] %constant.1826), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.35/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2619 = bf16[1024]{0} multiply(bf16[1024]{0} %p379.1827, bf16[1024]{0} %broadcast.2618), metadata={op_type="aten__add" op_name="aten__add.35/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2620 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2619), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.35/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2621 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2617, bf16[1,1025,1024]{2,1,0} %broadcast.2620), metadata={op_type="aten__add" op_name="aten__add.35/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2622 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2621), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p378.1824 = bf16[1024]{0} parameter(378), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1825 = f32[1024]{0} convert(bf16[1024]{0} %p378.1824), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2623 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1825), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.36/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2624 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2622, f32[1,1025,1024]{2,1,0} %broadcast.2623), metadata={op_type="aten__mul" op_name="aten__mul.36/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2625 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2624), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1823 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2626 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1823), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.37/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2627 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2625, bf16[1,1025,1024]{2,1,0} %broadcast.2626), metadata={op_type="aten__add" op_name="aten__add.37/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2628 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2580, bf16[1,1025,1024]{2,1,0} %multiply.2627), metadata={op_type="aten__add" op_name="aten__add.37/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1818 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1819 = bf16[1]{0} reshape(bf16[] %constant.1818), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1820 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1819), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1821 = bf16[] reshape(bf16[1]{0} %broadcast.1820), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1822 = bf16[1025]{0} broadcast(bf16[] %reshape.1821), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1813 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1814 = bf16[1]{0} reshape(bf16[] %constant.1813), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1815 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1814), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1816 = bf16[] reshape(bf16[1]{0} %broadcast.1815), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1817 = bf16[1025]{0} broadcast(bf16[] %reshape.1816), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2629 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2628, bf16[1025]{0} %broadcast.1822, bf16[1025]{0} %broadcast.1817), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2631 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2629), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2632 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2629), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2633 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2634 = bf16[1025]{0} broadcast(bf16[] %constant.2633), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2635 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2632, bf16[1025]{0} %broadcast.2634), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2636 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2635), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p441.2637 = bf16[1024]{0} parameter(441), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2643 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p441.2637), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2630 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2629), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p377.1802 = bf16[1024]{0} parameter(377), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2639 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p377.1802), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2640 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2630, bf16[1,1025,1024]{2,1,0} %broadcast.2639), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1801 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2638 = bf16[] convert(s64[] %constant.1801), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2641 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2638), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2642 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2640, bf16[1,1025,1024]{2,1,0} %broadcast.2641), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2644 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2643, bf16[1,1025,1024]{2,1,0} %multiply.2642), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2645 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2644), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p376.1799 = bf16[3072,1024]{1,0} parameter(376), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1800 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p376.1799), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2646 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2645, bf16[1024,3072]{0,1} %transpose.1800), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2647 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2646), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p375.1798 = bf16[3072]{0} parameter(375), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1797 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2648 = bf16[3072]{0} broadcast(bf16[] %constant.1797), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.38/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2649 = bf16[3072]{0} multiply(bf16[3072]{0} %p375.1798, bf16[3072]{0} %broadcast.2648), metadata={op_type="aten__add" op_name="aten__add.38/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2650 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2649), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.38/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2651 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2647, bf16[1,1025,3072]{2,1,0} %broadcast.2650), metadata={op_type="aten__add" op_name="aten__add.38/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2652 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2651), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2653 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2652), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2663 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2653), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2664 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2663), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2665 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2664), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2666 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.39/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2667 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2665, f32[1,16,1025,64]{3,2,1,0} %broadcast.2666), metadata={op_type="aten__mul" op_name="aten__mul.39/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2668 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2667), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2669 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2668), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2670 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2669), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2658 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2653), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2659 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2658), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2660 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2659), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2661 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2660), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2662 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2661), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2671 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2670, bf16[16,64,1025]{2,1,0} %reshape.2662), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2672 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2671), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2673 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2678 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2672, bf16[] %constant.2673), dimensions={3}, to_apply=%MaxComputation.2674, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2679 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2678), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2680 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2672, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2679), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2681 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2680), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2682 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2687 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2681, bf16[] %constant.2682), dimensions={3}, to_apply=%AddComputation.2683, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2688 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2687), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2689 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2681, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2688), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2690 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2689), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2691 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2690), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2654 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2653), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2655 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2654), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2656 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2655), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2657 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2656), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2692 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2691, bf16[16,1025,64]{2,1,0} %reshape.2657), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2693 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2692), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2694 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2693), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2695 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2694), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2696 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2695), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p374.1795 = bf16[1024,1024]{1,0} parameter(374), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1796 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p374.1795), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2697 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2696, bf16[1024,1024]{0,1} %transpose.1796), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2698 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2697), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p373.1794 = bf16[1024]{0} parameter(373), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1793 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2699 = bf16[1024]{0} broadcast(bf16[] %constant.1793), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.40/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2700 = bf16[1024]{0} multiply(bf16[1024]{0} %p373.1794, bf16[1024]{0} %broadcast.2699), metadata={op_type="aten__add" op_name="aten__add.40/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2701 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2700), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.40/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2702 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2698, bf16[1,1025,1024]{2,1,0} %broadcast.2701), metadata={op_type="aten__add" op_name="aten__add.40/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2703 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2702), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p372.1791 = bf16[1024]{0} parameter(372), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1792 = f32[1024]{0} convert(bf16[1024]{0} %p372.1791), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2704 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1792), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.41/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2705 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2703, f32[1,1025,1024]{2,1,0} %broadcast.2704), metadata={op_type="aten__mul" op_name="aten__mul.41/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2706 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2705), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1790 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2707 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1790), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.42/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2708 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2706, bf16[1,1025,1024]{2,1,0} %broadcast.2707), metadata={op_type="aten__add" op_name="aten__add.42/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2709 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2628, bf16[1,1025,1024]{2,1,0} %multiply.2708), metadata={op_type="aten__add" op_name="aten__add.42/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1785 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1786 = bf16[1]{0} reshape(bf16[] %constant.1785), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1787 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1786), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1788 = bf16[] reshape(bf16[1]{0} %broadcast.1787), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1789 = bf16[1025]{0} broadcast(bf16[] %reshape.1788), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1780 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1781 = bf16[1]{0} reshape(bf16[] %constant.1780), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1782 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1781), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1783 = bf16[] reshape(bf16[1]{0} %broadcast.1782), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1784 = bf16[1025]{0} broadcast(bf16[] %reshape.1783), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2710 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2709, bf16[1025]{0} %broadcast.1789, bf16[1025]{0} %broadcast.1784), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2712 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2710), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2713 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2710), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2714 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2715 = bf16[1025]{0} broadcast(bf16[] %constant.2714), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2716 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2713, bf16[1025]{0} %broadcast.2715), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2717 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2716), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p442.2718 = bf16[1024]{0} parameter(442), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2724 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p442.2718), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2711 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2710), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p371.1769 = bf16[1024]{0} parameter(371), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2720 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p371.1769), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2721 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2711, bf16[1,1025,1024]{2,1,0} %broadcast.2720), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1768 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2719 = bf16[] convert(s64[] %constant.1768), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2722 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2719), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2723 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2721, bf16[1,1025,1024]{2,1,0} %broadcast.2722), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2725 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2724, bf16[1,1025,1024]{2,1,0} %multiply.2723), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2726 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2725), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p370.1766 = bf16[4096,1024]{1,0} parameter(370), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1767 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p370.1766), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2727 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2726, bf16[1024,4096]{0,1} %transpose.1767), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2728 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2727), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p369.1765 = bf16[4096]{0} parameter(369), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1764 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2729 = bf16[4096]{0} broadcast(bf16[] %constant.1764), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.43/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2730 = bf16[4096]{0} multiply(bf16[4096]{0} %p369.1765, bf16[4096]{0} %broadcast.2729), metadata={op_type="aten__add" op_name="aten__add.43/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2731 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2730), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.43/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2732 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2728, bf16[1,1025,4096]{2,1,0} %broadcast.2731), metadata={op_type="aten__add" op_name="aten__add.43/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2733 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2741 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2733), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2742 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2732, bf16[1,1025,4096]{2,1,0} %broadcast.2741), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2735 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2736 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2735), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2737 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2732, bf16[1,1025,4096]{2,1,0} %broadcast.2736), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2738 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2737), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2734 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2739 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2734), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2740 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2738, bf16[1,1025,4096]{2,1,0} %broadcast.2739), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2743 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2742, bf16[1,1025,4096]{2,1,0} %add.2740), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2744 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2743), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p368.1762 = bf16[1024,4096]{1,0} parameter(368), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1763 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p368.1762), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2745 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2744, bf16[4096,1024]{0,1} %transpose.1763), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2746 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2745), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p367.1761 = bf16[1024]{0} parameter(367), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1760 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2747 = bf16[1024]{0} broadcast(bf16[] %constant.1760), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.44/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2748 = bf16[1024]{0} multiply(bf16[1024]{0} %p367.1761, bf16[1024]{0} %broadcast.2747), metadata={op_type="aten__add" op_name="aten__add.44/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2749 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2748), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.44/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2750 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2746, bf16[1,1025,1024]{2,1,0} %broadcast.2749), metadata={op_type="aten__add" op_name="aten__add.44/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2751 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2750), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p366.1758 = bf16[1024]{0} parameter(366), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1759 = f32[1024]{0} convert(bf16[1024]{0} %p366.1758), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2752 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1759), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.45/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2753 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2751, f32[1,1025,1024]{2,1,0} %broadcast.2752), metadata={op_type="aten__mul" op_name="aten__mul.45/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2754 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2753), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1757 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2755 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1757), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.46/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2756 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2754, bf16[1,1025,1024]{2,1,0} %broadcast.2755), metadata={op_type="aten__add" op_name="aten__add.46/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2757 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2709, bf16[1,1025,1024]{2,1,0} %multiply.2756), metadata={op_type="aten__add" op_name="aten__add.46/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1752 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1753 = bf16[1]{0} reshape(bf16[] %constant.1752), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1754 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1753), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1755 = bf16[] reshape(bf16[1]{0} %broadcast.1754), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1756 = bf16[1025]{0} broadcast(bf16[] %reshape.1755), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1747 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1748 = bf16[1]{0} reshape(bf16[] %constant.1747), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1749 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1748), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1750 = bf16[] reshape(bf16[1]{0} %broadcast.1749), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1751 = bf16[1025]{0} broadcast(bf16[] %reshape.1750), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2758 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2757, bf16[1025]{0} %broadcast.1756, bf16[1025]{0} %broadcast.1751), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2760 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2758), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2761 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2758), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2762 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2763 = bf16[1025]{0} broadcast(bf16[] %constant.2762), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2764 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2761, bf16[1025]{0} %broadcast.2763), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2765 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2764), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p443.2766 = bf16[1024]{0} parameter(443), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2772 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p443.2766), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2759 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2758), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p365.1736 = bf16[1024]{0} parameter(365), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2768 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p365.1736), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2769 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2759, bf16[1,1025,1024]{2,1,0} %broadcast.2768), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1735 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2767 = bf16[] convert(s64[] %constant.1735), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2770 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2767), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2771 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2769, bf16[1,1025,1024]{2,1,0} %broadcast.2770), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2773 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2772, bf16[1,1025,1024]{2,1,0} %multiply.2771), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2774 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2773), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p364.1733 = bf16[3072,1024]{1,0} parameter(364), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1734 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p364.1733), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2775 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2774, bf16[1024,3072]{0,1} %transpose.1734), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2776 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2775), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p363.1732 = bf16[3072]{0} parameter(363), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1731 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2777 = bf16[3072]{0} broadcast(bf16[] %constant.1731), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.47/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2778 = bf16[3072]{0} multiply(bf16[3072]{0} %p363.1732, bf16[3072]{0} %broadcast.2777), metadata={op_type="aten__add" op_name="aten__add.47/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2779 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2778), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.47/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2780 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2776, bf16[1,1025,3072]{2,1,0} %broadcast.2779), metadata={op_type="aten__add" op_name="aten__add.47/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2781 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2780), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2782 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2781), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2792 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2782), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2793 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2792), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2794 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2793), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2795 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.48/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2796 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2794, f32[1,16,1025,64]{3,2,1,0} %broadcast.2795), metadata={op_type="aten__mul" op_name="aten__mul.48/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2797 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2796), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2798 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2797), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2799 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2798), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2787 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2782), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2788 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2787), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2789 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2788), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2790 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2789), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2791 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2790), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2800 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2799, bf16[16,64,1025]{2,1,0} %reshape.2791), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2801 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2800), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2802 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2807 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2801, bf16[] %constant.2802), dimensions={3}, to_apply=%MaxComputation.2803, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2808 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2807), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2809 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2801, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2808), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2810 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2809), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2811 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2816 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2810, bf16[] %constant.2811), dimensions={3}, to_apply=%AddComputation.2812, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2817 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2816), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2818 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2810, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2817), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2819 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2818), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2820 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2819), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2783 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2782), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2784 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2783), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2785 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2784), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2786 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2785), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2821 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2820, bf16[16,1025,64]{2,1,0} %reshape.2786), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2822 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2821), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2823 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2822), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2824 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2823), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2825 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2824), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p362.1729 = bf16[1024,1024]{1,0} parameter(362), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1730 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p362.1729), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2826 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2825, bf16[1024,1024]{0,1} %transpose.1730), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2827 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2826), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p361.1728 = bf16[1024]{0} parameter(361), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1727 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2828 = bf16[1024]{0} broadcast(bf16[] %constant.1727), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2829 = bf16[1024]{0} multiply(bf16[1024]{0} %p361.1728, bf16[1024]{0} %broadcast.2828), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2830 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2829), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2831 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2827, bf16[1,1025,1024]{2,1,0} %broadcast.2830), metadata={op_type="aten__add" op_name="aten__add.49/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2832 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2831), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p360.1725 = bf16[1024]{0} parameter(360), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1726 = f32[1024]{0} convert(bf16[1024]{0} %p360.1725), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2833 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1726), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.50/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2834 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2832, f32[1,1025,1024]{2,1,0} %broadcast.2833), metadata={op_type="aten__mul" op_name="aten__mul.50/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2835 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2834), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1724 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2836 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1724), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.51/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2837 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2835, bf16[1,1025,1024]{2,1,0} %broadcast.2836), metadata={op_type="aten__add" op_name="aten__add.51/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2838 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2757, bf16[1,1025,1024]{2,1,0} %multiply.2837), metadata={op_type="aten__add" op_name="aten__add.51/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1719 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1720 = bf16[1]{0} reshape(bf16[] %constant.1719), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1721 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1720), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1722 = bf16[] reshape(bf16[1]{0} %broadcast.1721), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1723 = bf16[1025]{0} broadcast(bf16[] %reshape.1722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1714 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1715 = bf16[1]{0} reshape(bf16[] %constant.1714), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1716 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1715), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1717 = bf16[] reshape(bf16[1]{0} %broadcast.1716), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1718 = bf16[1025]{0} broadcast(bf16[] %reshape.1717), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2839 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2838, bf16[1025]{0} %broadcast.1723, bf16[1025]{0} %broadcast.1718), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2841 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2839), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2842 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2839), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2843 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2844 = bf16[1025]{0} broadcast(bf16[] %constant.2843), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2845 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2842, bf16[1025]{0} %broadcast.2844), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2846 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2845), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p444.2847 = bf16[1024]{0} parameter(444), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2853 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p444.2847), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2840 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2839), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p359.1703 = bf16[1024]{0} parameter(359), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2849 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p359.1703), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2850 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2840, bf16[1,1025,1024]{2,1,0} %broadcast.2849), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1702 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2848 = bf16[] convert(s64[] %constant.1702), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2851 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2848), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2852 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2850, bf16[1,1025,1024]{2,1,0} %broadcast.2851), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2854 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2853, bf16[1,1025,1024]{2,1,0} %multiply.2852), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2855 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2854), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p358.1700 = bf16[4096,1024]{1,0} parameter(358), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1701 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p358.1700), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2856 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2855, bf16[1024,4096]{0,1} %transpose.1701), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2857 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2856), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p357.1699 = bf16[4096]{0} parameter(357), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1698 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2858 = bf16[4096]{0} broadcast(bf16[] %constant.1698), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.52/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2859 = bf16[4096]{0} multiply(bf16[4096]{0} %p357.1699, bf16[4096]{0} %broadcast.2858), metadata={op_type="aten__add" op_name="aten__add.52/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2860 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2859), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.52/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2861 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2857, bf16[1,1025,4096]{2,1,0} %broadcast.2860), metadata={op_type="aten__add" op_name="aten__add.52/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2862 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2870 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2862), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2871 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2861, bf16[1,1025,4096]{2,1,0} %broadcast.2870), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2864 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2865 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2864), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2866 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2861, bf16[1,1025,4096]{2,1,0} %broadcast.2865), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2867 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2866), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2863 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2868 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2863), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2869 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2867, bf16[1,1025,4096]{2,1,0} %broadcast.2868), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2872 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.2871, bf16[1,1025,4096]{2,1,0} %add.2869), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.2873 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.2872), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p356.1696 = bf16[1024,4096]{1,0} parameter(356), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1697 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p356.1696), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2874 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.2873, bf16[4096,1024]{0,1} %transpose.1697), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2875 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2874), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p355.1695 = bf16[1024]{0} parameter(355), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1694 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2876 = bf16[1024]{0} broadcast(bf16[] %constant.1694), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.53/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2877 = bf16[1024]{0} multiply(bf16[1024]{0} %p355.1695, bf16[1024]{0} %broadcast.2876), metadata={op_type="aten__add" op_name="aten__add.53/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2878 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2877), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.53/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2879 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2875, bf16[1,1025,1024]{2,1,0} %broadcast.2878), metadata={op_type="aten__add" op_name="aten__add.53/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2880 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2879), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p354.1692 = bf16[1024]{0} parameter(354), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1693 = f32[1024]{0} convert(bf16[1024]{0} %p354.1692), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2881 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1693), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.54/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2882 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2880, f32[1,1025,1024]{2,1,0} %broadcast.2881), metadata={op_type="aten__mul" op_name="aten__mul.54/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.2883 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2882), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1691 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.2884 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1691), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.55/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.2885 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2883, bf16[1,1025,1024]{2,1,0} %broadcast.2884), metadata={op_type="aten__add" op_name="aten__add.55/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.2886 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2838, bf16[1,1025,1024]{2,1,0} %multiply.2885), metadata={op_type="aten__add" op_name="aten__add.55/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1686 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1687 = bf16[1]{0} reshape(bf16[] %constant.1686), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1688 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1687), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1689 = bf16[] reshape(bf16[1]{0} %broadcast.1688), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1690 = bf16[1025]{0} broadcast(bf16[] %reshape.1689), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1681 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1682 = bf16[1]{0} reshape(bf16[] %constant.1681), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1683 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1682), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1684 = bf16[] reshape(bf16[1]{0} %broadcast.1683), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1685 = bf16[1025]{0} broadcast(bf16[] %reshape.1684), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2887 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2886, bf16[1025]{0} %broadcast.1690, bf16[1025]{0} %broadcast.1685), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2889 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2887), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2890 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2887), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2891 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2892 = bf16[1025]{0} broadcast(bf16[] %constant.2891), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2893 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2890, bf16[1025]{0} %broadcast.2892), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2894 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2893), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p445.2895 = bf16[1024]{0} parameter(445), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2901 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p445.2895), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2888 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2887), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p353.1670 = bf16[1024]{0} parameter(353), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2897 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p353.1670), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2898 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2888, bf16[1,1025,1024]{2,1,0} %broadcast.2897), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1669 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2896 = bf16[] convert(s64[] %constant.1669), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2899 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2896), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2900 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2898, bf16[1,1025,1024]{2,1,0} %broadcast.2899), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2902 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2901, bf16[1,1025,1024]{2,1,0} %multiply.2900), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2903 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2902), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p352.1667 = bf16[3072,1024]{1,0} parameter(352), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1668 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p352.1667), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2904 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2903, bf16[1024,3072]{0,1} %transpose.1668), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2905 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.2904), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p351.1666 = bf16[3072]{0} parameter(351), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1665 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2906 = bf16[3072]{0} broadcast(bf16[] %constant.1665), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.56/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2907 = bf16[3072]{0} multiply(bf16[3072]{0} %p351.1666, bf16[3072]{0} %broadcast.2906), metadata={op_type="aten__add" op_name="aten__add.56/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2908 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.2907), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.56/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2909 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.2905, bf16[1,1025,3072]{2,1,0} %broadcast.2908), metadata={op_type="aten__add" op_name="aten__add.56/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2910 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.2909), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.2911 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.2910), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.2921 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2911), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2922 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2921), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.2923 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.2922), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2924 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.57/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.2925 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.2923, f32[1,16,1025,64]{3,2,1,0} %broadcast.2924), metadata={op_type="aten__mul" op_name="aten__mul.57/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.2926 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.2925), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2927 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.2926), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2928 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2927), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.2916 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2911), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2917 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2916), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.2918 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2917), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.2919 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.2918), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2920 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.2919), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.2929 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.2928, bf16[16,64,1025]{2,1,0} %reshape.2920), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.2930 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.2929), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.2931 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2936 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2930, bf16[] %constant.2931), dimensions={3}, to_apply=%MaxComputation.2932, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2937 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2936), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.2938 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.2930, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2937), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.2939 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.2938), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.2940 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.2945 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2939, bf16[] %constant.2940), dimensions={3}, to_apply=%AddComputation.2941, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2946 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.2945), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.2947 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.2939, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2946), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.2948 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.2947), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2949 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.2948), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.2912 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.2911), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.2913 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.2912), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.2914 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.2913), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2915 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.2914), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.2950 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.2949, bf16[16,1025,64]{2,1,0} %reshape.2915), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2951 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.2950), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.2952 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.2951), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2953 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.2952), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.2954 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.2953), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p350.1663 = bf16[1024,1024]{1,0} parameter(350), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1664 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p350.1663), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2955 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2954, bf16[1024,1024]{0,1} %transpose.1664), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2956 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.2955), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p349.1662 = bf16[1024]{0} parameter(349), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1661 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2957 = bf16[1024]{0} broadcast(bf16[] %constant.1661), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.58/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2958 = bf16[1024]{0} multiply(bf16[1024]{0} %p349.1662, bf16[1024]{0} %broadcast.2957), metadata={op_type="aten__add" op_name="aten__add.58/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2959 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.2958), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.58/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2960 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.2956, bf16[1,1025,1024]{2,1,0} %broadcast.2959), metadata={op_type="aten__add" op_name="aten__add.58/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.2961 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.2960), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p348.1659 = bf16[1024]{0} parameter(348), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1660 = f32[1024]{0} convert(bf16[1024]{0} %p348.1659), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2962 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1660), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.59/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2963 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.2961, f32[1,1025,1024]{2,1,0} %broadcast.2962), metadata={op_type="aten__mul" op_name="aten__mul.59/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.2964 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.2963), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1658 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.2965 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1658), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.60/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.2966 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.2964, bf16[1,1025,1024]{2,1,0} %broadcast.2965), metadata={op_type="aten__add" op_name="aten__add.60/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.2967 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2886, bf16[1,1025,1024]{2,1,0} %multiply.2966), metadata={op_type="aten__add" op_name="aten__add.60/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1653 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1654 = bf16[1]{0} reshape(bf16[] %constant.1653), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1655 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1654), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1656 = bf16[] reshape(bf16[1]{0} %broadcast.1655), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1657 = bf16[1025]{0} broadcast(bf16[] %reshape.1656), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1648 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1649 = bf16[1]{0} reshape(bf16[] %constant.1648), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1650 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1649), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1651 = bf16[] reshape(bf16[1]{0} %broadcast.1650), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1652 = bf16[1025]{0} broadcast(bf16[] %reshape.1651), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.2968 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.2967, bf16[1025]{0} %broadcast.1657, bf16[1025]{0} %broadcast.1652), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2970 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2968), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2971 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2968), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.2972 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2973 = bf16[1025]{0} broadcast(bf16[] %constant.2972), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2974 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.2971, bf16[1025]{0} %broadcast.2973), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.2975 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.2974), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p446.2976 = bf16[1024]{0} parameter(446), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2982 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p446.2976), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.2969 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.2968), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p347.1637 = bf16[1024]{0} parameter(347), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.2978 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p347.1637), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2979 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.2969, bf16[1,1025,1024]{2,1,0} %broadcast.2978), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1636 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.2977 = bf16[] convert(s64[] %constant.1636), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.2980 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.2977), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.2981 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.2979, bf16[1,1025,1024]{2,1,0} %broadcast.2980), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.2983 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.2982, bf16[1,1025,1024]{2,1,0} %multiply.2981), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.2984 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.2983), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p346.1634 = bf16[4096,1024]{1,0} parameter(346), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1635 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p346.1634), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.2985 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.2984, bf16[1024,4096]{0,1} %transpose.1635), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.2986 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.2985), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p345.1633 = bf16[4096]{0} parameter(345), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1632 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2987 = bf16[4096]{0} broadcast(bf16[] %constant.1632), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.61/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.2988 = bf16[4096]{0} multiply(bf16[4096]{0} %p345.1633, bf16[4096]{0} %broadcast.2987), metadata={op_type="aten__add" op_name="aten__add.61/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.2989 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.2988), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.61/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.2990 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.2986, bf16[1,1025,4096]{2,1,0} %broadcast.2989), metadata={op_type="aten__add" op_name="aten__add.61/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.2991 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2999 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2991), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3000 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2990, bf16[1,1025,4096]{2,1,0} %broadcast.2999), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2993 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2994 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2993), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.2995 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.2990, bf16[1,1025,4096]{2,1,0} %broadcast.2994), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.2996 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.2995), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.2992 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.2997 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.2992), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.2998 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.2996, bf16[1,1025,4096]{2,1,0} %broadcast.2997), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3001 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3000, bf16[1,1025,4096]{2,1,0} %add.2998), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3002 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3001), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p344.1630 = bf16[1024,4096]{1,0} parameter(344), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1631 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p344.1630), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3003 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3002, bf16[4096,1024]{0,1} %transpose.1631), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3004 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3003), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p343.1629 = bf16[1024]{0} parameter(343), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1628 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3005 = bf16[1024]{0} broadcast(bf16[] %constant.1628), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.62/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3006 = bf16[1024]{0} multiply(bf16[1024]{0} %p343.1629, bf16[1024]{0} %broadcast.3005), metadata={op_type="aten__add" op_name="aten__add.62/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3007 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3006), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.62/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3008 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3004, bf16[1,1025,1024]{2,1,0} %broadcast.3007), metadata={op_type="aten__add" op_name="aten__add.62/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3009 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3008), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p342.1626 = bf16[1024]{0} parameter(342), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1627 = f32[1024]{0} convert(bf16[1024]{0} %p342.1626), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3010 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1627), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.63/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3011 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3009, f32[1,1025,1024]{2,1,0} %broadcast.3010), metadata={op_type="aten__mul" op_name="aten__mul.63/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3012 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3011), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1625 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3013 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1625), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.64/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3014 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3012, bf16[1,1025,1024]{2,1,0} %broadcast.3013), metadata={op_type="aten__add" op_name="aten__add.64/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3015 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.2967, bf16[1,1025,1024]{2,1,0} %multiply.3014), metadata={op_type="aten__add" op_name="aten__add.64/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1620 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1621 = bf16[1]{0} reshape(bf16[] %constant.1620), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1622 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1621), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1623 = bf16[] reshape(bf16[1]{0} %broadcast.1622), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1624 = bf16[1025]{0} broadcast(bf16[] %reshape.1623), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1615 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1616 = bf16[1]{0} reshape(bf16[] %constant.1615), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1617 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1616), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1618 = bf16[] reshape(bf16[1]{0} %broadcast.1617), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1619 = bf16[1025]{0} broadcast(bf16[] %reshape.1618), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3016 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3015, bf16[1025]{0} %broadcast.1624, bf16[1025]{0} %broadcast.1619), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3018 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3016), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3019 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3016), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3020 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3021 = bf16[1025]{0} broadcast(bf16[] %constant.3020), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3022 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3019, bf16[1025]{0} %broadcast.3021), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3023 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3022), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p447.3024 = bf16[1024]{0} parameter(447), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3030 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p447.3024), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3017 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3016), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p341.1604 = bf16[1024]{0} parameter(341), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3026 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p341.1604), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3027 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3017, bf16[1,1025,1024]{2,1,0} %broadcast.3026), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1603 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3025 = bf16[] convert(s64[] %constant.1603), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3028 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3025), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3029 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3027, bf16[1,1025,1024]{2,1,0} %broadcast.3028), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3031 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3030, bf16[1,1025,1024]{2,1,0} %multiply.3029), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3032 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3031), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p340.1601 = bf16[3072,1024]{1,0} parameter(340), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1602 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p340.1601), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3033 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3032, bf16[1024,3072]{0,1} %transpose.1602), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3034 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3033), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p339.1600 = bf16[3072]{0} parameter(339), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1599 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3035 = bf16[3072]{0} broadcast(bf16[] %constant.1599), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.65/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3036 = bf16[3072]{0} multiply(bf16[3072]{0} %p339.1600, bf16[3072]{0} %broadcast.3035), metadata={op_type="aten__add" op_name="aten__add.65/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3037 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3036), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.65/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3038 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3034, bf16[1,1025,3072]{2,1,0} %broadcast.3037), metadata={op_type="aten__add" op_name="aten__add.65/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3039 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3038), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3040 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3039), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3050 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3040), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3051 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3050), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3052 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3051), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3053 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.66/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3054 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3052, f32[1,16,1025,64]{3,2,1,0} %broadcast.3053), metadata={op_type="aten__mul" op_name="aten__mul.66/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3055 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3054), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3056 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3055), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3057 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3056), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3045 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3040), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3046 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3045), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3047 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3046), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3048 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3047), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3049 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3048), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3058 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3057, bf16[16,64,1025]{2,1,0} %reshape.3049), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3059 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3058), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3060 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3065 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3059, bf16[] %constant.3060), dimensions={3}, to_apply=%MaxComputation.3061, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3066 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3065), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3067 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3059, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3066), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3068 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3067), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3069 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3074 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3068, bf16[] %constant.3069), dimensions={3}, to_apply=%AddComputation.3070, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3075 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3074), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3076 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3068, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3075), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3077 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3076), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3078 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3077), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3041 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3040), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3042 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3041), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3043 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3042), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3044 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3043), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3079 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3078, bf16[16,1025,64]{2,1,0} %reshape.3044), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3080 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3079), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3081 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3080), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3082 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3081), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3083 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3082), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p338.1597 = bf16[1024,1024]{1,0} parameter(338), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1598 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p338.1597), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3084 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3083, bf16[1024,1024]{0,1} %transpose.1598), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3085 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3084), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p337.1596 = bf16[1024]{0} parameter(337), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1595 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3086 = bf16[1024]{0} broadcast(bf16[] %constant.1595), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3087 = bf16[1024]{0} multiply(bf16[1024]{0} %p337.1596, bf16[1024]{0} %broadcast.3086), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3088 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3087), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3089 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3085, bf16[1,1025,1024]{2,1,0} %broadcast.3088), metadata={op_type="aten__add" op_name="aten__add.67/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3090 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3089), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p336.1593 = bf16[1024]{0} parameter(336), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1594 = f32[1024]{0} convert(bf16[1024]{0} %p336.1593), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3091 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1594), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.68/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3092 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3090, f32[1,1025,1024]{2,1,0} %broadcast.3091), metadata={op_type="aten__mul" op_name="aten__mul.68/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3093 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3092), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1592 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3094 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1592), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.69/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3095 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3093, bf16[1,1025,1024]{2,1,0} %broadcast.3094), metadata={op_type="aten__add" op_name="aten__add.69/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3096 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3015, bf16[1,1025,1024]{2,1,0} %multiply.3095), metadata={op_type="aten__add" op_name="aten__add.69/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1587 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1588 = bf16[1]{0} reshape(bf16[] %constant.1587), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1589 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1588), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1590 = bf16[] reshape(bf16[1]{0} %broadcast.1589), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1591 = bf16[1025]{0} broadcast(bf16[] %reshape.1590), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1582 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1583 = bf16[1]{0} reshape(bf16[] %constant.1582), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1584 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1583), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1585 = bf16[] reshape(bf16[1]{0} %broadcast.1584), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1586 = bf16[1025]{0} broadcast(bf16[] %reshape.1585), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3097 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3096, bf16[1025]{0} %broadcast.1591, bf16[1025]{0} %broadcast.1586), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3099 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3097), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3100 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3097), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3101 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3102 = bf16[1025]{0} broadcast(bf16[] %constant.3101), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3103 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3100, bf16[1025]{0} %broadcast.3102), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3104 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3103), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p448.3105 = bf16[1024]{0} parameter(448), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3111 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p448.3105), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3098 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3097), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p335.1571 = bf16[1024]{0} parameter(335), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3107 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p335.1571), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3108 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3098, bf16[1,1025,1024]{2,1,0} %broadcast.3107), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1570 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3106 = bf16[] convert(s64[] %constant.1570), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3109 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3106), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3110 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3108, bf16[1,1025,1024]{2,1,0} %broadcast.3109), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3112 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3111, bf16[1,1025,1024]{2,1,0} %multiply.3110), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3113 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3112), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p334.1568 = bf16[4096,1024]{1,0} parameter(334), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1569 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p334.1568), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3114 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3113, bf16[1024,4096]{0,1} %transpose.1569), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3115 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3114), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p333.1567 = bf16[4096]{0} parameter(333), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1566 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3116 = bf16[4096]{0} broadcast(bf16[] %constant.1566), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.70/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3117 = bf16[4096]{0} multiply(bf16[4096]{0} %p333.1567, bf16[4096]{0} %broadcast.3116), metadata={op_type="aten__add" op_name="aten__add.70/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3118 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3117), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.70/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3119 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3115, bf16[1,1025,4096]{2,1,0} %broadcast.3118), metadata={op_type="aten__add" op_name="aten__add.70/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3120 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3128 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3120), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3129 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3119, bf16[1,1025,4096]{2,1,0} %broadcast.3128), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3122 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3123 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3122), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3124 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3119, bf16[1,1025,4096]{2,1,0} %broadcast.3123), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3125 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3124), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3121 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3126 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3121), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3127 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3125, bf16[1,1025,4096]{2,1,0} %broadcast.3126), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3130 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3129, bf16[1,1025,4096]{2,1,0} %add.3127), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3131 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3130), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p332.1564 = bf16[1024,4096]{1,0} parameter(332), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1565 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p332.1564), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3132 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3131, bf16[4096,1024]{0,1} %transpose.1565), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3133 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3132), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p331.1563 = bf16[1024]{0} parameter(331), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1562 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3134 = bf16[1024]{0} broadcast(bf16[] %constant.1562), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.71/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3135 = bf16[1024]{0} multiply(bf16[1024]{0} %p331.1563, bf16[1024]{0} %broadcast.3134), metadata={op_type="aten__add" op_name="aten__add.71/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3136 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3135), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.71/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3137 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3133, bf16[1,1025,1024]{2,1,0} %broadcast.3136), metadata={op_type="aten__add" op_name="aten__add.71/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3138 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3137), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p330.1560 = bf16[1024]{0} parameter(330), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1561 = f32[1024]{0} convert(bf16[1024]{0} %p330.1560), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3139 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1561), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.72/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3140 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3138, f32[1,1025,1024]{2,1,0} %broadcast.3139), metadata={op_type="aten__mul" op_name="aten__mul.72/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3141 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3140), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1559 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3142 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1559), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.73/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3143 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3141, bf16[1,1025,1024]{2,1,0} %broadcast.3142), metadata={op_type="aten__add" op_name="aten__add.73/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3144 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3096, bf16[1,1025,1024]{2,1,0} %multiply.3143), metadata={op_type="aten__add" op_name="aten__add.73/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1554 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1555 = bf16[1]{0} reshape(bf16[] %constant.1554), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1556 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1555), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1557 = bf16[] reshape(bf16[1]{0} %broadcast.1556), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1558 = bf16[1025]{0} broadcast(bf16[] %reshape.1557), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1549 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1550 = bf16[1]{0} reshape(bf16[] %constant.1549), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1551 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1550), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1552 = bf16[] reshape(bf16[1]{0} %broadcast.1551), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1553 = bf16[1025]{0} broadcast(bf16[] %reshape.1552), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3145 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3144, bf16[1025]{0} %broadcast.1558, bf16[1025]{0} %broadcast.1553), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3147 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3145), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3148 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3145), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3149 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3150 = bf16[1025]{0} broadcast(bf16[] %constant.3149), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3151 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3148, bf16[1025]{0} %broadcast.3150), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3152 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3151), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p449.3153 = bf16[1024]{0} parameter(449), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3159 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p449.3153), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3146 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3145), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p329.1538 = bf16[1024]{0} parameter(329), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3155 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p329.1538), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3156 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3146, bf16[1,1025,1024]{2,1,0} %broadcast.3155), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1537 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3154 = bf16[] convert(s64[] %constant.1537), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3157 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3154), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3158 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3156, bf16[1,1025,1024]{2,1,0} %broadcast.3157), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3160 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3159, bf16[1,1025,1024]{2,1,0} %multiply.3158), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3161 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3160), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p328.1535 = bf16[3072,1024]{1,0} parameter(328), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1536 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p328.1535), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3162 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3161, bf16[1024,3072]{0,1} %transpose.1536), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3163 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3162), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p327.1534 = bf16[3072]{0} parameter(327), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1533 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3164 = bf16[3072]{0} broadcast(bf16[] %constant.1533), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.74/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3165 = bf16[3072]{0} multiply(bf16[3072]{0} %p327.1534, bf16[3072]{0} %broadcast.3164), metadata={op_type="aten__add" op_name="aten__add.74/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3166 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3165), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.74/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3167 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3163, bf16[1,1025,3072]{2,1,0} %broadcast.3166), metadata={op_type="aten__add" op_name="aten__add.74/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3168 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3167), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3169 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3168), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3179 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3169), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3180 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3179), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3181 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3180), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3182 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.75/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3183 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3181, f32[1,16,1025,64]{3,2,1,0} %broadcast.3182), metadata={op_type="aten__mul" op_name="aten__mul.75/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3184 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3183), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3185 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3184), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3186 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3185), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3174 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3169), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3175 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3174), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3176 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3175), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3177 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3176), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3178 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3177), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3187 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3186, bf16[16,64,1025]{2,1,0} %reshape.3178), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3188 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3187), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3189 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3194 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3188, bf16[] %constant.3189), dimensions={3}, to_apply=%MaxComputation.3190, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3195 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3194), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3196 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3188, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3195), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3197 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3196), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3198 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3203 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3197, bf16[] %constant.3198), dimensions={3}, to_apply=%AddComputation.3199, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3204 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3203), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3205 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3197, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3204), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3206 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3205), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3207 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3206), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3170 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3169), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3171 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3170), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3172 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3171), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3173 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3172), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3208 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3207, bf16[16,1025,64]{2,1,0} %reshape.3173), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3209 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3208), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3210 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3209), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3211 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3210), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3212 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3211), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p326.1531 = bf16[1024,1024]{1,0} parameter(326), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1532 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p326.1531), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3213 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3212, bf16[1024,1024]{0,1} %transpose.1532), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3214 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3213), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p325.1530 = bf16[1024]{0} parameter(325), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1529 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3215 = bf16[1024]{0} broadcast(bf16[] %constant.1529), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.76/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3216 = bf16[1024]{0} multiply(bf16[1024]{0} %p325.1530, bf16[1024]{0} %broadcast.3215), metadata={op_type="aten__add" op_name="aten__add.76/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3217 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3216), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.76/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3218 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3214, bf16[1,1025,1024]{2,1,0} %broadcast.3217), metadata={op_type="aten__add" op_name="aten__add.76/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3219 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3218), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p324.1527 = bf16[1024]{0} parameter(324), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1528 = f32[1024]{0} convert(bf16[1024]{0} %p324.1527), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3220 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1528), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.77/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3221 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3219, f32[1,1025,1024]{2,1,0} %broadcast.3220), metadata={op_type="aten__mul" op_name="aten__mul.77/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3222 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3221), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1526 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3223 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1526), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.78/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3224 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3222, bf16[1,1025,1024]{2,1,0} %broadcast.3223), metadata={op_type="aten__add" op_name="aten__add.78/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3225 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3144, bf16[1,1025,1024]{2,1,0} %multiply.3224), metadata={op_type="aten__add" op_name="aten__add.78/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1521 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1522 = bf16[1]{0} reshape(bf16[] %constant.1521), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1523 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1522), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1524 = bf16[] reshape(bf16[1]{0} %broadcast.1523), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1525 = bf16[1025]{0} broadcast(bf16[] %reshape.1524), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1516 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1517 = bf16[1]{0} reshape(bf16[] %constant.1516), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1518 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1517), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1519 = bf16[] reshape(bf16[1]{0} %broadcast.1518), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1520 = bf16[1025]{0} broadcast(bf16[] %reshape.1519), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3226 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3225, bf16[1025]{0} %broadcast.1525, bf16[1025]{0} %broadcast.1520), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3228 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3226), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3229 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3226), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3230 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3231 = bf16[1025]{0} broadcast(bf16[] %constant.3230), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3232 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3229, bf16[1025]{0} %broadcast.3231), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3233 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3232), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p450.3234 = bf16[1024]{0} parameter(450), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3240 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p450.3234), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3227 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3226), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p323.1505 = bf16[1024]{0} parameter(323), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3236 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p323.1505), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3237 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3227, bf16[1,1025,1024]{2,1,0} %broadcast.3236), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1504 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3235 = bf16[] convert(s64[] %constant.1504), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3238 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3235), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3239 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3237, bf16[1,1025,1024]{2,1,0} %broadcast.3238), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3241 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3240, bf16[1,1025,1024]{2,1,0} %multiply.3239), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3242 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3241), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p322.1502 = bf16[4096,1024]{1,0} parameter(322), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1503 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p322.1502), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3243 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3242, bf16[1024,4096]{0,1} %transpose.1503), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3244 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3243), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p321.1501 = bf16[4096]{0} parameter(321), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1500 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3245 = bf16[4096]{0} broadcast(bf16[] %constant.1500), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.79/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3246 = bf16[4096]{0} multiply(bf16[4096]{0} %p321.1501, bf16[4096]{0} %broadcast.3245), metadata={op_type="aten__add" op_name="aten__add.79/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3247 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3246), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.79/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3248 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3244, bf16[1,1025,4096]{2,1,0} %broadcast.3247), metadata={op_type="aten__add" op_name="aten__add.79/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3249 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3257 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3249), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3258 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3248, bf16[1,1025,4096]{2,1,0} %broadcast.3257), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3251 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3252 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3251), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3253 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3248, bf16[1,1025,4096]{2,1,0} %broadcast.3252), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3254 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3253), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3250 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3255 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3250), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3256 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3254, bf16[1,1025,4096]{2,1,0} %broadcast.3255), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3259 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3258, bf16[1,1025,4096]{2,1,0} %add.3256), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3260 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3259), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p320.1498 = bf16[1024,4096]{1,0} parameter(320), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1499 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p320.1498), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3261 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3260, bf16[4096,1024]{0,1} %transpose.1499), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3262 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3261), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p319.1497 = bf16[1024]{0} parameter(319), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1496 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3263 = bf16[1024]{0} broadcast(bf16[] %constant.1496), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.80/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3264 = bf16[1024]{0} multiply(bf16[1024]{0} %p319.1497, bf16[1024]{0} %broadcast.3263), metadata={op_type="aten__add" op_name="aten__add.80/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3265 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3264), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.80/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3266 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3262, bf16[1,1025,1024]{2,1,0} %broadcast.3265), metadata={op_type="aten__add" op_name="aten__add.80/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3267 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3266), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p318.1494 = bf16[1024]{0} parameter(318), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1495 = f32[1024]{0} convert(bf16[1024]{0} %p318.1494), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3268 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1495), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.81/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3269 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3267, f32[1,1025,1024]{2,1,0} %broadcast.3268), metadata={op_type="aten__mul" op_name="aten__mul.81/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3270 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3269), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1493 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3271 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1493), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.82/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3272 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3270, bf16[1,1025,1024]{2,1,0} %broadcast.3271), metadata={op_type="aten__add" op_name="aten__add.82/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3273 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3225, bf16[1,1025,1024]{2,1,0} %multiply.3272), metadata={op_type="aten__add" op_name="aten__add.82/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1488 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1489 = bf16[1]{0} reshape(bf16[] %constant.1488), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1490 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1489), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1491 = bf16[] reshape(bf16[1]{0} %broadcast.1490), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1492 = bf16[1025]{0} broadcast(bf16[] %reshape.1491), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1483 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1484 = bf16[1]{0} reshape(bf16[] %constant.1483), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1485 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1484), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1486 = bf16[] reshape(bf16[1]{0} %broadcast.1485), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1487 = bf16[1025]{0} broadcast(bf16[] %reshape.1486), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3274 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3273, bf16[1025]{0} %broadcast.1492, bf16[1025]{0} %broadcast.1487), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3276 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3274), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3277 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3274), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3278 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3279 = bf16[1025]{0} broadcast(bf16[] %constant.3278), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3280 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3277, bf16[1025]{0} %broadcast.3279), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3281 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3280), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p451.3282 = bf16[1024]{0} parameter(451), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3288 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p451.3282), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3275 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3274), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p317.1472 = bf16[1024]{0} parameter(317), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3284 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p317.1472), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3285 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3275, bf16[1,1025,1024]{2,1,0} %broadcast.3284), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1471 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3283 = bf16[] convert(s64[] %constant.1471), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3286 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3283), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3287 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3285, bf16[1,1025,1024]{2,1,0} %broadcast.3286), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3289 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3288, bf16[1,1025,1024]{2,1,0} %multiply.3287), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3290 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3289), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p316.1469 = bf16[3072,1024]{1,0} parameter(316), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1470 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p316.1469), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3291 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3290, bf16[1024,3072]{0,1} %transpose.1470), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3292 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3291), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p315.1468 = bf16[3072]{0} parameter(315), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1467 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3293 = bf16[3072]{0} broadcast(bf16[] %constant.1467), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.83/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3294 = bf16[3072]{0} multiply(bf16[3072]{0} %p315.1468, bf16[3072]{0} %broadcast.3293), metadata={op_type="aten__add" op_name="aten__add.83/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3295 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3294), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.83/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3296 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3292, bf16[1,1025,3072]{2,1,0} %broadcast.3295), metadata={op_type="aten__add" op_name="aten__add.83/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3297 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3296), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3298 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3297), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3308 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3298), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3309 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3308), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3310 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3309), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3311 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.84/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3312 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3310, f32[1,16,1025,64]{3,2,1,0} %broadcast.3311), metadata={op_type="aten__mul" op_name="aten__mul.84/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3313 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3312), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3314 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3313), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3315 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3314), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3303 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3298), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3304 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3303), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3305 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3304), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3306 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3305), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3307 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3306), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3316 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3315, bf16[16,64,1025]{2,1,0} %reshape.3307), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3317 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3316), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3318 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3323 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3317, bf16[] %constant.3318), dimensions={3}, to_apply=%MaxComputation.3319, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3324 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3323), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3325 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3317, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3324), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3326 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3325), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3327 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3332 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3326, bf16[] %constant.3327), dimensions={3}, to_apply=%AddComputation.3328, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3333 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3332), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3334 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3326, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3333), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3335 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3334), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3336 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3335), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3299 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3298), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3300 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3299), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3301 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3300), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3302 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3301), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3337 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3336, bf16[16,1025,64]{2,1,0} %reshape.3302), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3338 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3337), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3339 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3338), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3340 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3339), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3341 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3340), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p314.1465 = bf16[1024,1024]{1,0} parameter(314), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1466 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p314.1465), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3342 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3341, bf16[1024,1024]{0,1} %transpose.1466), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3343 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3342), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p313.1464 = bf16[1024]{0} parameter(313), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1463 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3344 = bf16[1024]{0} broadcast(bf16[] %constant.1463), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3345 = bf16[1024]{0} multiply(bf16[1024]{0} %p313.1464, bf16[1024]{0} %broadcast.3344), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3346 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3345), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3347 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3343, bf16[1,1025,1024]{2,1,0} %broadcast.3346), metadata={op_type="aten__add" op_name="aten__add.85/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3348 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3347), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p312.1461 = bf16[1024]{0} parameter(312), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1462 = f32[1024]{0} convert(bf16[1024]{0} %p312.1461), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3349 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1462), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.86/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3350 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3348, f32[1,1025,1024]{2,1,0} %broadcast.3349), metadata={op_type="aten__mul" op_name="aten__mul.86/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3351 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3350), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1460 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3352 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1460), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.87/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3353 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3351, bf16[1,1025,1024]{2,1,0} %broadcast.3352), metadata={op_type="aten__add" op_name="aten__add.87/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3354 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3273, bf16[1,1025,1024]{2,1,0} %multiply.3353), metadata={op_type="aten__add" op_name="aten__add.87/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1455 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1456 = bf16[1]{0} reshape(bf16[] %constant.1455), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1457 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1456), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1458 = bf16[] reshape(bf16[1]{0} %broadcast.1457), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1459 = bf16[1025]{0} broadcast(bf16[] %reshape.1458), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1450 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1451 = bf16[1]{0} reshape(bf16[] %constant.1450), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1452 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1451), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1453 = bf16[] reshape(bf16[1]{0} %broadcast.1452), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1454 = bf16[1025]{0} broadcast(bf16[] %reshape.1453), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3355 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3354, bf16[1025]{0} %broadcast.1459, bf16[1025]{0} %broadcast.1454), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3357 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3355), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3358 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3355), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3359 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3360 = bf16[1025]{0} broadcast(bf16[] %constant.3359), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3361 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3358, bf16[1025]{0} %broadcast.3360), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3362 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3361), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p452.3363 = bf16[1024]{0} parameter(452), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3369 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p452.3363), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3356 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3355), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p311.1439 = bf16[1024]{0} parameter(311), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3365 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p311.1439), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3366 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3356, bf16[1,1025,1024]{2,1,0} %broadcast.3365), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1438 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3364 = bf16[] convert(s64[] %constant.1438), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3367 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3364), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3368 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3366, bf16[1,1025,1024]{2,1,0} %broadcast.3367), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3370 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3369, bf16[1,1025,1024]{2,1,0} %multiply.3368), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3371 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3370), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p310.1436 = bf16[4096,1024]{1,0} parameter(310), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1437 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p310.1436), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3372 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3371, bf16[1024,4096]{0,1} %transpose.1437), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3373 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3372), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p309.1435 = bf16[4096]{0} parameter(309), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1434 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3374 = bf16[4096]{0} broadcast(bf16[] %constant.1434), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.88/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3375 = bf16[4096]{0} multiply(bf16[4096]{0} %p309.1435, bf16[4096]{0} %broadcast.3374), metadata={op_type="aten__add" op_name="aten__add.88/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3376 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3375), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.88/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3377 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3373, bf16[1,1025,4096]{2,1,0} %broadcast.3376), metadata={op_type="aten__add" op_name="aten__add.88/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3378 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3386 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3378), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3387 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3377, bf16[1,1025,4096]{2,1,0} %broadcast.3386), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3380 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3381 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3380), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3382 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3377, bf16[1,1025,4096]{2,1,0} %broadcast.3381), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3383 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3382), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3379 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3384 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3379), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3385 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3383, bf16[1,1025,4096]{2,1,0} %broadcast.3384), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3388 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3387, bf16[1,1025,4096]{2,1,0} %add.3385), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3389 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3388), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p308.1432 = bf16[1024,4096]{1,0} parameter(308), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1433 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p308.1432), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3390 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3389, bf16[4096,1024]{0,1} %transpose.1433), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3391 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3390), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p307.1431 = bf16[1024]{0} parameter(307), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1430 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3392 = bf16[1024]{0} broadcast(bf16[] %constant.1430), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.89/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3393 = bf16[1024]{0} multiply(bf16[1024]{0} %p307.1431, bf16[1024]{0} %broadcast.3392), metadata={op_type="aten__add" op_name="aten__add.89/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3394 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3393), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.89/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3395 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3391, bf16[1,1025,1024]{2,1,0} %broadcast.3394), metadata={op_type="aten__add" op_name="aten__add.89/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3396 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3395), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p306.1428 = bf16[1024]{0} parameter(306), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1429 = f32[1024]{0} convert(bf16[1024]{0} %p306.1428), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3397 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1429), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.90/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3398 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3396, f32[1,1025,1024]{2,1,0} %broadcast.3397), metadata={op_type="aten__mul" op_name="aten__mul.90/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3399 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3398), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1427 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3400 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1427), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.91/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3401 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3399, bf16[1,1025,1024]{2,1,0} %broadcast.3400), metadata={op_type="aten__add" op_name="aten__add.91/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3402 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3354, bf16[1,1025,1024]{2,1,0} %multiply.3401), metadata={op_type="aten__add" op_name="aten__add.91/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1422 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1423 = bf16[1]{0} reshape(bf16[] %constant.1422), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1424 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1423), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1425 = bf16[] reshape(bf16[1]{0} %broadcast.1424), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1426 = bf16[1025]{0} broadcast(bf16[] %reshape.1425), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1417 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1418 = bf16[1]{0} reshape(bf16[] %constant.1417), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1419 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1418), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1420 = bf16[] reshape(bf16[1]{0} %broadcast.1419), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1421 = bf16[1025]{0} broadcast(bf16[] %reshape.1420), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3403 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3402, bf16[1025]{0} %broadcast.1426, bf16[1025]{0} %broadcast.1421), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3405 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3403), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3406 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3403), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3407 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3408 = bf16[1025]{0} broadcast(bf16[] %constant.3407), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3409 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3406, bf16[1025]{0} %broadcast.3408), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3410 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3409), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p453.3411 = bf16[1024]{0} parameter(453), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3417 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p453.3411), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3404 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3403), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p305.1406 = bf16[1024]{0} parameter(305), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3413 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p305.1406), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3414 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3404, bf16[1,1025,1024]{2,1,0} %broadcast.3413), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1405 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3412 = bf16[] convert(s64[] %constant.1405), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3415 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3412), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3416 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3414, bf16[1,1025,1024]{2,1,0} %broadcast.3415), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3418 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3417, bf16[1,1025,1024]{2,1,0} %multiply.3416), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3419 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3418), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p304.1403 = bf16[3072,1024]{1,0} parameter(304), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1404 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p304.1403), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3420 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3419, bf16[1024,3072]{0,1} %transpose.1404), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3421 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3420), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p303.1402 = bf16[3072]{0} parameter(303), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1401 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3422 = bf16[3072]{0} broadcast(bf16[] %constant.1401), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.92/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3423 = bf16[3072]{0} multiply(bf16[3072]{0} %p303.1402, bf16[3072]{0} %broadcast.3422), metadata={op_type="aten__add" op_name="aten__add.92/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3424 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3423), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.92/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3425 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3421, bf16[1,1025,3072]{2,1,0} %broadcast.3424), metadata={op_type="aten__add" op_name="aten__add.92/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3426 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3425), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3427 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3426), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3437 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3427), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3438 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3437), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3439 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3438), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3440 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.93/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3441 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3439, f32[1,16,1025,64]{3,2,1,0} %broadcast.3440), metadata={op_type="aten__mul" op_name="aten__mul.93/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3442 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3441), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3443 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3442), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3444 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3443), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3432 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3427), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3433 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3432), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3434 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3433), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3435 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3434), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3436 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3435), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3445 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3444, bf16[16,64,1025]{2,1,0} %reshape.3436), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3446 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3445), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3447 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3452 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3446, bf16[] %constant.3447), dimensions={3}, to_apply=%MaxComputation.3448, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3453 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3452), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3454 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3446, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3453), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3455 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3454), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3456 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3461 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3455, bf16[] %constant.3456), dimensions={3}, to_apply=%AddComputation.3457, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3462 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3461), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3463 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3455, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3462), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3464 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3463), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3465 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3464), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3428 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3427), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3429 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3428), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3430 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3429), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3431 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3430), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3466 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3465, bf16[16,1025,64]{2,1,0} %reshape.3431), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3467 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3466), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3468 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3467), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3469 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3468), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3470 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3469), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p302.1399 = bf16[1024,1024]{1,0} parameter(302), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1400 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p302.1399), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3471 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3470, bf16[1024,1024]{0,1} %transpose.1400), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3472 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3471), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p301.1398 = bf16[1024]{0} parameter(301), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1397 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3473 = bf16[1024]{0} broadcast(bf16[] %constant.1397), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3474 = bf16[1024]{0} multiply(bf16[1024]{0} %p301.1398, bf16[1024]{0} %broadcast.3473), metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3475 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3474), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3476 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3472, bf16[1,1025,1024]{2,1,0} %broadcast.3475), metadata={op_type="aten__add" op_name="aten__add.94/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3477 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3476), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p300.1395 = bf16[1024]{0} parameter(300), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1396 = f32[1024]{0} convert(bf16[1024]{0} %p300.1395), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3478 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1396), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.95/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3479 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3477, f32[1,1025,1024]{2,1,0} %broadcast.3478), metadata={op_type="aten__mul" op_name="aten__mul.95/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3480 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3479), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1394 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3481 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1394), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.96/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3482 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3480, bf16[1,1025,1024]{2,1,0} %broadcast.3481), metadata={op_type="aten__add" op_name="aten__add.96/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3483 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3402, bf16[1,1025,1024]{2,1,0} %multiply.3482), metadata={op_type="aten__add" op_name="aten__add.96/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1389 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1390 = bf16[1]{0} reshape(bf16[] %constant.1389), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1391 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1390), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1392 = bf16[] reshape(bf16[1]{0} %broadcast.1391), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1393 = bf16[1025]{0} broadcast(bf16[] %reshape.1392), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1384 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1385 = bf16[1]{0} reshape(bf16[] %constant.1384), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1386 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1385), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1387 = bf16[] reshape(bf16[1]{0} %broadcast.1386), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1388 = bf16[1025]{0} broadcast(bf16[] %reshape.1387), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3484 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3483, bf16[1025]{0} %broadcast.1393, bf16[1025]{0} %broadcast.1388), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3486 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3484), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3487 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3484), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3488 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3489 = bf16[1025]{0} broadcast(bf16[] %constant.3488), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3490 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3487, bf16[1025]{0} %broadcast.3489), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3491 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3490), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p454.3492 = bf16[1024]{0} parameter(454), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3498 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p454.3492), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3485 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3484), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p299.1373 = bf16[1024]{0} parameter(299), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3494 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p299.1373), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3495 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3485, bf16[1,1025,1024]{2,1,0} %broadcast.3494), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1372 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3493 = bf16[] convert(s64[] %constant.1372), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3496 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3493), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3497 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3495, bf16[1,1025,1024]{2,1,0} %broadcast.3496), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3499 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3498, bf16[1,1025,1024]{2,1,0} %multiply.3497), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3500 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3499), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p298.1370 = bf16[4096,1024]{1,0} parameter(298), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1371 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p298.1370), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3501 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3500, bf16[1024,4096]{0,1} %transpose.1371), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3502 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3501), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p297.1369 = bf16[4096]{0} parameter(297), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1368 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3503 = bf16[4096]{0} broadcast(bf16[] %constant.1368), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.97/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3504 = bf16[4096]{0} multiply(bf16[4096]{0} %p297.1369, bf16[4096]{0} %broadcast.3503), metadata={op_type="aten__add" op_name="aten__add.97/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3505 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3504), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.97/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3506 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3502, bf16[1,1025,4096]{2,1,0} %broadcast.3505), metadata={op_type="aten__add" op_name="aten__add.97/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3507 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3515 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3507), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3516 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3506, bf16[1,1025,4096]{2,1,0} %broadcast.3515), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3509 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3510 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3509), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3511 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3506, bf16[1,1025,4096]{2,1,0} %broadcast.3510), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3512 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3511), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3508 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3513 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3508), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3514 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3512, bf16[1,1025,4096]{2,1,0} %broadcast.3513), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3517 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3516, bf16[1,1025,4096]{2,1,0} %add.3514), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3518 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3517), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p296.1366 = bf16[1024,4096]{1,0} parameter(296), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1367 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p296.1366), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3519 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3518, bf16[4096,1024]{0,1} %transpose.1367), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3520 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3519), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p295.1365 = bf16[1024]{0} parameter(295), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1364 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3521 = bf16[1024]{0} broadcast(bf16[] %constant.1364), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.98/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3522 = bf16[1024]{0} multiply(bf16[1024]{0} %p295.1365, bf16[1024]{0} %broadcast.3521), metadata={op_type="aten__add" op_name="aten__add.98/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3523 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3522), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.98/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3524 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3520, bf16[1,1025,1024]{2,1,0} %broadcast.3523), metadata={op_type="aten__add" op_name="aten__add.98/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3525 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3524), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p294.1362 = bf16[1024]{0} parameter(294), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1363 = f32[1024]{0} convert(bf16[1024]{0} %p294.1362), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3526 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1363), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.99/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3527 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3525, f32[1,1025,1024]{2,1,0} %broadcast.3526), metadata={op_type="aten__mul" op_name="aten__mul.99/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3528 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3527), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1361 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3529 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1361), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.100/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3530 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3528, bf16[1,1025,1024]{2,1,0} %broadcast.3529), metadata={op_type="aten__add" op_name="aten__add.100/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3531 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3483, bf16[1,1025,1024]{2,1,0} %multiply.3530), metadata={op_type="aten__add" op_name="aten__add.100/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1356 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1357 = bf16[1]{0} reshape(bf16[] %constant.1356), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1358 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1357), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1359 = bf16[] reshape(bf16[1]{0} %broadcast.1358), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1360 = bf16[1025]{0} broadcast(bf16[] %reshape.1359), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1351 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1352 = bf16[1]{0} reshape(bf16[] %constant.1351), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1353 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1352), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1354 = bf16[] reshape(bf16[1]{0} %broadcast.1353), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1355 = bf16[1025]{0} broadcast(bf16[] %reshape.1354), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3532 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3531, bf16[1025]{0} %broadcast.1360, bf16[1025]{0} %broadcast.1355), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3534 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3532), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3535 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3532), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3536 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3537 = bf16[1025]{0} broadcast(bf16[] %constant.3536), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3538 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3535, bf16[1025]{0} %broadcast.3537), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3539 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3538), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p455.3540 = bf16[1024]{0} parameter(455), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3546 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p455.3540), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3533 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3532), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p293.1340 = bf16[1024]{0} parameter(293), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3542 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p293.1340), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3543 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3533, bf16[1,1025,1024]{2,1,0} %broadcast.3542), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1339 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3541 = bf16[] convert(s64[] %constant.1339), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3544 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3541), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3545 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3543, bf16[1,1025,1024]{2,1,0} %broadcast.3544), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3547 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3546, bf16[1,1025,1024]{2,1,0} %multiply.3545), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3548 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3547), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p292.1337 = bf16[3072,1024]{1,0} parameter(292), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1338 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p292.1337), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3549 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3548, bf16[1024,3072]{0,1} %transpose.1338), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3550 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3549), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p291.1336 = bf16[3072]{0} parameter(291), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1335 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3551 = bf16[3072]{0} broadcast(bf16[] %constant.1335), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.101/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3552 = bf16[3072]{0} multiply(bf16[3072]{0} %p291.1336, bf16[3072]{0} %broadcast.3551), metadata={op_type="aten__add" op_name="aten__add.101/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3553 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3552), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.101/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3554 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3550, bf16[1,1025,3072]{2,1,0} %broadcast.3553), metadata={op_type="aten__add" op_name="aten__add.101/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3555 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3554), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3556 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3555), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3566 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3556), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3567 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3566), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3568 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3567), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3569 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.102/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3570 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3568, f32[1,16,1025,64]{3,2,1,0} %broadcast.3569), metadata={op_type="aten__mul" op_name="aten__mul.102/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3571 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3570), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3572 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3571), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3573 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3572), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3561 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3556), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3562 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3561), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3563 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3562), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3564 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3563), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3565 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3564), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3574 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3573, bf16[16,64,1025]{2,1,0} %reshape.3565), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3575 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3574), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3576 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3581 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3575, bf16[] %constant.3576), dimensions={3}, to_apply=%MaxComputation.3577, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3582 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3581), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3583 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3575, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3582), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3584 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3583), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3585 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3590 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3584, bf16[] %constant.3585), dimensions={3}, to_apply=%AddComputation.3586, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3591 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3590), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3592 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3584, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3591), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3593 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3592), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3594 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3593), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3557 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3556), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3558 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3557), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3559 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3558), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3560 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3559), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3595 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3594, bf16[16,1025,64]{2,1,0} %reshape.3560), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3596 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3595), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3597 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3596), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3598 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3597), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3599 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3598), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p290.1333 = bf16[1024,1024]{1,0} parameter(290), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1334 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p290.1333), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3600 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3599, bf16[1024,1024]{0,1} %transpose.1334), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3601 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3600), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p289.1332 = bf16[1024]{0} parameter(289), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1331 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3602 = bf16[1024]{0} broadcast(bf16[] %constant.1331), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3603 = bf16[1024]{0} multiply(bf16[1024]{0} %p289.1332, bf16[1024]{0} %broadcast.3602), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3604 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3603), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3605 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3601, bf16[1,1025,1024]{2,1,0} %broadcast.3604), metadata={op_type="aten__add" op_name="aten__add.103/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3606 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3605), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p288.1329 = bf16[1024]{0} parameter(288), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1330 = f32[1024]{0} convert(bf16[1024]{0} %p288.1329), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3607 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1330), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.104/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3608 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3606, f32[1,1025,1024]{2,1,0} %broadcast.3607), metadata={op_type="aten__mul" op_name="aten__mul.104/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3609 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3608), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1328 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3610 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1328), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.105/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3611 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3609, bf16[1,1025,1024]{2,1,0} %broadcast.3610), metadata={op_type="aten__add" op_name="aten__add.105/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3612 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3531, bf16[1,1025,1024]{2,1,0} %multiply.3611), metadata={op_type="aten__add" op_name="aten__add.105/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1323 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1324 = bf16[1]{0} reshape(bf16[] %constant.1323), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1325 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1324), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1326 = bf16[] reshape(bf16[1]{0} %broadcast.1325), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1327 = bf16[1025]{0} broadcast(bf16[] %reshape.1326), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1318 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1319 = bf16[1]{0} reshape(bf16[] %constant.1318), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1320 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1319), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1321 = bf16[] reshape(bf16[1]{0} %broadcast.1320), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1322 = bf16[1025]{0} broadcast(bf16[] %reshape.1321), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3613 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3612, bf16[1025]{0} %broadcast.1327, bf16[1025]{0} %broadcast.1322), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3615 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3613), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3616 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3613), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3617 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3618 = bf16[1025]{0} broadcast(bf16[] %constant.3617), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3619 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3616, bf16[1025]{0} %broadcast.3618), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3620 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3619), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p456.3621 = bf16[1024]{0} parameter(456), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3627 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p456.3621), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3614 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3613), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p287.1307 = bf16[1024]{0} parameter(287), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3623 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p287.1307), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3624 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3614, bf16[1,1025,1024]{2,1,0} %broadcast.3623), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1306 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3622 = bf16[] convert(s64[] %constant.1306), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3625 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3622), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3626 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3624, bf16[1,1025,1024]{2,1,0} %broadcast.3625), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3628 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3627, bf16[1,1025,1024]{2,1,0} %multiply.3626), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3629 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3628), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p286.1304 = bf16[4096,1024]{1,0} parameter(286), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1305 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p286.1304), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3630 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3629, bf16[1024,4096]{0,1} %transpose.1305), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3631 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3630), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p285.1303 = bf16[4096]{0} parameter(285), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1302 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3632 = bf16[4096]{0} broadcast(bf16[] %constant.1302), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.106/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3633 = bf16[4096]{0} multiply(bf16[4096]{0} %p285.1303, bf16[4096]{0} %broadcast.3632), metadata={op_type="aten__add" op_name="aten__add.106/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3634 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3633), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.106/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3635 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3631, bf16[1,1025,4096]{2,1,0} %broadcast.3634), metadata={op_type="aten__add" op_name="aten__add.106/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3636 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3644 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3636), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3645 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3635, bf16[1,1025,4096]{2,1,0} %broadcast.3644), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3638 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3639 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3638), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3640 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3635, bf16[1,1025,4096]{2,1,0} %broadcast.3639), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3641 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3640), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3637 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3642 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3637), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3643 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3641, bf16[1,1025,4096]{2,1,0} %broadcast.3642), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3646 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3645, bf16[1,1025,4096]{2,1,0} %add.3643), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3647 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3646), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p284.1300 = bf16[1024,4096]{1,0} parameter(284), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1301 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p284.1300), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3648 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3647, bf16[4096,1024]{0,1} %transpose.1301), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3649 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3648), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p283.1299 = bf16[1024]{0} parameter(283), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1298 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3650 = bf16[1024]{0} broadcast(bf16[] %constant.1298), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.107/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3651 = bf16[1024]{0} multiply(bf16[1024]{0} %p283.1299, bf16[1024]{0} %broadcast.3650), metadata={op_type="aten__add" op_name="aten__add.107/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3652 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3651), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.107/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3653 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3649, bf16[1,1025,1024]{2,1,0} %broadcast.3652), metadata={op_type="aten__add" op_name="aten__add.107/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3654 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3653), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p282.1296 = bf16[1024]{0} parameter(282), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1297 = f32[1024]{0} convert(bf16[1024]{0} %p282.1296), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3655 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1297), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.108/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3656 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3654, f32[1,1025,1024]{2,1,0} %broadcast.3655), metadata={op_type="aten__mul" op_name="aten__mul.108/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3657 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3656), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1295 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3658 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1295), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.109/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3659 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3657, bf16[1,1025,1024]{2,1,0} %broadcast.3658), metadata={op_type="aten__add" op_name="aten__add.109/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3660 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3612, bf16[1,1025,1024]{2,1,0} %multiply.3659), metadata={op_type="aten__add" op_name="aten__add.109/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1290 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1291 = bf16[1]{0} reshape(bf16[] %constant.1290), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1292 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1291), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1293 = bf16[] reshape(bf16[1]{0} %broadcast.1292), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1294 = bf16[1025]{0} broadcast(bf16[] %reshape.1293), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1285 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1286 = bf16[1]{0} reshape(bf16[] %constant.1285), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1287 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1286), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1288 = bf16[] reshape(bf16[1]{0} %broadcast.1287), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1289 = bf16[1025]{0} broadcast(bf16[] %reshape.1288), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3661 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3660, bf16[1025]{0} %broadcast.1294, bf16[1025]{0} %broadcast.1289), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3663 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3661), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3664 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3661), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3665 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3666 = bf16[1025]{0} broadcast(bf16[] %constant.3665), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3667 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3664, bf16[1025]{0} %broadcast.3666), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3668 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3667), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p457.3669 = bf16[1024]{0} parameter(457), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3675 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p457.3669), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3662 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3661), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p281.1274 = bf16[1024]{0} parameter(281), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3671 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p281.1274), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3672 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3662, bf16[1,1025,1024]{2,1,0} %broadcast.3671), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1273 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3670 = bf16[] convert(s64[] %constant.1273), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3673 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3670), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3674 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3672, bf16[1,1025,1024]{2,1,0} %broadcast.3673), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3676 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3675, bf16[1,1025,1024]{2,1,0} %multiply.3674), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3677 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3676), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p280.1271 = bf16[3072,1024]{1,0} parameter(280), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1272 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p280.1271), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3678 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3677, bf16[1024,3072]{0,1} %transpose.1272), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3679 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3678), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p279.1270 = bf16[3072]{0} parameter(279), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1269 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3680 = bf16[3072]{0} broadcast(bf16[] %constant.1269), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.110/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3681 = bf16[3072]{0} multiply(bf16[3072]{0} %p279.1270, bf16[3072]{0} %broadcast.3680), metadata={op_type="aten__add" op_name="aten__add.110/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3682 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3681), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.110/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3683 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3679, bf16[1,1025,3072]{2,1,0} %broadcast.3682), metadata={op_type="aten__add" op_name="aten__add.110/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3684 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3683), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3685 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3684), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3695 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3685), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3696 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3695), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3697 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3696), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3698 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.111/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3699 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3697, f32[1,16,1025,64]{3,2,1,0} %broadcast.3698), metadata={op_type="aten__mul" op_name="aten__mul.111/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3700 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3699), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3701 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3700), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3702 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3701), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3690 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3685), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3691 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3690), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3692 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3691), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3693 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3692), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3694 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3693), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3703 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3702, bf16[16,64,1025]{2,1,0} %reshape.3694), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3704 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3703), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3705 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3710 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3704, bf16[] %constant.3705), dimensions={3}, to_apply=%MaxComputation.3706, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3711 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3710), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3712 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3704, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3711), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3713 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3712), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3714 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3719 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3713, bf16[] %constant.3714), dimensions={3}, to_apply=%AddComputation.3715, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3720 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3719), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3721 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3713, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3720), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3722 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3721), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3723 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3722), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3686 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3685), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3687 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3686), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3688 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3687), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3689 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3688), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3724 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3723, bf16[16,1025,64]{2,1,0} %reshape.3689), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3725 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3724), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3726 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3725), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3727 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3726), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3728 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3727), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p278.1267 = bf16[1024,1024]{1,0} parameter(278), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1268 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p278.1267), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3729 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3728, bf16[1024,1024]{0,1} %transpose.1268), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3730 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3729), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p277.1266 = bf16[1024]{0} parameter(277), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1265 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3731 = bf16[1024]{0} broadcast(bf16[] %constant.1265), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3732 = bf16[1024]{0} multiply(bf16[1024]{0} %p277.1266, bf16[1024]{0} %broadcast.3731), metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3733 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3732), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3734 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3730, bf16[1,1025,1024]{2,1,0} %broadcast.3733), metadata={op_type="aten__add" op_name="aten__add.112/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3735 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3734), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p276.1263 = bf16[1024]{0} parameter(276), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1264 = f32[1024]{0} convert(bf16[1024]{0} %p276.1263), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3736 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1264), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.113/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3737 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3735, f32[1,1025,1024]{2,1,0} %broadcast.3736), metadata={op_type="aten__mul" op_name="aten__mul.113/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3738 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3737), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1262 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3739 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1262), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.114/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3740 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3738, bf16[1,1025,1024]{2,1,0} %broadcast.3739), metadata={op_type="aten__add" op_name="aten__add.114/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3741 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3660, bf16[1,1025,1024]{2,1,0} %multiply.3740), metadata={op_type="aten__add" op_name="aten__add.114/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1257 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1258 = bf16[1]{0} reshape(bf16[] %constant.1257), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1259 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1258), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1260 = bf16[] reshape(bf16[1]{0} %broadcast.1259), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1261 = bf16[1025]{0} broadcast(bf16[] %reshape.1260), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1252 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1253 = bf16[1]{0} reshape(bf16[] %constant.1252), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1254 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1253), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1255 = bf16[] reshape(bf16[1]{0} %broadcast.1254), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1256 = bf16[1025]{0} broadcast(bf16[] %reshape.1255), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3742 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3741, bf16[1025]{0} %broadcast.1261, bf16[1025]{0} %broadcast.1256), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3744 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3742), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3745 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3742), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3746 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3747 = bf16[1025]{0} broadcast(bf16[] %constant.3746), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3748 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3745, bf16[1025]{0} %broadcast.3747), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3749 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3748), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p458.3750 = bf16[1024]{0} parameter(458), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3756 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p458.3750), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3743 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3742), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p275.1241 = bf16[1024]{0} parameter(275), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3752 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p275.1241), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3753 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3743, bf16[1,1025,1024]{2,1,0} %broadcast.3752), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1240 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3751 = bf16[] convert(s64[] %constant.1240), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3754 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3751), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3755 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3753, bf16[1,1025,1024]{2,1,0} %broadcast.3754), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3757 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3756, bf16[1,1025,1024]{2,1,0} %multiply.3755), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3758 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3757), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p274.1238 = bf16[4096,1024]{1,0} parameter(274), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1239 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p274.1238), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3759 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3758, bf16[1024,4096]{0,1} %transpose.1239), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3760 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3759), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p273.1237 = bf16[4096]{0} parameter(273), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1236 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3761 = bf16[4096]{0} broadcast(bf16[] %constant.1236), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.115/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3762 = bf16[4096]{0} multiply(bf16[4096]{0} %p273.1237, bf16[4096]{0} %broadcast.3761), metadata={op_type="aten__add" op_name="aten__add.115/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3763 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3762), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.115/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3764 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3760, bf16[1,1025,4096]{2,1,0} %broadcast.3763), metadata={op_type="aten__add" op_name="aten__add.115/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3765 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3773 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3765), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3774 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3764, bf16[1,1025,4096]{2,1,0} %broadcast.3773), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3767 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3768 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3767), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3769 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3764, bf16[1,1025,4096]{2,1,0} %broadcast.3768), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3770 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3769), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3766 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3771 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3766), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3772 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3770, bf16[1,1025,4096]{2,1,0} %broadcast.3771), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3775 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3774, bf16[1,1025,4096]{2,1,0} %add.3772), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3776 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3775), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p272.1234 = bf16[1024,4096]{1,0} parameter(272), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1235 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p272.1234), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3777 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3776, bf16[4096,1024]{0,1} %transpose.1235), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3778 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3777), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p271.1233 = bf16[1024]{0} parameter(271), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1232 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3779 = bf16[1024]{0} broadcast(bf16[] %constant.1232), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.116/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3780 = bf16[1024]{0} multiply(bf16[1024]{0} %p271.1233, bf16[1024]{0} %broadcast.3779), metadata={op_type="aten__add" op_name="aten__add.116/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3781 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3780), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.116/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3782 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3778, bf16[1,1025,1024]{2,1,0} %broadcast.3781), metadata={op_type="aten__add" op_name="aten__add.116/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3783 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3782), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p270.1230 = bf16[1024]{0} parameter(270), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1231 = f32[1024]{0} convert(bf16[1024]{0} %p270.1230), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3784 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1231), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.117/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3785 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3783, f32[1,1025,1024]{2,1,0} %broadcast.3784), metadata={op_type="aten__mul" op_name="aten__mul.117/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3786 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3785), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1229 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3787 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1229), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.118/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3788 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3786, bf16[1,1025,1024]{2,1,0} %broadcast.3787), metadata={op_type="aten__add" op_name="aten__add.118/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3789 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3741, bf16[1,1025,1024]{2,1,0} %multiply.3788), metadata={op_type="aten__add" op_name="aten__add.118/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1224 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1225 = bf16[1]{0} reshape(bf16[] %constant.1224), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1226 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1225), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1227 = bf16[] reshape(bf16[1]{0} %broadcast.1226), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1228 = bf16[1025]{0} broadcast(bf16[] %reshape.1227), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1219 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1220 = bf16[1]{0} reshape(bf16[] %constant.1219), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1221 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1220), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1222 = bf16[] reshape(bf16[1]{0} %broadcast.1221), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1223 = bf16[1025]{0} broadcast(bf16[] %reshape.1222), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3790 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3789, bf16[1025]{0} %broadcast.1228, bf16[1025]{0} %broadcast.1223), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3792 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3790), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3793 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3790), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3794 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3795 = bf16[1025]{0} broadcast(bf16[] %constant.3794), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3796 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3793, bf16[1025]{0} %broadcast.3795), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3797 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3796), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p459.3798 = bf16[1024]{0} parameter(459), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3804 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p459.3798), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3791 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3790), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p269.1208 = bf16[1024]{0} parameter(269), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3800 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p269.1208), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3801 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3791, bf16[1,1025,1024]{2,1,0} %broadcast.3800), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1207 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3799 = bf16[] convert(s64[] %constant.1207), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3802 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3799), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3803 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3801, bf16[1,1025,1024]{2,1,0} %broadcast.3802), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3805 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3804, bf16[1,1025,1024]{2,1,0} %multiply.3803), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3806 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3805), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p268.1205 = bf16[3072,1024]{1,0} parameter(268), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1206 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p268.1205), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3807 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3806, bf16[1024,3072]{0,1} %transpose.1206), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3808 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3807), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p267.1204 = bf16[3072]{0} parameter(267), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1203 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3809 = bf16[3072]{0} broadcast(bf16[] %constant.1203), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.119/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3810 = bf16[3072]{0} multiply(bf16[3072]{0} %p267.1204, bf16[3072]{0} %broadcast.3809), metadata={op_type="aten__add" op_name="aten__add.119/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3811 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3810), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.119/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3812 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3808, bf16[1,1025,3072]{2,1,0} %broadcast.3811), metadata={op_type="aten__add" op_name="aten__add.119/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3813 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3812), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3814 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3813), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3824 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3814), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3825 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3824), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3826 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3825), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3827 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.120/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3828 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3826, f32[1,16,1025,64]{3,2,1,0} %broadcast.3827), metadata={op_type="aten__mul" op_name="aten__mul.120/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3829 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3828), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3830 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3829), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3831 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3830), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3819 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3814), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3820 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3819), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3821 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3820), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3822 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3821), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3823 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3822), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3832 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3831, bf16[16,64,1025]{2,1,0} %reshape.3823), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3833 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3832), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3834 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3839 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3833, bf16[] %constant.3834), dimensions={3}, to_apply=%MaxComputation.3835, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3840 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3839), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3841 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3833, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3840), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3842 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3841), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3843 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3848 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3842, bf16[] %constant.3843), dimensions={3}, to_apply=%AddComputation.3844, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3849 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3848), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3850 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3842, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3849), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3851 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3850), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3852 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3851), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3815 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3814), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3816 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3815), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3817 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3816), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3818 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3817), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3853 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3852, bf16[16,1025,64]{2,1,0} %reshape.3818), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3854 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3853), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3855 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3854), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3856 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3855), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3857 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3856), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p266.1201 = bf16[1024,1024]{1,0} parameter(266), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1202 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p266.1201), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3858 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3857, bf16[1024,1024]{0,1} %transpose.1202), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3859 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3858), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p265.1200 = bf16[1024]{0} parameter(265), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1199 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3860 = bf16[1024]{0} broadcast(bf16[] %constant.1199), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3861 = bf16[1024]{0} multiply(bf16[1024]{0} %p265.1200, bf16[1024]{0} %broadcast.3860), metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3862 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3861), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3863 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3859, bf16[1,1025,1024]{2,1,0} %broadcast.3862), metadata={op_type="aten__add" op_name="aten__add.121/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3864 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3863), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p264.1197 = bf16[1024]{0} parameter(264), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1198 = f32[1024]{0} convert(bf16[1024]{0} %p264.1197), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3865 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1198), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.122/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3866 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3864, f32[1,1025,1024]{2,1,0} %broadcast.3865), metadata={op_type="aten__mul" op_name="aten__mul.122/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3867 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3866), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1196 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3868 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1196), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.123/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3869 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3867, bf16[1,1025,1024]{2,1,0} %broadcast.3868), metadata={op_type="aten__add" op_name="aten__add.123/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3870 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3789, bf16[1,1025,1024]{2,1,0} %multiply.3869), metadata={op_type="aten__add" op_name="aten__add.123/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1191 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1192 = bf16[1]{0} reshape(bf16[] %constant.1191), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1193 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1192), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1194 = bf16[] reshape(bf16[1]{0} %broadcast.1193), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1195 = bf16[1025]{0} broadcast(bf16[] %reshape.1194), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1186 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1187 = bf16[1]{0} reshape(bf16[] %constant.1186), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1188 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1187), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1189 = bf16[] reshape(bf16[1]{0} %broadcast.1188), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1190 = bf16[1025]{0} broadcast(bf16[] %reshape.1189), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3871 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3870, bf16[1025]{0} %broadcast.1195, bf16[1025]{0} %broadcast.1190), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3873 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3871), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3874 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3871), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3875 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3876 = bf16[1025]{0} broadcast(bf16[] %constant.3875), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3877 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3874, bf16[1025]{0} %broadcast.3876), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3878 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3877), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p460.3879 = bf16[1024]{0} parameter(460), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3885 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p460.3879), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3872 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3871), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p263.1175 = bf16[1024]{0} parameter(263), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3881 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p263.1175), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3882 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3872, bf16[1,1025,1024]{2,1,0} %broadcast.3881), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1174 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3880 = bf16[] convert(s64[] %constant.1174), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3883 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3880), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3884 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3882, bf16[1,1025,1024]{2,1,0} %broadcast.3883), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3886 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3885, bf16[1,1025,1024]{2,1,0} %multiply.3884), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3887 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3886), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p262.1172 = bf16[4096,1024]{1,0} parameter(262), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1173 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p262.1172), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3888 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3887, bf16[1024,4096]{0,1} %transpose.1173), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3889 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.3888), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p261.1171 = bf16[4096]{0} parameter(261), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1170 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3890 = bf16[4096]{0} broadcast(bf16[] %constant.1170), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.124/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3891 = bf16[4096]{0} multiply(bf16[4096]{0} %p261.1171, bf16[4096]{0} %broadcast.3890), metadata={op_type="aten__add" op_name="aten__add.124/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3892 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.3891), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.124/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3893 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.3889, bf16[1,1025,4096]{2,1,0} %broadcast.3892), metadata={op_type="aten__add" op_name="aten__add.124/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.3894 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3902 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3894), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3903 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3893, bf16[1,1025,4096]{2,1,0} %broadcast.3902), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3896 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3897 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3896), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3898 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.3893, bf16[1,1025,4096]{2,1,0} %broadcast.3897), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.3899 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.3898), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.3895 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.3900 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.3895), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.3901 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.3899, bf16[1,1025,4096]{2,1,0} %broadcast.3900), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.3904 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.3903, bf16[1,1025,4096]{2,1,0} %add.3901), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.3905 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.3904), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p260.1168 = bf16[1024,4096]{1,0} parameter(260), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1169 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p260.1168), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3906 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.3905, bf16[4096,1024]{0,1} %transpose.1169), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3907 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3906), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p259.1167 = bf16[1024]{0} parameter(259), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1166 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3908 = bf16[1024]{0} broadcast(bf16[] %constant.1166), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.125/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3909 = bf16[1024]{0} multiply(bf16[1024]{0} %p259.1167, bf16[1024]{0} %broadcast.3908), metadata={op_type="aten__add" op_name="aten__add.125/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3910 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3909), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.125/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3911 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3907, bf16[1,1025,1024]{2,1,0} %broadcast.3910), metadata={op_type="aten__add" op_name="aten__add.125/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3912 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3911), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p258.1164 = bf16[1024]{0} parameter(258), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1165 = f32[1024]{0} convert(bf16[1024]{0} %p258.1164), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3913 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1165), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.126/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3914 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3912, f32[1,1025,1024]{2,1,0} %broadcast.3913), metadata={op_type="aten__mul" op_name="aten__mul.126/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.3915 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3914), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1163 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.3916 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1163), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.127/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.3917 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3915, bf16[1,1025,1024]{2,1,0} %broadcast.3916), metadata={op_type="aten__add" op_name="aten__add.127/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.3918 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3870, bf16[1,1025,1024]{2,1,0} %multiply.3917), metadata={op_type="aten__add" op_name="aten__add.127/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1158 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1159 = bf16[1]{0} reshape(bf16[] %constant.1158), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1160 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1159), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1161 = bf16[] reshape(bf16[1]{0} %broadcast.1160), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1162 = bf16[1025]{0} broadcast(bf16[] %reshape.1161), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1153 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1154 = bf16[1]{0} reshape(bf16[] %constant.1153), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1155 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1154), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1156 = bf16[] reshape(bf16[1]{0} %broadcast.1155), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1157 = bf16[1025]{0} broadcast(bf16[] %reshape.1156), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.3919 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3918, bf16[1025]{0} %broadcast.1162, bf16[1025]{0} %broadcast.1157), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3921 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3919), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3922 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3919), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.3923 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3924 = bf16[1025]{0} broadcast(bf16[] %constant.3923), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3925 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.3922, bf16[1025]{0} %broadcast.3924), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.3926 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.3925), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p461.3927 = bf16[1024]{0} parameter(461), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3933 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p461.3927), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.3920 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.3919), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p257.1142 = bf16[1024]{0} parameter(257), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.3929 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p257.1142), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3930 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.3920, bf16[1,1025,1024]{2,1,0} %broadcast.3929), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1141 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.3928 = bf16[] convert(s64[] %constant.1141), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.3931 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.3928), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.3932 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.3930, bf16[1,1025,1024]{2,1,0} %broadcast.3931), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.3934 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.3933, bf16[1,1025,1024]{2,1,0} %multiply.3932), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.3935 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.3934), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p256.1139 = bf16[3072,1024]{1,0} parameter(256), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1140 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p256.1139), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3936 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3935, bf16[1024,3072]{0,1} %transpose.1140), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3937 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.3936), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p255.1138 = bf16[3072]{0} parameter(255), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1137 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3938 = bf16[3072]{0} broadcast(bf16[] %constant.1137), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.128/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3939 = bf16[3072]{0} multiply(bf16[3072]{0} %p255.1138, bf16[3072]{0} %broadcast.3938), metadata={op_type="aten__add" op_name="aten__add.128/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3940 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.3939), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.128/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3941 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.3937, bf16[1,1025,3072]{2,1,0} %broadcast.3940), metadata={op_type="aten__add" op_name="aten__add.128/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3942 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.3941), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.3943 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.3942), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.3953 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3943), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3954 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3953), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.3955 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.3954), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3956 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.129/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.3957 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.3955, f32[1,16,1025,64]{3,2,1,0} %broadcast.3956), metadata={op_type="aten__mul" op_name="aten__mul.129/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.3958 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.3957), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3959 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.3958), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3960 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3959), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.3948 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3943), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3949 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3948), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.3950 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3949), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.3951 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.3950), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3952 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.3951), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.3961 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.3960, bf16[16,64,1025]{2,1,0} %reshape.3952), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.3962 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.3961), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.3963 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3968 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3962, bf16[] %constant.3963), dimensions={3}, to_apply=%MaxComputation.3964, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3969 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3968), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.3970 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.3962, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3969), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.3971 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.3970), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.3972 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.3977 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3971, bf16[] %constant.3972), dimensions={3}, to_apply=%AddComputation.3973, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3978 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.3977), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.3979 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.3971, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3978), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.3980 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.3979), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3981 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.3980), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.3944 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.3943), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.3945 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.3944), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.3946 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.3945), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3947 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.3946), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.3982 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.3981, bf16[16,1025,64]{2,1,0} %reshape.3947), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3983 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.3982), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.3984 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.3983), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3985 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.3984), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.3986 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.3985), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p254.1135 = bf16[1024,1024]{1,0} parameter(254), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1136 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p254.1135), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.3987 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.3986, bf16[1024,1024]{0,1} %transpose.1136), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.3988 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.3987), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p253.1134 = bf16[1024]{0} parameter(253), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1133 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3989 = bf16[1024]{0} broadcast(bf16[] %constant.1133), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.130/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.3990 = bf16[1024]{0} multiply(bf16[1024]{0} %p253.1134, bf16[1024]{0} %broadcast.3989), metadata={op_type="aten__add" op_name="aten__add.130/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.3991 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.3990), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.130/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.3992 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.3988, bf16[1,1025,1024]{2,1,0} %broadcast.3991), metadata={op_type="aten__add" op_name="aten__add.130/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.3993 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.3992), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p252.1131 = bf16[1024]{0} parameter(252), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1132 = f32[1024]{0} convert(bf16[1024]{0} %p252.1131), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3994 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1132), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.131/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3995 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.3993, f32[1,1025,1024]{2,1,0} %broadcast.3994), metadata={op_type="aten__mul" op_name="aten__mul.131/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.3996 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.3995), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1130 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.3997 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1130), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.132/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.3998 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.3996, bf16[1,1025,1024]{2,1,0} %broadcast.3997), metadata={op_type="aten__add" op_name="aten__add.132/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.3999 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3918, bf16[1,1025,1024]{2,1,0} %multiply.3998), metadata={op_type="aten__add" op_name="aten__add.132/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1125 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1126 = bf16[1]{0} reshape(bf16[] %constant.1125), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1127 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1126), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1128 = bf16[] reshape(bf16[1]{0} %broadcast.1127), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1129 = bf16[1025]{0} broadcast(bf16[] %reshape.1128), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1120 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1121 = bf16[1]{0} reshape(bf16[] %constant.1120), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1122 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1121), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1123 = bf16[] reshape(bf16[1]{0} %broadcast.1122), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1124 = bf16[1025]{0} broadcast(bf16[] %reshape.1123), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4000 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.3999, bf16[1025]{0} %broadcast.1129, bf16[1025]{0} %broadcast.1124), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4002 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4000), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4003 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4000), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4004 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4005 = bf16[1025]{0} broadcast(bf16[] %constant.4004), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4006 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4003, bf16[1025]{0} %broadcast.4005), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4007 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4006), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p462.4008 = bf16[1024]{0} parameter(462), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4014 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p462.4008), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4001 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4000), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p251.1109 = bf16[1024]{0} parameter(251), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4010 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p251.1109), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4011 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4001, bf16[1,1025,1024]{2,1,0} %broadcast.4010), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1108 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4009 = bf16[] convert(s64[] %constant.1108), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4012 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4009), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4013 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4011, bf16[1,1025,1024]{2,1,0} %broadcast.4012), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4015 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4014, bf16[1,1025,1024]{2,1,0} %multiply.4013), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4016 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4015), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p250.1106 = bf16[4096,1024]{1,0} parameter(250), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1107 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p250.1106), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4017 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4016, bf16[1024,4096]{0,1} %transpose.1107), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4018 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4017), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p249.1105 = bf16[4096]{0} parameter(249), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1104 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4019 = bf16[4096]{0} broadcast(bf16[] %constant.1104), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.133/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4020 = bf16[4096]{0} multiply(bf16[4096]{0} %p249.1105, bf16[4096]{0} %broadcast.4019), metadata={op_type="aten__add" op_name="aten__add.133/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4021 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4020), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.133/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4022 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4018, bf16[1,1025,4096]{2,1,0} %broadcast.4021), metadata={op_type="aten__add" op_name="aten__add.133/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4023 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4031 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4023), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4032 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4022, bf16[1,1025,4096]{2,1,0} %broadcast.4031), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4025 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4026 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4025), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4027 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4022, bf16[1,1025,4096]{2,1,0} %broadcast.4026), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4028 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4027), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4024 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4029 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4024), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4030 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4028, bf16[1,1025,4096]{2,1,0} %broadcast.4029), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4033 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4032, bf16[1,1025,4096]{2,1,0} %add.4030), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4034 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4033), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p248.1102 = bf16[1024,4096]{1,0} parameter(248), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1103 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p248.1102), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4035 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4034, bf16[4096,1024]{0,1} %transpose.1103), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4036 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4035), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p247.1101 = bf16[1024]{0} parameter(247), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1100 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4037 = bf16[1024]{0} broadcast(bf16[] %constant.1100), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.134/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4038 = bf16[1024]{0} multiply(bf16[1024]{0} %p247.1101, bf16[1024]{0} %broadcast.4037), metadata={op_type="aten__add" op_name="aten__add.134/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4039 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4038), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.134/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4040 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4036, bf16[1,1025,1024]{2,1,0} %broadcast.4039), metadata={op_type="aten__add" op_name="aten__add.134/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4041 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4040), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p246.1098 = bf16[1024]{0} parameter(246), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1099 = f32[1024]{0} convert(bf16[1024]{0} %p246.1098), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4042 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1099), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.135/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4043 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4041, f32[1,1025,1024]{2,1,0} %broadcast.4042), metadata={op_type="aten__mul" op_name="aten__mul.135/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4044 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4043), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1097 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4045 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1097), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.136/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4046 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4044, bf16[1,1025,1024]{2,1,0} %broadcast.4045), metadata={op_type="aten__add" op_name="aten__add.136/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4047 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.3999, bf16[1,1025,1024]{2,1,0} %multiply.4046), metadata={op_type="aten__add" op_name="aten__add.136/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1092 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1093 = bf16[1]{0} reshape(bf16[] %constant.1092), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1094 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1093), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1095 = bf16[] reshape(bf16[1]{0} %broadcast.1094), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1096 = bf16[1025]{0} broadcast(bf16[] %reshape.1095), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1087 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1088 = bf16[1]{0} reshape(bf16[] %constant.1087), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1089 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1088), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1090 = bf16[] reshape(bf16[1]{0} %broadcast.1089), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1091 = bf16[1025]{0} broadcast(bf16[] %reshape.1090), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4048 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4047, bf16[1025]{0} %broadcast.1096, bf16[1025]{0} %broadcast.1091), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4050 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4048), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4051 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4048), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4052 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4053 = bf16[1025]{0} broadcast(bf16[] %constant.4052), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4054 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4051, bf16[1025]{0} %broadcast.4053), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4055 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4054), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p463.4056 = bf16[1024]{0} parameter(463), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4062 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p463.4056), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4049 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4048), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p245.1076 = bf16[1024]{0} parameter(245), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4058 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p245.1076), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4059 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4049, bf16[1,1025,1024]{2,1,0} %broadcast.4058), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1075 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4057 = bf16[] convert(s64[] %constant.1075), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4060 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4057), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4061 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4059, bf16[1,1025,1024]{2,1,0} %broadcast.4060), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4063 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4062, bf16[1,1025,1024]{2,1,0} %multiply.4061), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4064 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4063), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p244.1073 = bf16[3072,1024]{1,0} parameter(244), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1074 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p244.1073), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4065 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4064, bf16[1024,3072]{0,1} %transpose.1074), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4066 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4065), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p243.1072 = bf16[3072]{0} parameter(243), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1071 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4067 = bf16[3072]{0} broadcast(bf16[] %constant.1071), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.137/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4068 = bf16[3072]{0} multiply(bf16[3072]{0} %p243.1072, bf16[3072]{0} %broadcast.4067), metadata={op_type="aten__add" op_name="aten__add.137/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4069 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4068), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.137/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4070 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4066, bf16[1,1025,3072]{2,1,0} %broadcast.4069), metadata={op_type="aten__add" op_name="aten__add.137/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4071 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4070), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4072 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4071), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4082 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4072), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4083 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4082), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4084 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4083), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4085 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.138/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4086 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4084, f32[1,16,1025,64]{3,2,1,0} %broadcast.4085), metadata={op_type="aten__mul" op_name="aten__mul.138/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4087 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4086), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4088 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4087), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4089 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4088), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4077 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4072), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4078 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4077), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4079 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4078), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4080 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4079), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4081 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4080), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4090 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4089, bf16[16,64,1025]{2,1,0} %reshape.4081), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4091 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4090), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4092 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4097 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4091, bf16[] %constant.4092), dimensions={3}, to_apply=%MaxComputation.4093, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4098 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4097), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4099 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4091, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4098), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4100 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4099), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4101 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4106 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4100, bf16[] %constant.4101), dimensions={3}, to_apply=%AddComputation.4102, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4107 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4106), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4108 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4100, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4107), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4109 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4108), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4110 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4109), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4073 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4072), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4074 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4073), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4075 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4074), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4076 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4075), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4111 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4110, bf16[16,1025,64]{2,1,0} %reshape.4076), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4112 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4111), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4113 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4112), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4114 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4113), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4115 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4114), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p242.1069 = bf16[1024,1024]{1,0} parameter(242), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1070 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p242.1069), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4116 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4115, bf16[1024,1024]{0,1} %transpose.1070), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4117 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4116), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p241.1068 = bf16[1024]{0} parameter(241), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1067 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4118 = bf16[1024]{0} broadcast(bf16[] %constant.1067), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4119 = bf16[1024]{0} multiply(bf16[1024]{0} %p241.1068, bf16[1024]{0} %broadcast.4118), metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4120 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4119), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4121 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4117, bf16[1,1025,1024]{2,1,0} %broadcast.4120), metadata={op_type="aten__add" op_name="aten__add.139/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4122 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4121), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p240.1065 = bf16[1024]{0} parameter(240), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1066 = f32[1024]{0} convert(bf16[1024]{0} %p240.1065), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4123 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1066), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.140/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4124 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4122, f32[1,1025,1024]{2,1,0} %broadcast.4123), metadata={op_type="aten__mul" op_name="aten__mul.140/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4125 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4124), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1064 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4126 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1064), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.141/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4127 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4125, bf16[1,1025,1024]{2,1,0} %broadcast.4126), metadata={op_type="aten__add" op_name="aten__add.141/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4128 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4047, bf16[1,1025,1024]{2,1,0} %multiply.4127), metadata={op_type="aten__add" op_name="aten__add.141/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.1059 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1060 = bf16[1]{0} reshape(bf16[] %constant.1059), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1061 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1060), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1062 = bf16[] reshape(bf16[1]{0} %broadcast.1061), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1063 = bf16[1025]{0} broadcast(bf16[] %reshape.1062), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1054 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1055 = bf16[1]{0} reshape(bf16[] %constant.1054), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1056 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1055), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1057 = bf16[] reshape(bf16[1]{0} %broadcast.1056), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1058 = bf16[1025]{0} broadcast(bf16[] %reshape.1057), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4129 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4128, bf16[1025]{0} %broadcast.1063, bf16[1025]{0} %broadcast.1058), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4131 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4129), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4132 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4129), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4133 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4134 = bf16[1025]{0} broadcast(bf16[] %constant.4133), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4135 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4132, bf16[1025]{0} %broadcast.4134), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4136 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4135), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p464.4137 = bf16[1024]{0} parameter(464), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4143 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p464.4137), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4130 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4129), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p239.1043 = bf16[1024]{0} parameter(239), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4139 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p239.1043), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4140 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4130, bf16[1,1025,1024]{2,1,0} %broadcast.4139), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1042 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4138 = bf16[] convert(s64[] %constant.1042), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4141 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4138), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4142 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4140, bf16[1,1025,1024]{2,1,0} %broadcast.4141), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4144 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4143, bf16[1,1025,1024]{2,1,0} %multiply.4142), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4145 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4144), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p238.1040 = bf16[4096,1024]{1,0} parameter(238), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1041 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p238.1040), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4146 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4145, bf16[1024,4096]{0,1} %transpose.1041), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4147 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4146), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p237.1039 = bf16[4096]{0} parameter(237), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1038 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4148 = bf16[4096]{0} broadcast(bf16[] %constant.1038), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.142/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4149 = bf16[4096]{0} multiply(bf16[4096]{0} %p237.1039, bf16[4096]{0} %broadcast.4148), metadata={op_type="aten__add" op_name="aten__add.142/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4150 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4149), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.142/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4151 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4147, bf16[1,1025,4096]{2,1,0} %broadcast.4150), metadata={op_type="aten__add" op_name="aten__add.142/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4152 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4160 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4152), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4161 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4151, bf16[1,1025,4096]{2,1,0} %broadcast.4160), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4154 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4155 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4154), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4156 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4151, bf16[1,1025,4096]{2,1,0} %broadcast.4155), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4157 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4156), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4153 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4158 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4153), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4159 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4157, bf16[1,1025,4096]{2,1,0} %broadcast.4158), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4162 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4161, bf16[1,1025,4096]{2,1,0} %add.4159), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4163 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4162), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p236.1036 = bf16[1024,4096]{1,0} parameter(236), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1037 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p236.1036), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4164 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4163, bf16[4096,1024]{0,1} %transpose.1037), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4165 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4164), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p235.1035 = bf16[1024]{0} parameter(235), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1034 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4166 = bf16[1024]{0} broadcast(bf16[] %constant.1034), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.143/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4167 = bf16[1024]{0} multiply(bf16[1024]{0} %p235.1035, bf16[1024]{0} %broadcast.4166), metadata={op_type="aten__add" op_name="aten__add.143/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4168 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4167), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.143/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4169 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4165, bf16[1,1025,1024]{2,1,0} %broadcast.4168), metadata={op_type="aten__add" op_name="aten__add.143/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4170 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4169), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p234.1032 = bf16[1024]{0} parameter(234), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1033 = f32[1024]{0} convert(bf16[1024]{0} %p234.1032), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4171 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1033), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.144/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4172 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4170, f32[1,1025,1024]{2,1,0} %broadcast.4171), metadata={op_type="aten__mul" op_name="aten__mul.144/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4173 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4172), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1031 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4174 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.1031), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.145/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4175 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4173, bf16[1,1025,1024]{2,1,0} %broadcast.4174), metadata={op_type="aten__add" op_name="aten__add.145/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4176 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4128, bf16[1,1025,1024]{2,1,0} %multiply.4175), metadata={op_type="aten__add" op_name="aten__add.145/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.1026 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1027 = bf16[1]{0} reshape(bf16[] %constant.1026), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1028 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1027), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1029 = bf16[] reshape(bf16[1]{0} %broadcast.1028), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1030 = bf16[1025]{0} broadcast(bf16[] %reshape.1029), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1021 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1022 = bf16[1]{0} reshape(bf16[] %constant.1021), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1023 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.1022), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.1024 = bf16[] reshape(bf16[1]{0} %broadcast.1023), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.1025 = bf16[1025]{0} broadcast(bf16[] %reshape.1024), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4177 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4176, bf16[1025]{0} %broadcast.1030, bf16[1025]{0} %broadcast.1025), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4179 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4177), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4180 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4177), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4181 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4182 = bf16[1025]{0} broadcast(bf16[] %constant.4181), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4183 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4180, bf16[1025]{0} %broadcast.4182), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4184 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4183), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p465.4185 = bf16[1024]{0} parameter(465), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4191 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p465.4185), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4178 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4177), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p233.1010 = bf16[1024]{0} parameter(233), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4187 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p233.1010), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4188 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4178, bf16[1,1025,1024]{2,1,0} %broadcast.4187), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.1009 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4186 = bf16[] convert(s64[] %constant.1009), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4189 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4186), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4190 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4188, bf16[1,1025,1024]{2,1,0} %broadcast.4189), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4192 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4191, bf16[1,1025,1024]{2,1,0} %multiply.4190), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4193 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4192), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p232.1007 = bf16[3072,1024]{1,0} parameter(232), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1008 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p232.1007), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4194 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4193, bf16[1024,3072]{0,1} %transpose.1008), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4195 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4194), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p231.1006 = bf16[3072]{0} parameter(231), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1005 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4196 = bf16[3072]{0} broadcast(bf16[] %constant.1005), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.146/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4197 = bf16[3072]{0} multiply(bf16[3072]{0} %p231.1006, bf16[3072]{0} %broadcast.4196), metadata={op_type="aten__add" op_name="aten__add.146/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4198 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4197), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.146/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4199 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4195, bf16[1,1025,3072]{2,1,0} %broadcast.4198), metadata={op_type="aten__add" op_name="aten__add.146/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4200 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4199), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4201 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4200), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4211 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4201), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4212 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4211), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4213 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4212), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4214 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.147/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4215 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4213, f32[1,16,1025,64]{3,2,1,0} %broadcast.4214), metadata={op_type="aten__mul" op_name="aten__mul.147/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4216 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4215), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4217 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4216), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4218 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4217), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4206 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4201), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4207 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4206), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4208 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4207), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4209 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4208), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4210 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4209), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4219 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4218, bf16[16,64,1025]{2,1,0} %reshape.4210), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4220 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4219), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4221 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4226 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4220, bf16[] %constant.4221), dimensions={3}, to_apply=%MaxComputation.4222, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4227 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4226), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4228 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4220, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4227), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4229 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4228), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4230 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4235 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4229, bf16[] %constant.4230), dimensions={3}, to_apply=%AddComputation.4231, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4236 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4235), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4237 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4229, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4236), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4238 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4237), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4239 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4238), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4202 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4201), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4203 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4202), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4204 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4203), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4205 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4204), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4240 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4239, bf16[16,1025,64]{2,1,0} %reshape.4205), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4241 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4240), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4242 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4241), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4243 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4242), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4244 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4243), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p230.1003 = bf16[1024,1024]{1,0} parameter(230), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.1004 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p230.1003), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4245 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4244, bf16[1024,1024]{0,1} %transpose.1004), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4246 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4245), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p229.1002 = bf16[1024]{0} parameter(229), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.1001 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4247 = bf16[1024]{0} broadcast(bf16[] %constant.1001), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.148/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4248 = bf16[1024]{0} multiply(bf16[1024]{0} %p229.1002, bf16[1024]{0} %broadcast.4247), metadata={op_type="aten__add" op_name="aten__add.148/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4249 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4248), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.148/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4250 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4246, bf16[1,1025,1024]{2,1,0} %broadcast.4249), metadata={op_type="aten__add" op_name="aten__add.148/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4251 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4250), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p228.999 = bf16[1024]{0} parameter(228), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.1000 = f32[1024]{0} convert(bf16[1024]{0} %p228.999), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4252 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.1000), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.149/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4253 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4251, f32[1,1025,1024]{2,1,0} %broadcast.4252), metadata={op_type="aten__mul" op_name="aten__mul.149/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4254 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4253), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.998 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4255 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.998), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.150/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4256 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4254, bf16[1,1025,1024]{2,1,0} %broadcast.4255), metadata={op_type="aten__add" op_name="aten__add.150/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4257 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4176, bf16[1,1025,1024]{2,1,0} %multiply.4256), metadata={op_type="aten__add" op_name="aten__add.150/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.993 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.994 = bf16[1]{0} reshape(bf16[] %constant.993), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.995 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.994), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.996 = bf16[] reshape(bf16[1]{0} %broadcast.995), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.997 = bf16[1025]{0} broadcast(bf16[] %reshape.996), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.988 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.989 = bf16[1]{0} reshape(bf16[] %constant.988), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.990 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.989), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.991 = bf16[] reshape(bf16[1]{0} %broadcast.990), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.992 = bf16[1025]{0} broadcast(bf16[] %reshape.991), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4258 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4257, bf16[1025]{0} %broadcast.997, bf16[1025]{0} %broadcast.992), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4260 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4258), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4261 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4258), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4262 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4263 = bf16[1025]{0} broadcast(bf16[] %constant.4262), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4264 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4261, bf16[1025]{0} %broadcast.4263), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4265 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4264), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p466.4266 = bf16[1024]{0} parameter(466), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4272 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p466.4266), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4259 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4258), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p227.977 = bf16[1024]{0} parameter(227), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4268 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p227.977), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4269 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4259, bf16[1,1025,1024]{2,1,0} %broadcast.4268), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.976 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4267 = bf16[] convert(s64[] %constant.976), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4270 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4267), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4271 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4269, bf16[1,1025,1024]{2,1,0} %broadcast.4270), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4273 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4272, bf16[1,1025,1024]{2,1,0} %multiply.4271), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4274 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4273), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p226.974 = bf16[4096,1024]{1,0} parameter(226), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.975 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p226.974), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4275 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4274, bf16[1024,4096]{0,1} %transpose.975), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4276 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4275), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p225.973 = bf16[4096]{0} parameter(225), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.972 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4277 = bf16[4096]{0} broadcast(bf16[] %constant.972), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.151/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4278 = bf16[4096]{0} multiply(bf16[4096]{0} %p225.973, bf16[4096]{0} %broadcast.4277), metadata={op_type="aten__add" op_name="aten__add.151/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4279 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4278), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.151/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4280 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4276, bf16[1,1025,4096]{2,1,0} %broadcast.4279), metadata={op_type="aten__add" op_name="aten__add.151/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4281 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4289 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4281), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4290 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4280, bf16[1,1025,4096]{2,1,0} %broadcast.4289), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4283 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4284 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4283), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4285 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4280, bf16[1,1025,4096]{2,1,0} %broadcast.4284), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4286 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4285), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4282 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4287 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4282), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4288 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4286, bf16[1,1025,4096]{2,1,0} %broadcast.4287), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4291 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4290, bf16[1,1025,4096]{2,1,0} %add.4288), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4292 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4291), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p224.970 = bf16[1024,4096]{1,0} parameter(224), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.971 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p224.970), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4293 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4292, bf16[4096,1024]{0,1} %transpose.971), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4294 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4293), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p223.969 = bf16[1024]{0} parameter(223), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.968 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4295 = bf16[1024]{0} broadcast(bf16[] %constant.968), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.152/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4296 = bf16[1024]{0} multiply(bf16[1024]{0} %p223.969, bf16[1024]{0} %broadcast.4295), metadata={op_type="aten__add" op_name="aten__add.152/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4297 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4296), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.152/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4298 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4294, bf16[1,1025,1024]{2,1,0} %broadcast.4297), metadata={op_type="aten__add" op_name="aten__add.152/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4299 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4298), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p222.966 = bf16[1024]{0} parameter(222), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.967 = f32[1024]{0} convert(bf16[1024]{0} %p222.966), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4300 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.967), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.153/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4301 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4299, f32[1,1025,1024]{2,1,0} %broadcast.4300), metadata={op_type="aten__mul" op_name="aten__mul.153/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4302 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4301), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.965 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4303 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.965), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.154/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4304 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4302, bf16[1,1025,1024]{2,1,0} %broadcast.4303), metadata={op_type="aten__add" op_name="aten__add.154/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4305 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4257, bf16[1,1025,1024]{2,1,0} %multiply.4304), metadata={op_type="aten__add" op_name="aten__add.154/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.960 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.961 = bf16[1]{0} reshape(bf16[] %constant.960), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.962 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.961), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.963 = bf16[] reshape(bf16[1]{0} %broadcast.962), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.964 = bf16[1025]{0} broadcast(bf16[] %reshape.963), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.955 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.956 = bf16[1]{0} reshape(bf16[] %constant.955), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.957 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.956), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.958 = bf16[] reshape(bf16[1]{0} %broadcast.957), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.959 = bf16[1025]{0} broadcast(bf16[] %reshape.958), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4306 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4305, bf16[1025]{0} %broadcast.964, bf16[1025]{0} %broadcast.959), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4308 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4306), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4309 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4306), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4310 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4311 = bf16[1025]{0} broadcast(bf16[] %constant.4310), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4312 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4309, bf16[1025]{0} %broadcast.4311), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4313 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4312), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p467.4314 = bf16[1024]{0} parameter(467), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4320 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p467.4314), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4307 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4306), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p221.944 = bf16[1024]{0} parameter(221), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4316 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p221.944), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4317 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4307, bf16[1,1025,1024]{2,1,0} %broadcast.4316), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.943 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4315 = bf16[] convert(s64[] %constant.943), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4318 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4315), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4319 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4317, bf16[1,1025,1024]{2,1,0} %broadcast.4318), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4321 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4320, bf16[1,1025,1024]{2,1,0} %multiply.4319), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4322 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4321), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p220.941 = bf16[3072,1024]{1,0} parameter(220), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.942 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p220.941), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4323 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4322, bf16[1024,3072]{0,1} %transpose.942), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4324 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4323), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p219.940 = bf16[3072]{0} parameter(219), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.939 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4325 = bf16[3072]{0} broadcast(bf16[] %constant.939), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.155/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4326 = bf16[3072]{0} multiply(bf16[3072]{0} %p219.940, bf16[3072]{0} %broadcast.4325), metadata={op_type="aten__add" op_name="aten__add.155/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4327 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4326), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.155/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4328 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4324, bf16[1,1025,3072]{2,1,0} %broadcast.4327), metadata={op_type="aten__add" op_name="aten__add.155/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4329 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4328), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4330 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4329), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4340 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4330), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4341 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4340), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4342 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4341), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4343 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.156/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4344 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4342, f32[1,16,1025,64]{3,2,1,0} %broadcast.4343), metadata={op_type="aten__mul" op_name="aten__mul.156/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4345 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4344), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4346 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4345), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4347 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4346), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4335 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4330), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4336 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4335), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4337 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4336), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4338 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4337), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4339 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4338), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4348 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4347, bf16[16,64,1025]{2,1,0} %reshape.4339), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4349 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4348), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4350 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4355 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4349, bf16[] %constant.4350), dimensions={3}, to_apply=%MaxComputation.4351, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4356 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4355), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4357 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4349, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4356), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4358 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4357), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4359 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4364 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4358, bf16[] %constant.4359), dimensions={3}, to_apply=%AddComputation.4360, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4365 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4364), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4366 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4358, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4365), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4367 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4366), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4368 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4367), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4331 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4330), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4332 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4331), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4333 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4332), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4334 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4333), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4369 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4368, bf16[16,1025,64]{2,1,0} %reshape.4334), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4370 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4369), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4371 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4370), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4372 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4371), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4373 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4372), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p218.937 = bf16[1024,1024]{1,0} parameter(218), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.938 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p218.937), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4374 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4373, bf16[1024,1024]{0,1} %transpose.938), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4375 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4374), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p217.936 = bf16[1024]{0} parameter(217), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.935 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4376 = bf16[1024]{0} broadcast(bf16[] %constant.935), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4377 = bf16[1024]{0} multiply(bf16[1024]{0} %p217.936, bf16[1024]{0} %broadcast.4376), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4378 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4377), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4379 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4375, bf16[1,1025,1024]{2,1,0} %broadcast.4378), metadata={op_type="aten__add" op_name="aten__add.157/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4380 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4379), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p216.933 = bf16[1024]{0} parameter(216), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.934 = f32[1024]{0} convert(bf16[1024]{0} %p216.933), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4381 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.934), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.158/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4382 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4380, f32[1,1025,1024]{2,1,0} %broadcast.4381), metadata={op_type="aten__mul" op_name="aten__mul.158/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4383 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4382), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.932 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4384 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.932), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.159/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4385 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4383, bf16[1,1025,1024]{2,1,0} %broadcast.4384), metadata={op_type="aten__add" op_name="aten__add.159/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4386 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4305, bf16[1,1025,1024]{2,1,0} %multiply.4385), metadata={op_type="aten__add" op_name="aten__add.159/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.927 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.928 = bf16[1]{0} reshape(bf16[] %constant.927), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.929 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.928), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.930 = bf16[] reshape(bf16[1]{0} %broadcast.929), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.931 = bf16[1025]{0} broadcast(bf16[] %reshape.930), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.922 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.923 = bf16[1]{0} reshape(bf16[] %constant.922), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.924 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.923), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.925 = bf16[] reshape(bf16[1]{0} %broadcast.924), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.926 = bf16[1025]{0} broadcast(bf16[] %reshape.925), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4387 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4386, bf16[1025]{0} %broadcast.931, bf16[1025]{0} %broadcast.926), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4389 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4387), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4390 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4387), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4391 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4392 = bf16[1025]{0} broadcast(bf16[] %constant.4391), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4393 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4390, bf16[1025]{0} %broadcast.4392), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4394 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4393), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p468.4395 = bf16[1024]{0} parameter(468), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4401 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p468.4395), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4388 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4387), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p215.911 = bf16[1024]{0} parameter(215), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4397 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p215.911), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4398 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4388, bf16[1,1025,1024]{2,1,0} %broadcast.4397), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.910 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4396 = bf16[] convert(s64[] %constant.910), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4399 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4396), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4400 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4398, bf16[1,1025,1024]{2,1,0} %broadcast.4399), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4402 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4401, bf16[1,1025,1024]{2,1,0} %multiply.4400), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4403 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4402), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p214.908 = bf16[4096,1024]{1,0} parameter(214), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.909 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p214.908), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4404 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4403, bf16[1024,4096]{0,1} %transpose.909), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4405 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4404), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p213.907 = bf16[4096]{0} parameter(213), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.906 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4406 = bf16[4096]{0} broadcast(bf16[] %constant.906), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.160/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4407 = bf16[4096]{0} multiply(bf16[4096]{0} %p213.907, bf16[4096]{0} %broadcast.4406), metadata={op_type="aten__add" op_name="aten__add.160/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4408 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4407), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.160/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4409 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4405, bf16[1,1025,4096]{2,1,0} %broadcast.4408), metadata={op_type="aten__add" op_name="aten__add.160/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4410 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4418 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4410), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4419 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4409, bf16[1,1025,4096]{2,1,0} %broadcast.4418), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4412 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4413 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4412), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4414 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4409, bf16[1,1025,4096]{2,1,0} %broadcast.4413), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4415 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4414), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4411 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4416 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4411), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4417 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4415, bf16[1,1025,4096]{2,1,0} %broadcast.4416), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4420 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4419, bf16[1,1025,4096]{2,1,0} %add.4417), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4421 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4420), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p212.904 = bf16[1024,4096]{1,0} parameter(212), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.905 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p212.904), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4422 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4421, bf16[4096,1024]{0,1} %transpose.905), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4423 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4422), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p211.903 = bf16[1024]{0} parameter(211), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.902 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4424 = bf16[1024]{0} broadcast(bf16[] %constant.902), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.161/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4425 = bf16[1024]{0} multiply(bf16[1024]{0} %p211.903, bf16[1024]{0} %broadcast.4424), metadata={op_type="aten__add" op_name="aten__add.161/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4426 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4425), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.161/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4427 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4423, bf16[1,1025,1024]{2,1,0} %broadcast.4426), metadata={op_type="aten__add" op_name="aten__add.161/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4428 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4427), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p210.900 = bf16[1024]{0} parameter(210), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.901 = f32[1024]{0} convert(bf16[1024]{0} %p210.900), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4429 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.901), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.162/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4430 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4428, f32[1,1025,1024]{2,1,0} %broadcast.4429), metadata={op_type="aten__mul" op_name="aten__mul.162/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4431 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4430), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.899 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4432 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.899), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.163/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4433 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4431, bf16[1,1025,1024]{2,1,0} %broadcast.4432), metadata={op_type="aten__add" op_name="aten__add.163/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4434 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4386, bf16[1,1025,1024]{2,1,0} %multiply.4433), metadata={op_type="aten__add" op_name="aten__add.163/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.894 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.895 = bf16[1]{0} reshape(bf16[] %constant.894), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.896 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.895), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.897 = bf16[] reshape(bf16[1]{0} %broadcast.896), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.898 = bf16[1025]{0} broadcast(bf16[] %reshape.897), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.889 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.890 = bf16[1]{0} reshape(bf16[] %constant.889), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.891 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.890), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.892 = bf16[] reshape(bf16[1]{0} %broadcast.891), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.893 = bf16[1025]{0} broadcast(bf16[] %reshape.892), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4435 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4434, bf16[1025]{0} %broadcast.898, bf16[1025]{0} %broadcast.893), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4437 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4435), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4438 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4435), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4439 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4440 = bf16[1025]{0} broadcast(bf16[] %constant.4439), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4441 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4438, bf16[1025]{0} %broadcast.4440), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4442 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4441), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p469.4443 = bf16[1024]{0} parameter(469), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4449 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p469.4443), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4436 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4435), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p209.878 = bf16[1024]{0} parameter(209), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4445 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p209.878), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4446 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4436, bf16[1,1025,1024]{2,1,0} %broadcast.4445), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.877 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4444 = bf16[] convert(s64[] %constant.877), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4447 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4444), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4448 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4446, bf16[1,1025,1024]{2,1,0} %broadcast.4447), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4450 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4449, bf16[1,1025,1024]{2,1,0} %multiply.4448), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4451 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4450), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p208.875 = bf16[3072,1024]{1,0} parameter(208), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.876 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p208.875), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4452 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4451, bf16[1024,3072]{0,1} %transpose.876), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4453 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4452), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p207.874 = bf16[3072]{0} parameter(207), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.873 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4454 = bf16[3072]{0} broadcast(bf16[] %constant.873), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.164/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4455 = bf16[3072]{0} multiply(bf16[3072]{0} %p207.874, bf16[3072]{0} %broadcast.4454), metadata={op_type="aten__add" op_name="aten__add.164/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4456 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4455), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.164/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4457 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4453, bf16[1,1025,3072]{2,1,0} %broadcast.4456), metadata={op_type="aten__add" op_name="aten__add.164/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4458 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4457), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4459 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4458), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4469 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4459), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4470 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4469), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4471 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4470), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4472 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.165/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4473 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4471, f32[1,16,1025,64]{3,2,1,0} %broadcast.4472), metadata={op_type="aten__mul" op_name="aten__mul.165/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4474 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4473), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4475 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4474), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4476 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4475), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4464 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4459), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4465 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4464), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4466 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4465), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4467 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4466), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4468 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4467), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4477 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4476, bf16[16,64,1025]{2,1,0} %reshape.4468), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4478 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4477), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4479 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4484 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4478, bf16[] %constant.4479), dimensions={3}, to_apply=%MaxComputation.4480, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4485 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4484), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4486 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4478, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4485), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4487 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4486), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4488 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4493 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4487, bf16[] %constant.4488), dimensions={3}, to_apply=%AddComputation.4489, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4494 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4493), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4495 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4487, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4494), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4496 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4495), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4497 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4496), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4460 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4459), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4461 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4460), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4462 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4461), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4463 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4462), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4498 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4497, bf16[16,1025,64]{2,1,0} %reshape.4463), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4499 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4498), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4500 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4499), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4501 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4500), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4502 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4501), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p206.871 = bf16[1024,1024]{1,0} parameter(206), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.872 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p206.871), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4503 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4502, bf16[1024,1024]{0,1} %transpose.872), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4504 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4503), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p205.870 = bf16[1024]{0} parameter(205), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.869 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4505 = bf16[1024]{0} broadcast(bf16[] %constant.869), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.166/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4506 = bf16[1024]{0} multiply(bf16[1024]{0} %p205.870, bf16[1024]{0} %broadcast.4505), metadata={op_type="aten__add" op_name="aten__add.166/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4507 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4506), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.166/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4508 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4504, bf16[1,1025,1024]{2,1,0} %broadcast.4507), metadata={op_type="aten__add" op_name="aten__add.166/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4509 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4508), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p204.867 = bf16[1024]{0} parameter(204), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.868 = f32[1024]{0} convert(bf16[1024]{0} %p204.867), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4510 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.868), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.167/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4511 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4509, f32[1,1025,1024]{2,1,0} %broadcast.4510), metadata={op_type="aten__mul" op_name="aten__mul.167/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4512 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4511), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.866 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4513 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.866), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.168/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4514 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4512, bf16[1,1025,1024]{2,1,0} %broadcast.4513), metadata={op_type="aten__add" op_name="aten__add.168/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4515 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4434, bf16[1,1025,1024]{2,1,0} %multiply.4514), metadata={op_type="aten__add" op_name="aten__add.168/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.861 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.862 = bf16[1]{0} reshape(bf16[] %constant.861), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.863 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.862), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.864 = bf16[] reshape(bf16[1]{0} %broadcast.863), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.865 = bf16[1025]{0} broadcast(bf16[] %reshape.864), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.856 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.857 = bf16[1]{0} reshape(bf16[] %constant.856), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.858 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.857), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.859 = bf16[] reshape(bf16[1]{0} %broadcast.858), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.860 = bf16[1025]{0} broadcast(bf16[] %reshape.859), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4516 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4515, bf16[1025]{0} %broadcast.865, bf16[1025]{0} %broadcast.860), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4518 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4516), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4519 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4516), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4520 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4521 = bf16[1025]{0} broadcast(bf16[] %constant.4520), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4522 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4519, bf16[1025]{0} %broadcast.4521), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4523 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4522), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p470.4524 = bf16[1024]{0} parameter(470), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4530 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p470.4524), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4517 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4516), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p203.845 = bf16[1024]{0} parameter(203), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4526 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p203.845), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4527 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4517, bf16[1,1025,1024]{2,1,0} %broadcast.4526), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.844 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4525 = bf16[] convert(s64[] %constant.844), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4528 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4525), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4529 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4527, bf16[1,1025,1024]{2,1,0} %broadcast.4528), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4531 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4530, bf16[1,1025,1024]{2,1,0} %multiply.4529), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4532 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4531), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p202.842 = bf16[4096,1024]{1,0} parameter(202), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.843 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p202.842), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4533 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4532, bf16[1024,4096]{0,1} %transpose.843), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4534 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4533), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p201.841 = bf16[4096]{0} parameter(201), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.840 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4535 = bf16[4096]{0} broadcast(bf16[] %constant.840), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.169/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4536 = bf16[4096]{0} multiply(bf16[4096]{0} %p201.841, bf16[4096]{0} %broadcast.4535), metadata={op_type="aten__add" op_name="aten__add.169/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4537 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4536), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.169/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4538 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4534, bf16[1,1025,4096]{2,1,0} %broadcast.4537), metadata={op_type="aten__add" op_name="aten__add.169/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4539 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4547 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4539), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4548 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4538, bf16[1,1025,4096]{2,1,0} %broadcast.4547), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4541 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4542 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4541), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4543 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4538, bf16[1,1025,4096]{2,1,0} %broadcast.4542), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4544 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4543), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4540 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4545 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4540), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4546 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4544, bf16[1,1025,4096]{2,1,0} %broadcast.4545), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4549 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4548, bf16[1,1025,4096]{2,1,0} %add.4546), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4550 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4549), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p200.838 = bf16[1024,4096]{1,0} parameter(200), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.839 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p200.838), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4551 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4550, bf16[4096,1024]{0,1} %transpose.839), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4552 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4551), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p199.837 = bf16[1024]{0} parameter(199), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.836 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4553 = bf16[1024]{0} broadcast(bf16[] %constant.836), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.170/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4554 = bf16[1024]{0} multiply(bf16[1024]{0} %p199.837, bf16[1024]{0} %broadcast.4553), metadata={op_type="aten__add" op_name="aten__add.170/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4555 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4554), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.170/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4556 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4552, bf16[1,1025,1024]{2,1,0} %broadcast.4555), metadata={op_type="aten__add" op_name="aten__add.170/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4557 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4556), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p198.834 = bf16[1024]{0} parameter(198), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.835 = f32[1024]{0} convert(bf16[1024]{0} %p198.834), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4558 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.835), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.171/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4559 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4557, f32[1,1025,1024]{2,1,0} %broadcast.4558), metadata={op_type="aten__mul" op_name="aten__mul.171/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4560 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4559), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.833 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4561 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.833), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.172/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4562 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4560, bf16[1,1025,1024]{2,1,0} %broadcast.4561), metadata={op_type="aten__add" op_name="aten__add.172/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4563 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4515, bf16[1,1025,1024]{2,1,0} %multiply.4562), metadata={op_type="aten__add" op_name="aten__add.172/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.828 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.829 = bf16[1]{0} reshape(bf16[] %constant.828), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.830 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.829), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.831 = bf16[] reshape(bf16[1]{0} %broadcast.830), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.832 = bf16[1025]{0} broadcast(bf16[] %reshape.831), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.823 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.824 = bf16[1]{0} reshape(bf16[] %constant.823), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.825 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.824), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.826 = bf16[] reshape(bf16[1]{0} %broadcast.825), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.827 = bf16[1025]{0} broadcast(bf16[] %reshape.826), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4564 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4563, bf16[1025]{0} %broadcast.832, bf16[1025]{0} %broadcast.827), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4566 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4564), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4567 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4564), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4568 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4569 = bf16[1025]{0} broadcast(bf16[] %constant.4568), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4570 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4567, bf16[1025]{0} %broadcast.4569), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4571 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4570), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p471.4572 = bf16[1024]{0} parameter(471), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4578 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p471.4572), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4565 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4564), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p197.812 = bf16[1024]{0} parameter(197), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4574 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p197.812), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4575 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4565, bf16[1,1025,1024]{2,1,0} %broadcast.4574), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.811 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4573 = bf16[] convert(s64[] %constant.811), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4576 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4573), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4577 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4575, bf16[1,1025,1024]{2,1,0} %broadcast.4576), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4579 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4578, bf16[1,1025,1024]{2,1,0} %multiply.4577), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4580 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4579), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p196.809 = bf16[3072,1024]{1,0} parameter(196), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.810 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p196.809), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4581 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4580, bf16[1024,3072]{0,1} %transpose.810), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4582 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4581), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p195.808 = bf16[3072]{0} parameter(195), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.807 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4583 = bf16[3072]{0} broadcast(bf16[] %constant.807), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.173/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4584 = bf16[3072]{0} multiply(bf16[3072]{0} %p195.808, bf16[3072]{0} %broadcast.4583), metadata={op_type="aten__add" op_name="aten__add.173/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4585 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4584), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.173/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4586 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4582, bf16[1,1025,3072]{2,1,0} %broadcast.4585), metadata={op_type="aten__add" op_name="aten__add.173/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4587 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4586), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4588 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4587), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4598 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4588), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4599 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4598), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4600 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4599), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4601 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.174/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4602 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4600, f32[1,16,1025,64]{3,2,1,0} %broadcast.4601), metadata={op_type="aten__mul" op_name="aten__mul.174/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4603 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4602), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4604 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4603), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4605 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4604), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4593 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4588), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4594 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4593), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4595 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4594), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4596 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4595), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4597 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4596), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4606 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4605, bf16[16,64,1025]{2,1,0} %reshape.4597), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4607 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4606), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4608 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4613 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4607, bf16[] %constant.4608), dimensions={3}, to_apply=%MaxComputation.4609, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4614 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4613), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4615 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4607, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4614), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4616 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4615), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4617 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4622 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4616, bf16[] %constant.4617), dimensions={3}, to_apply=%AddComputation.4618, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4623 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4622), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4624 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4616, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4623), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4625 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4624), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4626 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4625), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4589 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4588), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4590 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4589), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4591 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4590), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4592 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4591), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4627 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4626, bf16[16,1025,64]{2,1,0} %reshape.4592), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4628 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4627), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4629 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4628), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4630 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4629), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4631 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4630), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p194.805 = bf16[1024,1024]{1,0} parameter(194), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.806 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p194.805), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4632 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4631, bf16[1024,1024]{0,1} %transpose.806), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4633 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4632), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p193.804 = bf16[1024]{0} parameter(193), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.803 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4634 = bf16[1024]{0} broadcast(bf16[] %constant.803), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4635 = bf16[1024]{0} multiply(bf16[1024]{0} %p193.804, bf16[1024]{0} %broadcast.4634), metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4636 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4635), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4637 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4633, bf16[1,1025,1024]{2,1,0} %broadcast.4636), metadata={op_type="aten__add" op_name="aten__add.175/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4638 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4637), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p192.801 = bf16[1024]{0} parameter(192), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.802 = f32[1024]{0} convert(bf16[1024]{0} %p192.801), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4639 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.802), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.176/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4640 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4638, f32[1,1025,1024]{2,1,0} %broadcast.4639), metadata={op_type="aten__mul" op_name="aten__mul.176/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4641 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4640), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.800 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4642 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.800), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.177/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4643 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4641, bf16[1,1025,1024]{2,1,0} %broadcast.4642), metadata={op_type="aten__add" op_name="aten__add.177/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4644 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4563, bf16[1,1025,1024]{2,1,0} %multiply.4643), metadata={op_type="aten__add" op_name="aten__add.177/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.795 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.796 = bf16[1]{0} reshape(bf16[] %constant.795), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.797 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.796), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.798 = bf16[] reshape(bf16[1]{0} %broadcast.797), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.799 = bf16[1025]{0} broadcast(bf16[] %reshape.798), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.790 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.791 = bf16[1]{0} reshape(bf16[] %constant.790), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.792 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.791), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.793 = bf16[] reshape(bf16[1]{0} %broadcast.792), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.794 = bf16[1025]{0} broadcast(bf16[] %reshape.793), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4645 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4644, bf16[1025]{0} %broadcast.799, bf16[1025]{0} %broadcast.794), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4647 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4645), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4648 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4645), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4649 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4650 = bf16[1025]{0} broadcast(bf16[] %constant.4649), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4651 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4648, bf16[1025]{0} %broadcast.4650), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4652 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4651), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p472.4653 = bf16[1024]{0} parameter(472), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4659 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p472.4653), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4646 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4645), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p191.779 = bf16[1024]{0} parameter(191), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4655 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p191.779), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4656 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4646, bf16[1,1025,1024]{2,1,0} %broadcast.4655), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.778 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4654 = bf16[] convert(s64[] %constant.778), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4657 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4654), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4658 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4656, bf16[1,1025,1024]{2,1,0} %broadcast.4657), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4660 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4659, bf16[1,1025,1024]{2,1,0} %multiply.4658), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4661 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4660), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p190.776 = bf16[4096,1024]{1,0} parameter(190), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.777 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p190.776), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4662 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4661, bf16[1024,4096]{0,1} %transpose.777), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4663 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4662), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p189.775 = bf16[4096]{0} parameter(189), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.774 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4664 = bf16[4096]{0} broadcast(bf16[] %constant.774), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.178/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4665 = bf16[4096]{0} multiply(bf16[4096]{0} %p189.775, bf16[4096]{0} %broadcast.4664), metadata={op_type="aten__add" op_name="aten__add.178/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4666 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4665), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.178/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4667 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4663, bf16[1,1025,4096]{2,1,0} %broadcast.4666), metadata={op_type="aten__add" op_name="aten__add.178/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4668 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4676 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4668), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4677 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4667, bf16[1,1025,4096]{2,1,0} %broadcast.4676), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4670 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4671 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4670), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4672 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4667, bf16[1,1025,4096]{2,1,0} %broadcast.4671), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4673 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4672), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4669 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4674 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4669), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4675 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4673, bf16[1,1025,4096]{2,1,0} %broadcast.4674), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4678 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4677, bf16[1,1025,4096]{2,1,0} %add.4675), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4679 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4678), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p188.772 = bf16[1024,4096]{1,0} parameter(188), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.773 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p188.772), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4680 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4679, bf16[4096,1024]{0,1} %transpose.773), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4681 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4680), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p187.771 = bf16[1024]{0} parameter(187), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.770 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4682 = bf16[1024]{0} broadcast(bf16[] %constant.770), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.179/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4683 = bf16[1024]{0} multiply(bf16[1024]{0} %p187.771, bf16[1024]{0} %broadcast.4682), metadata={op_type="aten__add" op_name="aten__add.179/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4684 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4683), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.179/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4685 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4681, bf16[1,1025,1024]{2,1,0} %broadcast.4684), metadata={op_type="aten__add" op_name="aten__add.179/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4686 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4685), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p186.768 = bf16[1024]{0} parameter(186), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.769 = f32[1024]{0} convert(bf16[1024]{0} %p186.768), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4687 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.769), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.180/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4688 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4686, f32[1,1025,1024]{2,1,0} %broadcast.4687), metadata={op_type="aten__mul" op_name="aten__mul.180/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4689 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4688), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.767 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4690 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.767), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.181/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4691 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4689, bf16[1,1025,1024]{2,1,0} %broadcast.4690), metadata={op_type="aten__add" op_name="aten__add.181/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4692 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4644, bf16[1,1025,1024]{2,1,0} %multiply.4691), metadata={op_type="aten__add" op_name="aten__add.181/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.762 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.763 = bf16[1]{0} reshape(bf16[] %constant.762), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.764 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.763), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.765 = bf16[] reshape(bf16[1]{0} %broadcast.764), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.766 = bf16[1025]{0} broadcast(bf16[] %reshape.765), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.757 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.758 = bf16[1]{0} reshape(bf16[] %constant.757), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.759 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.758), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.760 = bf16[] reshape(bf16[1]{0} %broadcast.759), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.761 = bf16[1025]{0} broadcast(bf16[] %reshape.760), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4693 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4692, bf16[1025]{0} %broadcast.766, bf16[1025]{0} %broadcast.761), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4695 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4693), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4696 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4693), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4697 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4698 = bf16[1025]{0} broadcast(bf16[] %constant.4697), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4699 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4696, bf16[1025]{0} %broadcast.4698), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4700 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4699), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p473.4701 = bf16[1024]{0} parameter(473), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4707 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p473.4701), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4694 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4693), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p185.746 = bf16[1024]{0} parameter(185), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4703 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p185.746), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4704 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4694, bf16[1,1025,1024]{2,1,0} %broadcast.4703), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.745 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4702 = bf16[] convert(s64[] %constant.745), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4705 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4702), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4706 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4704, bf16[1,1025,1024]{2,1,0} %broadcast.4705), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4708 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4707, bf16[1,1025,1024]{2,1,0} %multiply.4706), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4709 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4708), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p184.743 = bf16[3072,1024]{1,0} parameter(184), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.744 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p184.743), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4710 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4709, bf16[1024,3072]{0,1} %transpose.744), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4711 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4710), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p183.742 = bf16[3072]{0} parameter(183), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.741 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4712 = bf16[3072]{0} broadcast(bf16[] %constant.741), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.182/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4713 = bf16[3072]{0} multiply(bf16[3072]{0} %p183.742, bf16[3072]{0} %broadcast.4712), metadata={op_type="aten__add" op_name="aten__add.182/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4714 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4713), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.182/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4715 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4711, bf16[1,1025,3072]{2,1,0} %broadcast.4714), metadata={op_type="aten__add" op_name="aten__add.182/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4716 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4715), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4717 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4716), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4727 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4717), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4728 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4727), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4729 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4728), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4730 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.183/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4731 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4729, f32[1,16,1025,64]{3,2,1,0} %broadcast.4730), metadata={op_type="aten__mul" op_name="aten__mul.183/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4732 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4731), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4733 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4732), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4734 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4733), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4722 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4717), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4723 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4722), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4724 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4723), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4725 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4724), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4726 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4725), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4735 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4734, bf16[16,64,1025]{2,1,0} %reshape.4726), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4736 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4735), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4737 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4742 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4736, bf16[] %constant.4737), dimensions={3}, to_apply=%MaxComputation.4738, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4743 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4742), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4744 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4736, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4743), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4745 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4744), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4746 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4751 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4745, bf16[] %constant.4746), dimensions={3}, to_apply=%AddComputation.4747, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4752 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4751), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4753 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4745, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4752), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4754 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4753), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4755 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4754), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4718 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4717), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4719 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4718), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4720 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4719), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4721 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4720), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4756 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4755, bf16[16,1025,64]{2,1,0} %reshape.4721), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4757 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4756), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4758 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4757), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4759 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4758), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4760 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4759), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p182.739 = bf16[1024,1024]{1,0} parameter(182), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.740 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p182.739), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4761 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4760, bf16[1024,1024]{0,1} %transpose.740), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4762 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4761), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p181.738 = bf16[1024]{0} parameter(181), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.737 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4763 = bf16[1024]{0} broadcast(bf16[] %constant.737), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.184/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4764 = bf16[1024]{0} multiply(bf16[1024]{0} %p181.738, bf16[1024]{0} %broadcast.4763), metadata={op_type="aten__add" op_name="aten__add.184/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4765 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4764), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.184/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4766 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4762, bf16[1,1025,1024]{2,1,0} %broadcast.4765), metadata={op_type="aten__add" op_name="aten__add.184/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4767 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4766), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p180.735 = bf16[1024]{0} parameter(180), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.736 = f32[1024]{0} convert(bf16[1024]{0} %p180.735), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4768 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.736), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.185/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4769 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4767, f32[1,1025,1024]{2,1,0} %broadcast.4768), metadata={op_type="aten__mul" op_name="aten__mul.185/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4770 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4769), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.734 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4771 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.734), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.186/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4772 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4770, bf16[1,1025,1024]{2,1,0} %broadcast.4771), metadata={op_type="aten__add" op_name="aten__add.186/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4773 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4692, bf16[1,1025,1024]{2,1,0} %multiply.4772), metadata={op_type="aten__add" op_name="aten__add.186/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.729 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.730 = bf16[1]{0} reshape(bf16[] %constant.729), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.731 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.730), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.732 = bf16[] reshape(bf16[1]{0} %broadcast.731), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.733 = bf16[1025]{0} broadcast(bf16[] %reshape.732), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.724 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.725 = bf16[1]{0} reshape(bf16[] %constant.724), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.726 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.725), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.727 = bf16[] reshape(bf16[1]{0} %broadcast.726), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.728 = bf16[1025]{0} broadcast(bf16[] %reshape.727), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4774 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4773, bf16[1025]{0} %broadcast.733, bf16[1025]{0} %broadcast.728), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4776 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4774), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4777 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4774), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4778 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4779 = bf16[1025]{0} broadcast(bf16[] %constant.4778), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4780 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4777, bf16[1025]{0} %broadcast.4779), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4781 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4780), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p474.4782 = bf16[1024]{0} parameter(474), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4788 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p474.4782), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4775 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4774), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p179.713 = bf16[1024]{0} parameter(179), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4784 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p179.713), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4785 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4775, bf16[1,1025,1024]{2,1,0} %broadcast.4784), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.712 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4783 = bf16[] convert(s64[] %constant.712), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4786 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4783), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4787 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4785, bf16[1,1025,1024]{2,1,0} %broadcast.4786), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4789 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4788, bf16[1,1025,1024]{2,1,0} %multiply.4787), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4790 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4789), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p178.710 = bf16[4096,1024]{1,0} parameter(178), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.711 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p178.710), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4791 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4790, bf16[1024,4096]{0,1} %transpose.711), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4792 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4791), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p177.709 = bf16[4096]{0} parameter(177), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.708 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4793 = bf16[4096]{0} broadcast(bf16[] %constant.708), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.187/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4794 = bf16[4096]{0} multiply(bf16[4096]{0} %p177.709, bf16[4096]{0} %broadcast.4793), metadata={op_type="aten__add" op_name="aten__add.187/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4795 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4794), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.187/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4796 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4792, bf16[1,1025,4096]{2,1,0} %broadcast.4795), metadata={op_type="aten__add" op_name="aten__add.187/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4797 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4805 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4797), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4806 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4796, bf16[1,1025,4096]{2,1,0} %broadcast.4805), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4799 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4800 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4799), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4801 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4796, bf16[1,1025,4096]{2,1,0} %broadcast.4800), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4802 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4801), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4798 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4803 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4798), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4804 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4802, bf16[1,1025,4096]{2,1,0} %broadcast.4803), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4807 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4806, bf16[1,1025,4096]{2,1,0} %add.4804), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4808 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4807), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p176.706 = bf16[1024,4096]{1,0} parameter(176), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.707 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p176.706), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4809 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4808, bf16[4096,1024]{0,1} %transpose.707), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4810 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4809), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p175.705 = bf16[1024]{0} parameter(175), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.704 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4811 = bf16[1024]{0} broadcast(bf16[] %constant.704), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.188/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4812 = bf16[1024]{0} multiply(bf16[1024]{0} %p175.705, bf16[1024]{0} %broadcast.4811), metadata={op_type="aten__add" op_name="aten__add.188/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4813 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4812), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.188/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4814 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4810, bf16[1,1025,1024]{2,1,0} %broadcast.4813), metadata={op_type="aten__add" op_name="aten__add.188/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4815 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4814), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p174.702 = bf16[1024]{0} parameter(174), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.703 = f32[1024]{0} convert(bf16[1024]{0} %p174.702), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4816 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.703), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.189/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4817 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4815, f32[1,1025,1024]{2,1,0} %broadcast.4816), metadata={op_type="aten__mul" op_name="aten__mul.189/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4818 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4817), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.701 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4819 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.701), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.190/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4820 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4818, bf16[1,1025,1024]{2,1,0} %broadcast.4819), metadata={op_type="aten__add" op_name="aten__add.190/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4821 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4773, bf16[1,1025,1024]{2,1,0} %multiply.4820), metadata={op_type="aten__add" op_name="aten__add.190/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.696 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.697 = bf16[1]{0} reshape(bf16[] %constant.696), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.698 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.697), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.699 = bf16[] reshape(bf16[1]{0} %broadcast.698), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.700 = bf16[1025]{0} broadcast(bf16[] %reshape.699), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.691 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.692 = bf16[1]{0} reshape(bf16[] %constant.691), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.693 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.692), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.694 = bf16[] reshape(bf16[1]{0} %broadcast.693), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.695 = bf16[1025]{0} broadcast(bf16[] %reshape.694), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4822 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4821, bf16[1025]{0} %broadcast.700, bf16[1025]{0} %broadcast.695), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4824 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4822), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4825 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4822), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4826 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4827 = bf16[1025]{0} broadcast(bf16[] %constant.4826), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4828 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4825, bf16[1025]{0} %broadcast.4827), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4829 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4828), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p475.4830 = bf16[1024]{0} parameter(475), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4836 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p475.4830), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4823 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4822), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p173.680 = bf16[1024]{0} parameter(173), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4832 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p173.680), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4833 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4823, bf16[1,1025,1024]{2,1,0} %broadcast.4832), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.679 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4831 = bf16[] convert(s64[] %constant.679), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4834 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4831), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4835 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4833, bf16[1,1025,1024]{2,1,0} %broadcast.4834), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4837 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4836, bf16[1,1025,1024]{2,1,0} %multiply.4835), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4838 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4837), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p172.677 = bf16[3072,1024]{1,0} parameter(172), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.678 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p172.677), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4839 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4838, bf16[1024,3072]{0,1} %transpose.678), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4840 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4839), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p171.676 = bf16[3072]{0} parameter(171), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.675 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4841 = bf16[3072]{0} broadcast(bf16[] %constant.675), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.191/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4842 = bf16[3072]{0} multiply(bf16[3072]{0} %p171.676, bf16[3072]{0} %broadcast.4841), metadata={op_type="aten__add" op_name="aten__add.191/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4843 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4842), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.191/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4844 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4840, bf16[1,1025,3072]{2,1,0} %broadcast.4843), metadata={op_type="aten__add" op_name="aten__add.191/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4845 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4844), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4846 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4845), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4856 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4846), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4857 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4856), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4858 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4857), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4859 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.192/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4860 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4858, f32[1,16,1025,64]{3,2,1,0} %broadcast.4859), metadata={op_type="aten__mul" op_name="aten__mul.192/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4861 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4860), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4862 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4861), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4863 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4862), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4851 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4846), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4852 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4851), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4853 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4852), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4854 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4853), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4855 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4854), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4864 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4863, bf16[16,64,1025]{2,1,0} %reshape.4855), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4865 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4864), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4866 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4871 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4865, bf16[] %constant.4866), dimensions={3}, to_apply=%MaxComputation.4867, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4872 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4871), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.4873 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4865, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4872), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.4874 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.4873), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.4875 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.4880 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4874, bf16[] %constant.4875), dimensions={3}, to_apply=%AddComputation.4876, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4881 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.4880), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.4882 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.4874, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4881), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.4883 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.4882), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4884 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.4883), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4847 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4846), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4848 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4847), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4849 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4848), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4850 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4849), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.4885 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.4884, bf16[16,1025,64]{2,1,0} %reshape.4850), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4886 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.4885), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.4887 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4886), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4888 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.4887), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4889 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.4888), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p170.673 = bf16[1024,1024]{1,0} parameter(170), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.674 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p170.673), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4890 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4889, bf16[1024,1024]{0,1} %transpose.674), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4891 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4890), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p169.672 = bf16[1024]{0} parameter(169), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.671 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4892 = bf16[1024]{0} broadcast(bf16[] %constant.671), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4893 = bf16[1024]{0} multiply(bf16[1024]{0} %p169.672, bf16[1024]{0} %broadcast.4892), metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4894 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4893), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4895 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4891, bf16[1,1025,1024]{2,1,0} %broadcast.4894), metadata={op_type="aten__add" op_name="aten__add.193/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4896 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4895), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p168.669 = bf16[1024]{0} parameter(168), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.670 = f32[1024]{0} convert(bf16[1024]{0} %p168.669), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4897 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.670), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.194/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4898 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4896, f32[1,1025,1024]{2,1,0} %broadcast.4897), metadata={op_type="aten__mul" op_name="aten__mul.194/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.4899 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4898), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.668 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.4900 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.668), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.195/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.4901 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4899, bf16[1,1025,1024]{2,1,0} %broadcast.4900), metadata={op_type="aten__add" op_name="aten__add.195/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.4902 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4821, bf16[1,1025,1024]{2,1,0} %multiply.4901), metadata={op_type="aten__add" op_name="aten__add.195/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.663 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.664 = bf16[1]{0} reshape(bf16[] %constant.663), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.665 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.664), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.666 = bf16[] reshape(bf16[1]{0} %broadcast.665), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.667 = bf16[1025]{0} broadcast(bf16[] %reshape.666), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.658 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.659 = bf16[1]{0} reshape(bf16[] %constant.658), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.660 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.659), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.661 = bf16[] reshape(bf16[1]{0} %broadcast.660), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.662 = bf16[1025]{0} broadcast(bf16[] %reshape.661), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4903 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4902, bf16[1025]{0} %broadcast.667, bf16[1025]{0} %broadcast.662), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4905 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4903), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4906 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4903), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4907 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4908 = bf16[1025]{0} broadcast(bf16[] %constant.4907), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4909 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4906, bf16[1025]{0} %broadcast.4908), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4910 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4909), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p476.4911 = bf16[1024]{0} parameter(476), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4917 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p476.4911), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4904 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4903), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p167.647 = bf16[1024]{0} parameter(167), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4913 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p167.647), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4914 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4904, bf16[1,1025,1024]{2,1,0} %broadcast.4913), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.646 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4912 = bf16[] convert(s64[] %constant.646), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4915 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4912), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4916 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4914, bf16[1,1025,1024]{2,1,0} %broadcast.4915), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4918 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4917, bf16[1,1025,1024]{2,1,0} %multiply.4916), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4919 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4918), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p166.644 = bf16[4096,1024]{1,0} parameter(166), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.645 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p166.644), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4920 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4919, bf16[1024,4096]{0,1} %transpose.645), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4921 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.4920), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p165.643 = bf16[4096]{0} parameter(165), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.642 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4922 = bf16[4096]{0} broadcast(bf16[] %constant.642), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.196/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4923 = bf16[4096]{0} multiply(bf16[4096]{0} %p165.643, bf16[4096]{0} %broadcast.4922), metadata={op_type="aten__add" op_name="aten__add.196/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4924 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.4923), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.196/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4925 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.4921, bf16[1,1025,4096]{2,1,0} %broadcast.4924), metadata={op_type="aten__add" op_name="aten__add.196/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.4926 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4934 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4926), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4935 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4925, bf16[1,1025,4096]{2,1,0} %broadcast.4934), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4928 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4929 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4928), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4930 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.4925, bf16[1,1025,4096]{2,1,0} %broadcast.4929), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.4931 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.4930), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.4927 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.4932 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.4927), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.4933 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.4931, bf16[1,1025,4096]{2,1,0} %broadcast.4932), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.4936 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.4935, bf16[1,1025,4096]{2,1,0} %add.4933), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.4937 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.4936), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p164.640 = bf16[1024,4096]{1,0} parameter(164), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.641 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p164.640), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4938 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.4937, bf16[4096,1024]{0,1} %transpose.641), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4939 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.4938), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p163.639 = bf16[1024]{0} parameter(163), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.638 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4940 = bf16[1024]{0} broadcast(bf16[] %constant.638), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.197/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4941 = bf16[1024]{0} multiply(bf16[1024]{0} %p163.639, bf16[1024]{0} %broadcast.4940), metadata={op_type="aten__add" op_name="aten__add.197/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4942 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.4941), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.197/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4943 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.4939, bf16[1,1025,1024]{2,1,0} %broadcast.4942), metadata={op_type="aten__add" op_name="aten__add.197/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.4944 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.4943), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p162.636 = bf16[1024]{0} parameter(162), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.637 = f32[1024]{0} convert(bf16[1024]{0} %p162.636), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4945 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.637), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.198/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4946 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.4944, f32[1,1025,1024]{2,1,0} %broadcast.4945), metadata={op_type="aten__mul" op_name="aten__mul.198/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.4947 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.4946), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.635 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.4948 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.635), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.199/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.4949 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.4947, bf16[1,1025,1024]{2,1,0} %broadcast.4948), metadata={op_type="aten__add" op_name="aten__add.199/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.4950 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4902, bf16[1,1025,1024]{2,1,0} %multiply.4949), metadata={op_type="aten__add" op_name="aten__add.199/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.630 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.631 = bf16[1]{0} reshape(bf16[] %constant.630), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.632 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.631), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.633 = bf16[] reshape(bf16[1]{0} %broadcast.632), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.634 = bf16[1025]{0} broadcast(bf16[] %reshape.633), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.625 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.626 = bf16[1]{0} reshape(bf16[] %constant.625), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.627 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.626), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.628 = bf16[] reshape(bf16[1]{0} %broadcast.627), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.629 = bf16[1025]{0} broadcast(bf16[] %reshape.628), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.4951 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.4950, bf16[1025]{0} %broadcast.634, bf16[1025]{0} %broadcast.629), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4953 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4951), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4954 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4951), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.4955 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4956 = bf16[1025]{0} broadcast(bf16[] %constant.4955), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4957 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.4954, bf16[1025]{0} %broadcast.4956), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.4958 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.4957), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p477.4959 = bf16[1024]{0} parameter(477), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4965 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p477.4959), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.4952 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.4951), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p161.614 = bf16[1024]{0} parameter(161), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.4961 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p161.614), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4962 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.4952, bf16[1,1025,1024]{2,1,0} %broadcast.4961), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.613 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.4960 = bf16[] convert(s64[] %constant.613), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.4963 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.4960), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.4964 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.4962, bf16[1,1025,1024]{2,1,0} %broadcast.4963), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.4966 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.4965, bf16[1,1025,1024]{2,1,0} %multiply.4964), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.4967 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.4966), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p160.611 = bf16[3072,1024]{1,0} parameter(160), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.612 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p160.611), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.4968 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.4967, bf16[1024,3072]{0,1} %transpose.612), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4969 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.4968), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p159.610 = bf16[3072]{0} parameter(159), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.609 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4970 = bf16[3072]{0} broadcast(bf16[] %constant.609), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.200/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.4971 = bf16[3072]{0} multiply(bf16[3072]{0} %p159.610, bf16[3072]{0} %broadcast.4970), metadata={op_type="aten__add" op_name="aten__add.200/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.4972 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.4971), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.200/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.4973 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.4969, bf16[1,1025,3072]{2,1,0} %broadcast.4972), metadata={op_type="aten__add" op_name="aten__add.200/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.4974 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.4973), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.4975 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.4974), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.4985 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4975), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4986 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4985), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.4987 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.4986), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4988 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.201/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.4989 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.4987, f32[1,16,1025,64]{3,2,1,0} %broadcast.4988), metadata={op_type="aten__mul" op_name="aten__mul.201/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.4990 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.4989), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4991 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.4990), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4992 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4991), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.4980 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4975), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4981 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4980), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.4982 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.4981), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.4983 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.4982), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4984 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.4983), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.4993 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.4992, bf16[16,64,1025]{2,1,0} %reshape.4984), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.4994 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.4993), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.4995 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.5000 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4994, bf16[] %constant.4995), dimensions={3}, to_apply=%MaxComputation.4996, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5001 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.5000), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.5002 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.4994, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5001), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.5003 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.5002), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.5004 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.5009 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.5003, bf16[] %constant.5004), dimensions={3}, to_apply=%AddComputation.5005, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5010 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.5009), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.5011 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.5003, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5010), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5012 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.5011), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5013 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5012), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.4976 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.4975), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.4977 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.4976), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.4978 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.4977), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.4979 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.4978), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.5014 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.5013, bf16[16,1025,64]{2,1,0} %reshape.4979), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5015 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.5014), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.5016 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.5015), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5017 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.5016), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5018 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.5017), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p158.607 = bf16[1024,1024]{1,0} parameter(158), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.608 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p158.607), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5019 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.5018, bf16[1024,1024]{0,1} %transpose.608), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5020 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.5019), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p157.606 = bf16[1024]{0} parameter(157), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.605 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5021 = bf16[1024]{0} broadcast(bf16[] %constant.605), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.202/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5022 = bf16[1024]{0} multiply(bf16[1024]{0} %p157.606, bf16[1024]{0} %broadcast.5021), metadata={op_type="aten__add" op_name="aten__add.202/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5023 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.5022), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.202/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5024 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.5020, bf16[1,1025,1024]{2,1,0} %broadcast.5023), metadata={op_type="aten__add" op_name="aten__add.202/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5025 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.5024), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p156.603 = bf16[1024]{0} parameter(156), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.604 = f32[1024]{0} convert(bf16[1024]{0} %p156.603), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.5026 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.604), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.203/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.5027 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.5025, f32[1,1025,1024]{2,1,0} %broadcast.5026), metadata={op_type="aten__mul" op_name="aten__mul.203/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.5028 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.5027), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.602 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.5029 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.602), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.204/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.5030 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.5028, bf16[1,1025,1024]{2,1,0} %broadcast.5029), metadata={op_type="aten__add" op_name="aten__add.204/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.5031 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.4950, bf16[1,1025,1024]{2,1,0} %multiply.5030), metadata={op_type="aten__add" op_name="aten__add.204/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.597 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.598 = bf16[1]{0} reshape(bf16[] %constant.597), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.599 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.598), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.600 = bf16[] reshape(bf16[1]{0} %broadcast.599), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.601 = bf16[1025]{0} broadcast(bf16[] %reshape.600), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.592 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.593 = bf16[1]{0} reshape(bf16[] %constant.592), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.594 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.593), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.595 = bf16[] reshape(bf16[1]{0} %broadcast.594), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.596 = bf16[1025]{0} broadcast(bf16[] %reshape.595), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.5032 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.5031, bf16[1025]{0} %broadcast.601, bf16[1025]{0} %broadcast.596), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5034 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5032), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5035 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5032), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.5036 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5037 = bf16[1025]{0} broadcast(bf16[] %constant.5036), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5038 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.5035, bf16[1025]{0} %broadcast.5037), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.5039 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.5038), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p478.5040 = bf16[1024]{0} parameter(478), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5046 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p478.5040), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5033 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5032), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p155.581 = bf16[1024]{0} parameter(155), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5042 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p155.581), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5043 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.5033, bf16[1,1025,1024]{2,1,0} %broadcast.5042), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.580 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.5041 = bf16[] convert(s64[] %constant.580), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5044 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.5041), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5045 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.5043, bf16[1,1025,1024]{2,1,0} %broadcast.5044), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5047 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.5046, bf16[1,1025,1024]{2,1,0} %multiply.5045), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.5048 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.5047), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p154.578 = bf16[4096,1024]{1,0} parameter(154), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.579 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p154.578), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5049 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.5048, bf16[1024,4096]{0,1} %transpose.579), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5050 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.5049), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p153.577 = bf16[4096]{0} parameter(153), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.576 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5051 = bf16[4096]{0} broadcast(bf16[] %constant.576), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.205/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5052 = bf16[4096]{0} multiply(bf16[4096]{0} %p153.577, bf16[4096]{0} %broadcast.5051), metadata={op_type="aten__add" op_name="aten__add.205/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5053 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.5052), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.205/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5054 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.5050, bf16[1,1025,4096]{2,1,0} %broadcast.5053), metadata={op_type="aten__add" op_name="aten__add.205/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.5055 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5063 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5055), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5064 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.5054, bf16[1,1025,4096]{2,1,0} %broadcast.5063), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.5057 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5058 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5057), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5059 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.5054, bf16[1,1025,4096]{2,1,0} %broadcast.5058), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.5060 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.5059), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.5056 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5061 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5056), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.5062 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.5060, bf16[1,1025,4096]{2,1,0} %broadcast.5061), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5065 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.5064, bf16[1,1025,4096]{2,1,0} %add.5062), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.5066 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.5065), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p152.574 = bf16[1024,4096]{1,0} parameter(152), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.575 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p152.574), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5067 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.5066, bf16[4096,1024]{0,1} %transpose.575), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5068 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.5067), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p151.573 = bf16[1024]{0} parameter(151), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.572 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5069 = bf16[1024]{0} broadcast(bf16[] %constant.572), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.206/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5070 = bf16[1024]{0} multiply(bf16[1024]{0} %p151.573, bf16[1024]{0} %broadcast.5069), metadata={op_type="aten__add" op_name="aten__add.206/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5071 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.5070), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.206/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5072 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.5068, bf16[1,1025,1024]{2,1,0} %broadcast.5071), metadata={op_type="aten__add" op_name="aten__add.206/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5073 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.5072), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p150.570 = bf16[1024]{0} parameter(150), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.571 = f32[1024]{0} convert(bf16[1024]{0} %p150.570), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.5074 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.571), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.207/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.5075 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.5073, f32[1,1025,1024]{2,1,0} %broadcast.5074), metadata={op_type="aten__mul" op_name="aten__mul.207/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.5076 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.5075), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.569 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.5077 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.569), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.208/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.5078 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.5076, bf16[1,1025,1024]{2,1,0} %broadcast.5077), metadata={op_type="aten__add" op_name="aten__add.208/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.5079 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.5031, bf16[1,1025,1024]{2,1,0} %multiply.5078), metadata={op_type="aten__add" op_name="aten__add.208/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.564 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.565 = bf16[1]{0} reshape(bf16[] %constant.564), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.566 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.565), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.567 = bf16[] reshape(bf16[1]{0} %broadcast.566), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.568 = bf16[1025]{0} broadcast(bf16[] %reshape.567), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.559 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.560 = bf16[1]{0} reshape(bf16[] %constant.559), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.561 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.560), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.562 = bf16[] reshape(bf16[1]{0} %broadcast.561), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.563 = bf16[1025]{0} broadcast(bf16[] %reshape.562), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.5080 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.5079, bf16[1025]{0} %broadcast.568, bf16[1025]{0} %broadcast.563), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5082 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5080), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5083 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5080), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.5084 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5085 = bf16[1025]{0} broadcast(bf16[] %constant.5084), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5086 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.5083, bf16[1025]{0} %broadcast.5085), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.5087 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.5086), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p479.5088 = bf16[1024]{0} parameter(479), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5094 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p479.5088), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5081 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5080), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p149.548 = bf16[1024]{0} parameter(149), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5090 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p149.548), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5091 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.5081, bf16[1,1025,1024]{2,1,0} %broadcast.5090), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.547 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.5089 = bf16[] convert(s64[] %constant.547), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5092 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.5089), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5093 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.5091, bf16[1,1025,1024]{2,1,0} %broadcast.5092), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5095 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.5094, bf16[1,1025,1024]{2,1,0} %multiply.5093), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.5096 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.5095), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p148.545 = bf16[3072,1024]{1,0} parameter(148), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.546 = bf16[1024,3072]{0,1} transpose(bf16[3072,1024]{1,0} %p148.545), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5097 = bf16[1025,3072]{1,0} dot(bf16[1025,1024]{1,0} %reshape.5096, bf16[1024,3072]{0,1} %transpose.546), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5098 = bf16[1,1025,3072]{2,1,0} reshape(bf16[1025,3072]{1,0} %dot.5097), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p147.544 = bf16[3072]{0} parameter(147), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.543 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5099 = bf16[3072]{0} broadcast(bf16[] %constant.543), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.209/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5100 = bf16[3072]{0} multiply(bf16[3072]{0} %p147.544, bf16[3072]{0} %broadcast.5099), metadata={op_type="aten__add" op_name="aten__add.209/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5101 = bf16[1,1025,3072]{2,1,0} broadcast(bf16[3072]{0} %multiply.5100), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.209/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5102 = bf16[1,1025,3072]{2,1,0} add(bf16[1,1025,3072]{2,1,0} %reshape.5098, bf16[1,1025,3072]{2,1,0} %broadcast.5101), metadata={op_type="aten__add" op_name="aten__add.209/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5103 = bf16[1,1025,3,16,64]{4,3,2,1,0} reshape(bf16[1,1025,3072]{2,1,0} %add.5102), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %transpose.5104 = bf16[3,1,16,1025,64]{4,2,0,3,1} transpose(bf16[1,1025,3,16,64]{4,3,2,1,0} %reshape.5103), dimensions={2,0,3,1,4}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=211}
  %slice.5114 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.5104), slice={[0:1], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.5115 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.5114), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %convert.5116 = f32[1,16,1025,64]{3,2,1,0} convert(bf16[1,16,1025,64]{3,2,1,0} %reshape.5115), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.5117 = f32[1,16,1025,64]{3,2,1,0} broadcast(f32[] %p433.2146), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.210/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %multiply.5118 = f32[1,16,1025,64]{3,2,1,0} multiply(f32[1,16,1025,64]{3,2,1,0} %convert.5116, f32[1,16,1025,64]{3,2,1,0} %broadcast.5117), metadata={op_type="aten__mul" op_name="aten__mul.210/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %convert.5119 = bf16[1,16,1025,64]{3,2,1,0} convert(f32[1,16,1025,64]{3,2,1,0} %multiply.5118), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.5120 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %convert.5119), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.5121 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.5120), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %slice.5109 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.5104), slice={[1:2], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.5110 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.5109), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %transpose.5111 = bf16[1,16,64,1025]{2,3,1,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.5110), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %broadcast.5112 = bf16[1,16,64,1025]{3,2,1,0} broadcast(bf16[1,16,64,1025]{2,3,1,0} %transpose.5111), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.5113 = bf16[16,64,1025]{2,1,0} reshape(bf16[1,16,64,1025]{3,2,1,0} %broadcast.5112), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %dot.5122 = bf16[16,1025,1025]{2,1,0} dot(bf16[16,1025,64]{2,1,0} %reshape.5121, bf16[16,64,1025]{2,1,0} %reshape.5113), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %reshape.5123 = bf16[1,16,1025,1025]{3,2,1,0} reshape(bf16[16,1025,1025]{2,1,0} %dot.5122), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=219}
  %constant.5124 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.5129 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %reshape.5123, bf16[] %constant.5124), dimensions={3}, to_apply=%MaxComputation.5125, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5130 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.5129), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %subtract.5131 = bf16[1,16,1025,1025]{3,2,1,0} subtract(bf16[1,16,1025,1025]{3,2,1,0} %reshape.5123, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5130), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %exponential.5132 = bf16[1,16,1025,1025]{3,2,1,0} exponential(bf16[1,16,1025,1025]{3,2,1,0} %subtract.5131), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %constant.5133 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %reduce.5138 = bf16[1,16,1025]{2,1,0} reduce(bf16[1,16,1025,1025]{3,2,1,0} %exponential.5132, bf16[] %constant.5133), dimensions={3}, to_apply=%AddComputation.5134, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5139 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025]{2,1,0} %reduce.5138), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %divide.5140 = bf16[1,16,1025,1025]{3,2,1,0} divide(bf16[1,16,1025,1025]{3,2,1,0} %exponential.5132, bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5139), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=220}
  %broadcast.5141 = bf16[1,16,1025,1025]{3,2,1,0} broadcast(bf16[1,16,1025,1025]{3,2,1,0} %divide.5140), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5142 = bf16[16,1025,1025]{2,1,0} reshape(bf16[1,16,1025,1025]{3,2,1,0} %broadcast.5141), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %slice.5105 = bf16[1,1,16,1025,64]{4,3,2,1,0} slice(bf16[3,1,16,1025,64]{4,2,0,3,1} %transpose.5104), slice={[2:3], [0:1], [0:16], [0:1025], [0:64]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %reshape.5106 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[1,1,16,1025,64]{4,3,2,1,0} %slice.5105), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=212}
  %broadcast.5107 = bf16[1,16,1025,64]{3,2,1,0} broadcast(bf16[1,16,1025,64]{3,2,1,0} %reshape.5106), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5108 = bf16[16,1025,64]{2,1,0} reshape(bf16[1,16,1025,64]{3,2,1,0} %broadcast.5107), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %dot.5143 = bf16[16,1025,64]{2,1,0} dot(bf16[16,1025,1025]{2,1,0} %reshape.5142, bf16[16,1025,64]{2,1,0} %reshape.5108), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5144 = bf16[1,16,1025,64]{3,2,1,0} reshape(bf16[16,1025,64]{2,1,0} %dot.5143), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %transpose.5145 = bf16[1,1025,16,64]{3,1,2,0} transpose(bf16[1,16,1025,64]{3,2,1,0} %reshape.5144), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5146 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1,1025,16,64]{3,1,2,0} %transpose.5145), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=223}
  %reshape.5147 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %reshape.5146), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p146.541 = bf16[1024,1024]{1,0} parameter(146), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.542 = bf16[1024,1024]{0,1} transpose(bf16[1024,1024]{1,0} %p146.541), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5148 = bf16[1025,1024]{1,0} dot(bf16[1025,1024]{1,0} %reshape.5147, bf16[1024,1024]{0,1} %transpose.542), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5149 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.5148), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p145.540 = bf16[1024]{0} parameter(145), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.539 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5150 = bf16[1024]{0} broadcast(bf16[] %constant.539), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5151 = bf16[1024]{0} multiply(bf16[1024]{0} %p145.540, bf16[1024]{0} %broadcast.5150), metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5152 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.5151), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5153 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.5149, bf16[1,1025,1024]{2,1,0} %broadcast.5152), metadata={op_type="aten__add" op_name="aten__add.211/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5154 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.5153), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %p144.537 = bf16[1024]{0} parameter(144), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.538 = f32[1024]{0} convert(bf16[1024]{0} %p144.537), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.5155 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.538), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.212/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.5156 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.5154, f32[1,1025,1024]{2,1,0} %broadcast.5155), metadata={op_type="aten__mul" op_name="aten__mul.212/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %convert.5157 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.5156), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.536 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %broadcast.5158 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.536), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.213/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %multiply.5159 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.5157, bf16[1,1025,1024]{2,1,0} %broadcast.5158), metadata={op_type="aten__add" op_name="aten__add.213/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %add.5160 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.5079, bf16[1,1025,1024]{2,1,0} %multiply.5159), metadata={op_type="aten__add" op_name="aten__add.213/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=290}
  %constant.531 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.532 = bf16[1]{0} reshape(bf16[] %constant.531), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.533 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.532), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.534 = bf16[] reshape(bf16[1]{0} %broadcast.533), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.535 = bf16[1025]{0} broadcast(bf16[] %reshape.534), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.526 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.527 = bf16[1]{0} reshape(bf16[] %constant.526), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.528 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.527), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.529 = bf16[] reshape(bf16[1]{0} %broadcast.528), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.530 = bf16[1025]{0} broadcast(bf16[] %reshape.529), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.5161 = (bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) batch-norm-training(bf16[1,1025,1024]{2,1,0} %add.5160, bf16[1025]{0} %broadcast.535, bf16[1025]{0} %broadcast.530), epsilon=1e-06, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5163 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5161), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5164 = bf16[1025]{0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5161), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.5165 = bf16[] constant(9.984e-07), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5166 = bf16[1025]{0} broadcast(bf16[] %constant.5165), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5167 = bf16[1025]{0} add(bf16[1025]{0} %get-tuple-element.5164, bf16[1025]{0} %broadcast.5166), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.5168 = bf16[1025]{0} rsqrt(bf16[1025]{0} %add.5167), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p480.5169 = bf16[1024]{0} parameter(480), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5175 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p480.5169), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5162 = bf16[1,1025,1024]{2,1,0} get-tuple-element((bf16[1,1025,1024]{2,1,0}, bf16[1025]{0}, bf16[1025]{0}) %batch-norm-training.5161), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p143.515 = bf16[1024]{0} parameter(143), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5171 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %p143.515), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5172 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %get-tuple-element.5162, bf16[1,1025,1024]{2,1,0} %broadcast.5171), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.514 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.5170 = bf16[] convert(s64[] %constant.514), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5173 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %convert.5170), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5174 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %multiply.5172, bf16[1,1025,1024]{2,1,0} %broadcast.5173), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5176 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %broadcast.5175, bf16[1,1025,1024]{2,1,0} %multiply.5174), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.5177 = bf16[1025,1024]{1,0} reshape(bf16[1,1025,1024]{2,1,0} %add.5176), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p142.512 = bf16[4096,1024]{1,0} parameter(142), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.513 = bf16[1024,4096]{0,1} transpose(bf16[4096,1024]{1,0} %p142.512), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5178 = bf16[1025,4096]{1,0} dot(bf16[1025,1024]{1,0} %reshape.5177, bf16[1024,4096]{0,1} %transpose.513), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5179 = bf16[1,1025,4096]{2,1,0} reshape(bf16[1025,4096]{1,0} %dot.5178), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p141.511 = bf16[4096]{0} parameter(141), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.510 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5180 = bf16[4096]{0} broadcast(bf16[] %constant.510), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.214/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5181 = bf16[4096]{0} multiply(bf16[4096]{0} %p141.511, bf16[4096]{0} %broadcast.5180), metadata={op_type="aten__add" op_name="aten__add.214/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5182 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.5181), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.214/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5183 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %reshape.5179, bf16[1,1025,4096]{2,1,0} %broadcast.5182), metadata={op_type="aten__add" op_name="aten__add.214/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.5184 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5192 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5184), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5193 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.5183, bf16[1,1025,4096]{2,1,0} %broadcast.5192), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.5186 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5187 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5186), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5188 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %add.5183, bf16[1,1025,4096]{2,1,0} %broadcast.5187), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %erf.5189 = bf16[1,1025,4096]{2,1,0} erf(bf16[1,1025,4096]{2,1,0} %multiply.5188), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %constant.5185 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %broadcast.5190 = bf16[1,1025,4096]{2,1,0} broadcast(bf16[] %constant.5185), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %add.5191 = bf16[1,1025,4096]{2,1,0} add(bf16[1,1025,4096]{2,1,0} %erf.5189, bf16[1,1025,4096]{2,1,0} %broadcast.5190), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %multiply.5194 = bf16[1,1025,4096]{2,1,0} multiply(bf16[1,1025,4096]{2,1,0} %multiply.5193, bf16[1,1025,4096]{2,1,0} %add.5191), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/activations.py" source_line=78}
  %reshape.5195 = bf16[1025,4096]{1,0} reshape(bf16[1,1025,4096]{2,1,0} %multiply.5194), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p140.508 = bf16[1024,4096]{1,0} parameter(140), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.509 = bf16[4096,1024]{0,1} transpose(bf16[1024,4096]{1,0} %p140.508), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5196 = bf16[1025,1024]{1,0} dot(bf16[1025,4096]{1,0} %reshape.5195, bf16[4096,1024]{0,1} %transpose.509), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5197 = bf16[1,1025,1024]{2,1,0} reshape(bf16[1025,1024]{1,0} %dot.5196), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p139.507 = bf16[1024]{0} parameter(139), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.506 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5198 = bf16[1024]{0} broadcast(bf16[] %constant.506), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.215/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5199 = bf16[1024]{0} multiply(bf16[1024]{0} %p139.507, bf16[1024]{0} %broadcast.5198), metadata={op_type="aten__add" op_name="aten__add.215/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5200 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[1024]{0} %multiply.5199), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.215/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5201 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %reshape.5197, bf16[1,1025,1024]{2,1,0} %broadcast.5200), metadata={op_type="aten__add" op_name="aten__add.215/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5202 = f32[1,1025,1024]{2,1,0} convert(bf16[1,1025,1024]{2,1,0} %add.5201), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %p138.504 = bf16[1024]{0} parameter(138), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.505 = f32[1024]{0} convert(bf16[1024]{0} %p138.504), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.5203 = f32[1,1025,1024]{2,1,0} broadcast(f32[1024]{0} %convert.505), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.216/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.5204 = f32[1,1025,1024]{2,1,0} multiply(f32[1,1025,1024]{2,1,0} %convert.5202, f32[1,1025,1024]{2,1,0} %broadcast.5203), metadata={op_type="aten__mul" op_name="aten__mul.216/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %convert.5205 = bf16[1,1025,1024]{2,1,0} convert(f32[1,1025,1024]{2,1,0} %multiply.5204), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %constant.503 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %broadcast.5206 = bf16[1,1025,1024]{2,1,0} broadcast(bf16[] %constant.503), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.217/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %multiply.5207 = bf16[1,1025,1024]{2,1,0} multiply(bf16[1,1025,1024]{2,1,0} %convert.5205, bf16[1,1025,1024]{2,1,0} %broadcast.5206), metadata={op_type="aten__add" op_name="aten__add.217/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %add.5208 = bf16[1,1025,1024]{2,1,0} add(bf16[1,1025,1024]{2,1,0} %add.5160, bf16[1,1025,1024]{2,1,0} %multiply.5207), metadata={op_type="aten__add" op_name="aten__add.217/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_intern_vit.py" source_line=292}
  %slice.5209 = bf16[1,1025,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %add.5208), slice={[0:1], [0:1025], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=225}
  %slice.5210 = bf16[1,1024,1024]{2,1,0} slice(bf16[1,1025,1024]{2,1,0} %slice.5209), slice={[0:1], [1:1025], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=225}
  %slice.5211 = bf16[1,1024,1024]{2,1,0} slice(bf16[1,1024,1024]{2,1,0} %slice.5210), slice={[0:1], [0:1024], [0:1024]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=225}
  %reshape.5212 = bf16[1,32,32,1024]{3,2,1,0} reshape(bf16[1,1024,1024]{2,1,0} %slice.5211), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=228}
  %reshape.5213 = bf16[1,32,16,2048]{3,2,1,0} reshape(bf16[1,32,32,1024]{3,2,1,0} %reshape.5212), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=197}
  %transpose.5214 = bf16[1,16,32,2048]{3,1,2,0} transpose(bf16[1,32,16,2048]{3,2,1,0} %reshape.5213), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=199}
  %reshape.5215 = bf16[1,16,16,4096]{3,2,1,0} reshape(bf16[1,16,32,2048]{3,1,2,0} %transpose.5214), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=201}
  %transpose.5216 = bf16[1,16,16,4096]{3,1,2,0} transpose(bf16[1,16,16,4096]{3,2,1,0} %reshape.5215), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=213}
  %reshape.5217 = bf16[1,256,4096]{2,1,0} reshape(bf16[1,16,16,4096]{3,1,2,0} %transpose.5216), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=230}
  %constant.498 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.499 = bf16[1]{0} reshape(bf16[] %constant.498), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.500 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.499), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.501 = bf16[] reshape(bf16[1]{0} %broadcast.500), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.502 = bf16[256]{0} broadcast(bf16[] %reshape.501), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.493 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.494 = bf16[1]{0} reshape(bf16[] %constant.493), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.495 = bf16[1]{0} broadcast(bf16[1]{0} %reshape.494), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.496 = bf16[] reshape(bf16[1]{0} %broadcast.495), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.497 = bf16[256]{0} broadcast(bf16[] %reshape.496), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %batch-norm-training.5218 = (bf16[1,256,4096]{2,1,0}, bf16[256]{0}, bf16[256]{0}) batch-norm-training(bf16[1,256,4096]{2,1,0} %reshape.5217, bf16[256]{0} %broadcast.502, bf16[256]{0} %broadcast.497), epsilon=1e-05, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5220 = bf16[256]{0} get-tuple-element((bf16[1,256,4096]{2,1,0}, bf16[256]{0}, bf16[256]{0}) %batch-norm-training.5218), index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5221 = bf16[256]{0} get-tuple-element((bf16[1,256,4096]{2,1,0}, bf16[256]{0}, bf16[256]{0}) %batch-norm-training.5218), index=2, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.5222 = bf16[] constant(1.001e-05), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5223 = bf16[256]{0} broadcast(bf16[] %constant.5222), dimensions={}, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5224 = bf16[256]{0} add(bf16[256]{0} %get-tuple-element.5221, bf16[256]{0} %broadcast.5223), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %rsqrt.5225 = bf16[256]{0} rsqrt(bf16[256]{0} %add.5224), metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p650.13148 = bf16[4096]{0} parameter(650), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.13149 = f32[4096]{0} convert(bf16[4096]{0} %p650.13148), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.13150 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.13149), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.739/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %p485.5277 = bf16[92553,4096]{1,0} parameter(485), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %p484.5275 = s64[1,310]{1,0} parameter(484), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %reshape.5276 = s64[310]{0} reshape(s64[1,310]{1,0} %p484.5275), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %convert.5278 = u32[310]{0} convert(s64[310]{0} %reshape.5276), metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %gather.5279 = bf16[310,4096]{1,0} gather(bf16[92553,4096]{1,0} %p485.5277, u32[310]{0} %convert.5278), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,4096}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %reshape.5280 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %gather.5279), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2551}
  %reshape.5281 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.5280), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=399}
  %p482.5260 = s64[256,1]{0,1} parameter(482), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %slice.5261 = s64[256,1]{1,0} slice(s64[256,1]{0,1} %p482.5260), slice={[0:256], [0:1]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5262 = s64[256]{0} reshape(s64[256,1]{1,0} %slice.5261), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %constant.5269 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %broadcast.5270 = s64[256]{0} broadcast(s64[] %constant.5269), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %compare.5271 = pred[256]{0} compare(s64[256]{0} %reshape.5262, s64[256]{0} %broadcast.5270), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %p483.5263 = s64[] parameter(483), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5264 = s64[1]{0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %broadcast.5265 = s64[1]{0} broadcast(s64[1]{0} %reshape.5264), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5266 = s64[] reshape(s64[1]{0} %broadcast.5265), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %broadcast.5267 = s64[256]{0} broadcast(s64[] %reshape.5266), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %add.5268 = s64[256]{0} add(s64[256]{0} %reshape.5262, s64[256]{0} %broadcast.5267), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %select.5272 = s64[256]{0} select(pred[256]{0} %compare.5271, s64[256]{0} %add.5268, s64[256]{0} %reshape.5262), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5273 = s64[256,1]{1,0} reshape(s64[256]{0} %select.5272), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %concatenate.5274 = s64[256,1]{1,0} concatenate(s64[256,1]{1,0} %reshape.5273), dimensions={1}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %p481.5226 = bf16[4096]{0} parameter(481), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5232 = bf16[1,256,4096]{2,1,0} broadcast(bf16[4096]{0} %p481.5226), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %get-tuple-element.5219 = bf16[1,256,4096]{2,1,0} get-tuple-element((bf16[1,256,4096]{2,1,0}, bf16[256]{0}, bf16[256]{0}) %batch-norm-training.5218), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %p137.482 = bf16[4096]{0} parameter(137), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %broadcast.5228 = bf16[1,256,4096]{2,1,0} broadcast(bf16[4096]{0} %p137.482), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5229 = bf16[1,256,4096]{2,1,0} multiply(bf16[1,256,4096]{2,1,0} %get-tuple-element.5219, bf16[1,256,4096]{2,1,0} %broadcast.5228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %constant.481 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %convert.5227 = bf16[] convert(s64[] %constant.481), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %broadcast.5230 = bf16[1,256,4096]{2,1,0} broadcast(bf16[] %convert.5227), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %multiply.5231 = bf16[1,256,4096]{2,1,0} multiply(bf16[1,256,4096]{2,1,0} %multiply.5229, bf16[1,256,4096]{2,1,0} %broadcast.5230), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %add.5233 = bf16[1,256,4096]{2,1,0} add(bf16[1,256,4096]{2,1,0} %broadcast.5232, bf16[1,256,4096]{2,1,0} %multiply.5231), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2900}
  %reshape.5234 = bf16[256,4096]{1,0} reshape(bf16[1,256,4096]{2,1,0} %add.5233), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p136.479 = bf16[4096,4096]{1,0} parameter(136), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.480 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p136.479), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5235 = bf16[256,4096]{1,0} dot(bf16[256,4096]{1,0} %reshape.5234, bf16[4096,4096]{0,1} %transpose.480), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5236 = bf16[1,256,4096]{2,1,0} reshape(bf16[256,4096]{1,0} %dot.5235), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p135.478 = bf16[4096]{0} parameter(135), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.477 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5237 = bf16[4096]{0} broadcast(bf16[] %constant.477), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.218/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5238 = bf16[4096]{0} multiply(bf16[4096]{0} %p135.478, bf16[4096]{0} %broadcast.5237), metadata={op_type="aten__add" op_name="aten__add.218/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5239 = bf16[1,256,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.5238), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.218/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5240 = bf16[1,256,4096]{2,1,0} add(bf16[1,256,4096]{2,1,0} %reshape.5236, bf16[1,256,4096]{2,1,0} %broadcast.5239), metadata={op_type="aten__add" op_name="aten__add.218/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.5241 = bf16[] constant(0.5), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %broadcast.5249 = bf16[1,256,4096]{2,1,0} broadcast(bf16[] %constant.5241), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %multiply.5250 = bf16[1,256,4096]{2,1,0} multiply(bf16[1,256,4096]{2,1,0} %add.5240, bf16[1,256,4096]{2,1,0} %broadcast.5249), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %constant.5243 = bf16[] constant(0.707), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %broadcast.5244 = bf16[1,256,4096]{2,1,0} broadcast(bf16[] %constant.5243), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %multiply.5245 = bf16[1,256,4096]{2,1,0} multiply(bf16[1,256,4096]{2,1,0} %add.5240, bf16[1,256,4096]{2,1,0} %broadcast.5244), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %erf.5246 = bf16[1,256,4096]{2,1,0} erf(bf16[1,256,4096]{2,1,0} %multiply.5245), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %constant.5242 = bf16[] constant(1), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %broadcast.5247 = bf16[1,256,4096]{2,1,0} broadcast(bf16[] %constant.5242), dimensions={}, metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %add.5248 = bf16[1,256,4096]{2,1,0} add(bf16[1,256,4096]{2,1,0} %erf.5246, bf16[1,256,4096]{2,1,0} %broadcast.5247), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %multiply.5251 = bf16[1,256,4096]{2,1,0} multiply(bf16[1,256,4096]{2,1,0} %multiply.5250, bf16[1,256,4096]{2,1,0} %add.5248), metadata={op_type="aten__gelu" op_name="aten__gelu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py" source_line=734}
  %reshape.5252 = bf16[256,4096]{1,0} reshape(bf16[1,256,4096]{2,1,0} %multiply.5251), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p134.475 = bf16[4096,4096]{1,0} parameter(134), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.476 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p134.475), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5253 = bf16[256,4096]{1,0} dot(bf16[256,4096]{1,0} %reshape.5252, bf16[4096,4096]{0,1} %transpose.476), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5254 = bf16[1,256,4096]{2,1,0} reshape(bf16[256,4096]{1,0} %dot.5253), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p133.474 = bf16[4096]{0} parameter(133), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %constant.473 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5255 = bf16[4096]{0} broadcast(bf16[] %constant.473), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.219/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %multiply.5256 = bf16[4096]{0} multiply(bf16[4096]{0} %p133.474, bf16[4096]{0} %broadcast.5255), metadata={op_type="aten__add" op_name="aten__add.219/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %broadcast.5257 = bf16[1,256,4096]{2,1,0} broadcast(bf16[4096]{0} %multiply.5256), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add.219/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %add.5258 = bf16[1,256,4096]{2,1,0} add(bf16[1,256,4096]{2,1,0} %reshape.5254, bf16[1,256,4096]{2,1,0} %broadcast.5257), metadata={op_type="aten__add" op_name="aten__add.219/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5259 = bf16[256,4096]{1,0} reshape(bf16[1,256,4096]{2,1,0} %add.5258), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %broadcast.5282 = bf16[256,4096]{1,0} broadcast(bf16[256,4096]{1,0} %reshape.5259), dimensions={0,1}, metadata={op_type="aten__index_put" op_name="aten__index_put" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %scatter.5286 = bf16[310,4096]{1,0} scatter(bf16[310,4096]{1,0} %reshape.5281, s64[256,1]{1,0} %concatenate.5274, bf16[256,4096]{1,0} %broadcast.5282), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%ScatterCombiner.5283, metadata={op_type="aten__index_put" op_name="aten__index_put" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %transpose.5287 = bf16[310,4096]{1,0} transpose(bf16[310,4096]{1,0} %scatter.5286), dimensions={0,1}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5288 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %transpose.5287), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internvl_chat.py" source_line=404}
  %reshape.5289 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.5288), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %reshape.5290 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %reshape.5289), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %p486.5321 = bf16[4096]{0} parameter(486), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.5322 = f32[4096]{0} convert(bf16[4096]{0} %p486.5321), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.5323 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.5322), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.227/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5291 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %reshape.5290), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.472 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5292 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.472), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.5293 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.5291, f32[1,310,4096]{2,1,0} %broadcast.5292), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5294 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.5300 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.5293, f32[] %constant.5294), dimensions={2}, to_apply=%AddComputation.5296, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5295 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5301 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.5306 = pred[] compare(s32[] %constant.5295, s32[] %constant.5301), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5302 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5304 = f32[] convert(s32[] %constant.5295), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.5305 = f32[] divide(f32[] %constant.5302, f32[] %convert.5304), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5303 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.5307 = f32[] select(pred[] %compare.5306, f32[] %divide.5305, f32[] %constant.5303), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5308 = f32[1,310]{1,0} broadcast(f32[] %select.5307), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.5309 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.5300, f32[1,310]{1,0} %broadcast.5308), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.5310 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.5309), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5311 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.5310), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %p4.23 = f32[] parameter(4), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %constant.471 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5312 = f32[] multiply(f32[] %p4.23, f32[] %constant.471), metadata={op_type="aten__add" op_name="aten__add.225/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5313 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.5312), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.225/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.5314 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.5311, f32[1,310,1]{2,1,0} %broadcast.5313), metadata={op_type="aten__add" op_name="aten__add.225/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.5315 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.5314), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.5316 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.5315), metadata={op_type="aten__mul" op_name="aten__mul.226/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5317 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.5316), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.226/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5318 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.5291, f32[1,310,4096]{2,1,0} %broadcast.5317), metadata={op_type="aten__mul" op_name="aten__mul.226/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.5319 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5318), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5320 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.5319), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.5324 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.5323, f32[1,310,4096]{2,1,0} %convert.5320), metadata={op_type="aten__mul" op_name="aten__mul.227/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5325 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5324), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.5326 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5325), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p132.469 = bf16[6144,4096]{1,0} parameter(132), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.470 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p132.469), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5327 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.5326, bf16[4096,6144]{0,1} %transpose.470), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5328 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.5327), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5329 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.5328), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.5497 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5329), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.5498 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5497), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.5499 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5498), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.5500 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.5499), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.5511 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.5500), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p492.5470 = bf16[32768,128]{1,0} parameter(492), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.5471 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p492.5470), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %p489.5381 = s64[1,310]{1,0} parameter(489), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %constant.5409 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %broadcast.5410 = s64[1,310]{1,0} broadcast(s64[] %constant.5409), dimensions={}, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %compare.5411 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %p489.5381, s64[1,310]{1,0} %broadcast.5410), direction=EQ, metadata={op_type="aten__eq" op_name="aten__eq" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %broadcast.5424 = pred[1,310]{1,0} broadcast(pred[1,310]{1,0} %compare.5411), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %constant.5425 = pred[] constant(false), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %broadcast.5426 = pred[1,310]{1,0} broadcast(pred[] %constant.5425), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %compare.5427 = pred[1,310]{1,0} compare(pred[1,310]{1,0} %broadcast.5424, pred[1,310]{1,0} %broadcast.5426), direction=NE, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %constant.5408 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %broadcast.5428 = s64[1,310]{1,0} broadcast(s64[] %constant.5408), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %constant.5414 = s64[] constant(0), metadata={op_type="aten__cumsum" op_name="aten__cumsum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %reduce-window.5419 = s64[1,310]{1,0} reduce-window(s64[1,310]{1,0} %p489.5381, s64[] %constant.5414), window={size=1x310 pad=0_0x309_0}, to_apply=%AddComputation.5415, metadata={op_type="aten__cumsum" op_name="aten__cumsum" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %constant.5413 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %constant.5412 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %multiply.5420 = s64[] multiply(s64[] %constant.5413, s64[] %constant.5412), metadata={op_type="aten__sub" op_name="aten__sub.221/aten__sub" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %broadcast.5421 = s64[1,310]{1,0} broadcast(s64[] %multiply.5420), dimensions={}, metadata={op_type="aten__sub" op_name="aten__sub.221/aten__sub" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %subtract.5422 = s64[1,310]{1,0} subtract(s64[1,310]{1,0} %reduce-window.5419, s64[1,310]{1,0} %broadcast.5421), metadata={op_type="aten__sub" op_name="aten__sub.221/aten__sub" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1130}
  %broadcast.5423 = s64[1,310]{1,0} broadcast(s64[1,310]{1,0} %subtract.5422), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %select.5429 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5427, s64[1,310]{1,0} %broadcast.5428, s64[1,310]{1,0} %broadcast.5423), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1131}
  %constant.5464 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5465 = s64[1,310]{1,0} broadcast(s64[] %constant.5464), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.5466 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5465), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5459 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5460 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5459), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5461 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5460), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5462 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5461), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.5463 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5462), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.5467 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5466, s64[1,310]{1,0} %add.5463, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5468 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5467), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.5469 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5468), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.5472 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5471, s64[1,310,1]{2,1,0} %concatenate.5469), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5473 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5472), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.5510 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5473), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5512 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5510), metadata={op_type="aten__mul" op_name="aten__mul.228/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5513 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5512), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.228/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5514 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.5511, f32[1,32,310,128]{3,2,1,0} %broadcast.5513), metadata={op_type="aten__mul" op_name="aten__mul.228/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5515 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5514), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.5502 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5500), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5503 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.5502), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5501 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5500), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5504 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.5503, bf16[1,32,310,64]{3,2,1,0} %slice.5501), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5505 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.5504), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p491.5441 = bf16[32768,128]{1,0} parameter(491), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.5442 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p491.5441), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.5435 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5436 = s64[1,310]{1,0} broadcast(s64[] %constant.5435), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.5437 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5436), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5430 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5431 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5430), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5432 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5431), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5433 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5432), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.5434 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5433), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.5438 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5437, s64[1,310]{1,0} %add.5434, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5439 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5438), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.5440 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5439), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.5443 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5442, s64[1,310,1]{2,1,0} %concatenate.5440), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5444 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5443), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.5496 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5444), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5506 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5496), metadata={op_type="aten__mul" op_name="aten__mul.229/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5507 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5506), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.229/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5508 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.5505, f32[1,32,310,128]{3,2,1,0} %broadcast.5507), metadata={op_type="aten__mul" op_name="aten__mul.229/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5509 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5508), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.5495 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5516 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.5495), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.230/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5517 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.5509, bf16[1,32,310,128]{3,2,1,0} %broadcast.5516), metadata={op_type="aten__add" op_name="aten__add.230/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.5518 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.5515, bf16[1,32,310,128]{3,2,1,0} %multiply.5517), metadata={op_type="aten__add" op_name="aten__add.230/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5519 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.5518), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5520 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.5519), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.5446 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5329), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.5447 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5446), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.5448 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5447), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.5449 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5448), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.5475 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.5449), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5474 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5473), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5476 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5474), metadata={op_type="aten__mul" op_name="aten__mul.231/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5477 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5476), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.231/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5478 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.5475, f32[1,8,310,128]{3,2,1,0} %broadcast.5477), metadata={op_type="aten__mul" op_name="aten__mul.231/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5479 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5478), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5451 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5449), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5452 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.5451), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5450 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5449), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5453 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.5452, bf16[1,8,310,64]{3,2,1,0} %slice.5450), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5454 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.5453), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5445 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5444), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5455 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5445), metadata={op_type="aten__mul" op_name="aten__mul.232/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5456 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5455), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.232/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5457 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.5454, f32[1,8,310,128]{3,2,1,0} %broadcast.5456), metadata={op_type="aten__mul" op_name="aten__mul.232/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5458 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5457), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.5407 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5480 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.5407), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.233/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5481 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.5458, bf16[1,8,310,128]{3,2,1,0} %broadcast.5480), metadata={op_type="aten__add" op_name="aten__add.233/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.5482 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.5479, bf16[1,8,310,128]{3,2,1,0} %multiply.5481), metadata={op_type="aten__add" op_name="aten__add.233/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5483 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.5482), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5484 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5483), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5485 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5484), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5486 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5485), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5487 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5486), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5488 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5487), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5489 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5488), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5490 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5489), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5491 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5490), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.5492 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.5491), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.5493 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.5492), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5494 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.5493), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.5521 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.5520, bf16[32,128,310]{2,1,0} %reshape.5494), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5522 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.5521), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %p490.5406 = bf16[] parameter(490), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.5523 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.5524 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.5522, bf16[1,32,310,310]{3,2,1,0} %broadcast.5523), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.5380 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %broadcast.5392 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5380), dimensions={}, metadata={op_type="aten__rsub" op_name="aten__rsub.223/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %slice.5382 = s64[1,310]{1,0} slice(s64[1,310]{1,0} %p489.5381), slice={[0:1], [0:310]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %reshape.5383 = s64[1,1,310]{2,1,0} reshape(s64[1,310]{1,0} %slice.5382), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %reshape.5384 = s64[1,1,1,310]{3,2,1,0} reshape(s64[1,1,310]{2,1,0} %reshape.5383), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %slice.5385 = s64[1,1,1,310]{3,2,1,0} slice(s64[1,1,1,310]{3,2,1,0} %reshape.5384), slice={[0:1], [0:1], [0:1], [0:310]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %broadcast.5386 = s64[1,1,1,310]{3,2,1,0} broadcast(s64[1,1,1,310]{3,2,1,0} %slice.5385), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %reshape.5387 = s64[1,1,310]{2,1,0} reshape(s64[1,1,1,310]{3,2,1,0} %broadcast.5386), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %broadcast.5388 = s64[1,1,310,310]{3,2,1,0} broadcast(s64[1,1,310]{2,1,0} %reshape.5387), dimensions={0,1,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %convert.5389 = bf16[1,1,310,310]{3,2,1,0} convert(s64[1,1,310,310]{3,2,1,0} %broadcast.5388), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=121}
  %constant.5379 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %broadcast.5390 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5379), dimensions={}, metadata={op_type="aten__rsub" op_name="aten__rsub.223/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %multiply.5391 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %convert.5389, bf16[1,1,310,310]{3,2,1,0} %broadcast.5390), metadata={op_type="aten__rsub" op_name="aten__rsub.223/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %subtract.5393 = bf16[1,1,310,310]{3,2,1,0} subtract(bf16[1,1,310,310]{3,2,1,0} %broadcast.5392, bf16[1,1,310,310]{3,2,1,0} %multiply.5391), metadata={op_type="aten__rsub" op_name="aten__rsub.223/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %convert.5394 = pred[1,1,310,310]{3,2,1,0} convert(bf16[1,1,310,310]{3,2,1,0} %subtract.5393), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %broadcast.5396 = pred[1,1,310,310]{3,2,1,0} broadcast(pred[1,1,310,310]{3,2,1,0} %convert.5394), dimensions={0,1,2,3}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %constant.5397 = pred[] constant(false), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %broadcast.5398 = pred[1,1,310,310]{3,2,1,0} broadcast(pred[] %constant.5397), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %compare.5399 = pred[1,1,310,310]{3,2,1,0} compare(pred[1,1,310,310]{3,2,1,0} %broadcast.5396, pred[1,1,310,310]{3,2,1,0} %broadcast.5398), direction=NE, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %p488.5378 = f64[] parameter(488), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %convert.5400 = bf16[] convert(f64[] %p488.5378), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %broadcast.5401 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %convert.5400), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %broadcast.5395 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[1,1,310,310]{3,2,1,0} %subtract.5393), dimensions={0,1,2,3}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %select.5402 = bf16[1,1,310,310]{3,2,1,0} select(pred[1,1,310,310]{3,2,1,0} %compare.5399, bf16[1,1,310,310]{3,2,1,0} %broadcast.5401, bf16[1,1,310,310]{3,2,1,0} %broadcast.5395), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=125}
  %constant.5350 = s64[310]{0} constant({...}), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=104}
  %broadcast.5355 = s64[310,310]{1,0} broadcast(s64[310]{0} %constant.5350), dimensions={1}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %constant.5349 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %constant.5348 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %multiply.5351 = s64[] multiply(s64[] %constant.5349, s64[] %constant.5348), metadata={op_type="aten__add" op_name="aten__add.222/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %broadcast.5352 = s64[310]{0} broadcast(s64[] %multiply.5351), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.222/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %add.5353 = s64[310]{0} add(s64[310]{0} %constant.5350, s64[310]{0} %broadcast.5352), metadata={op_type="aten__add" op_name="aten__add.222/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %reshape.5354 = s64[310,1]{1,0} reshape(s64[310]{0} %add.5353), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %reshape.5356 = s64[310]{0} reshape(s64[310,1]{1,0} %reshape.5354), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %broadcast.5357 = s64[310,310]{1,0} broadcast(s64[310]{0} %reshape.5356), dimensions={0}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %compare.5358 = pred[310,310]{1,0} compare(s64[310,310]{1,0} %broadcast.5355, s64[310,310]{1,0} %broadcast.5357), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %broadcast.5365 = pred[310,310]{1,0} broadcast(pred[310,310]{1,0} %compare.5358), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %constant.5366 = pred[] constant(false), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %broadcast.5367 = pred[310,310]{1,0} broadcast(pred[] %constant.5366), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %compare.5368 = pred[310,310]{1,0} compare(pred[310,310]{1,0} %broadcast.5365, pred[310,310]{1,0} %broadcast.5367), direction=NE, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %constant.5347 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %convert.5369 = f32[] convert(s64[] %constant.5347), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %broadcast.5370 = f32[310,310]{1,0} broadcast(f32[] %convert.5369), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %p487.5359 = f32[] parameter(487), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=103}
  %reshape.5360 = f32[1,1]{1,0} reshape(f32[] %p487.5359), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=103}
  %broadcast.5361 = f32[1,1]{1,0} broadcast(f32[1,1]{1,0} %reshape.5360), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=103}
  %reshape.5362 = f32[] reshape(f32[1,1]{1,0} %broadcast.5361), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=103}
  %broadcast.5363 = f32[310,310]{1,0} broadcast(f32[] %reshape.5362), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=103}
  %broadcast.5364 = f32[310,310]{1,0} broadcast(f32[310,310]{1,0} %broadcast.5363), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %select.5371 = f32[310,310]{1,0} select(pred[310,310]{1,0} %compare.5368, f32[310,310]{1,0} %broadcast.5370, f32[310,310]{1,0} %broadcast.5364), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=105}
  %convert.5372 = bf16[310,310]{1,0} convert(f32[310,310]{1,0} %select.5371), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=106}
  %reshape.5373 = bf16[1,310,310]{2,1,0} reshape(bf16[310,310]{1,0} %convert.5372), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=110}
  %reshape.5374 = bf16[1,1,310,310]{3,2,1,0} reshape(bf16[1,310,310]{2,1,0} %reshape.5373), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=110}
  %slice.5375 = bf16[1,1,310,310]{3,2,1,0} slice(bf16[1,1,310,310]{3,2,1,0} %reshape.5374), slice={[0:1], [0:1], [0:310], [0:310]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=110}
  %slice.5376 = bf16[1,1,310,310]{3,2,1,0} slice(bf16[1,1,310,310]{3,2,1,0} %slice.5375), slice={[0:1], [0:1], [0:310], [0:310]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=110}
  %broadcast.5377 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[1,1,310,310]{3,2,1,0} %slice.5376), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=110}
  %constant.5346 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=848}
  %broadcast.5403 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5346), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.224/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=848}
  %multiply.5404 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %broadcast.5377, bf16[1,1,310,310]{3,2,1,0} %broadcast.5403), metadata={op_type="aten__add" op_name="aten__add.224/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=848}
  %add.5405 = bf16[1,1,310,310]{3,2,1,0} add(bf16[1,1,310,310]{3,2,1,0} %select.5402, bf16[1,1,310,310]{3,2,1,0} %multiply.5404), metadata={op_type="aten__add" op_name="aten__add.224/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=848}
  %constant.5345 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.5525 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5345), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.5526 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.5525), metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.5527 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.5526), metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.5528 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.5527), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.5529 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.5524, bf16[1,32,310,310]{3,2,1,0} %broadcast.5528), metadata={op_type="aten__add" op_name="aten__add.234/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.5530 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.5529), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.5531 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.5536 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.5530, f32[] %constant.5531), dimensions={3}, to_apply=%MaxComputation.5532, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.5537 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.5536), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.5538 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.5530, f32[1,32,310,310]{3,2,1,0} %broadcast.5537), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.5539 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.5538), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.5540 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.5545 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.5539, f32[] %constant.5540), dimensions={3}, to_apply=%AddComputation.5541, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.5546 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.5545), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.5547 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.5539, f32[1,32,310,310]{3,2,1,0} %broadcast.5546), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.5548 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.5547), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.5549 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.5548), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5550 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.5549), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.5330 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5329), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.5331 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5330), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.5332 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5331), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.5333 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5332), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.5334 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5333), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5335 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5334), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5336 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5335), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5337 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5336), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5338 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5337), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5339 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5338), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5340 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5339), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5341 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5340), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5342 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5341), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.5343 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.5342), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5344 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.5343), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.5551 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.5550, bf16[32,310,128]{2,1,0} %reshape.5344), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5552 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.5551), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.5553 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.5552), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.5554 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.5553), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.5555 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.5554), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p131.467 = bf16[4096,4096]{1,0} parameter(131), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.468 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p131.467), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5556 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.5555, bf16[4096,4096]{0,1} %transpose.468), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5557 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.5556), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.466 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.5558 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.466), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.235/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.5559 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.5557, bf16[1,310,4096]{2,1,0} %broadcast.5558), metadata={op_type="aten__add" op_name="aten__add.235/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.5560 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %reshape.5290, bf16[1,310,4096]{2,1,0} %multiply.5559), metadata={op_type="aten__add" op_name="aten__add.235/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p493.5591 = bf16[4096]{0} parameter(493), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.5592 = f32[4096]{0} convert(bf16[4096]{0} %p493.5591), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.5593 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.5592), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.238/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5561 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.5560), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.465 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5562 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.465), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.5563 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.5561, f32[1,310,4096]{2,1,0} %broadcast.5562), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5564 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.5570 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.5563, f32[] %constant.5564), dimensions={2}, to_apply=%AddComputation.5566, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5565 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5571 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.5576 = pred[] compare(s32[] %constant.5565, s32[] %constant.5571), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5572 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5574 = f32[] convert(s32[] %constant.5565), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.5575 = f32[] divide(f32[] %constant.5572, f32[] %convert.5574), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5573 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.5577 = f32[] select(pred[] %compare.5576, f32[] %divide.5575, f32[] %constant.5573), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5578 = f32[1,310]{1,0} broadcast(f32[] %select.5577), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.5579 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.5570, f32[1,310]{1,0} %broadcast.5578), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.5580 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.5579), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5581 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.5580), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.464 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5582 = f32[] multiply(f32[] %p4.23, f32[] %constant.464), metadata={op_type="aten__add" op_name="aten__add.236/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5583 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.5582), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.236/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.5584 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.5581, f32[1,310,1]{2,1,0} %broadcast.5583), metadata={op_type="aten__add" op_name="aten__add.236/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.5585 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.5584), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.5586 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.5585), metadata={op_type="aten__mul" op_name="aten__mul.237/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5587 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.5586), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.237/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5588 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.5561, f32[1,310,4096]{2,1,0} %broadcast.5587), metadata={op_type="aten__mul" op_name="aten__mul.237/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.5589 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5588), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5590 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.5589), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.5594 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.5593, f32[1,310,4096]{2,1,0} %convert.5590), metadata={op_type="aten__mul" op_name="aten__mul.238/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5595 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5594), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.5602 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5595), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p494.5600 = bf16[14336,4096]{1,0} parameter(494), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.5601 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p494.5600), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5603 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.5602, bf16[4096,14336]{0,1} %transpose.5601), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5604 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.5603), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.5605 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.5604), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.5606 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.5604, bf16[1,310,14336]{2,1,0} %logistic.5605), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.5607 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.5606), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.5596 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5595), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p130.462 = bf16[14336,4096]{1,0} parameter(130), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.463 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p130.462), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5597 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.5596, bf16[4096,14336]{0,1} %transpose.463), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5598 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.5597), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5599 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.5598), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.5608 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.5607, f32[1,310,14336]{2,1,0} %convert.5599), metadata={op_type="aten__mul" op_name="aten__mul.239/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.5609 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.5608), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.5610 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.5609), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p129.460 = bf16[4096,14336]{1,0} parameter(129), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.461 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p129.460), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5611 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.5610, bf16[14336,4096]{0,1} %transpose.461), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5612 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.5611), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.459 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.5613 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.459), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.240/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.5614 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.5612, bf16[1,310,4096]{2,1,0} %broadcast.5613), metadata={op_type="aten__add" op_name="aten__add.240/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.5615 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.5560, bf16[1,310,4096]{2,1,0} %multiply.5614), metadata={op_type="aten__add" op_name="aten__add.240/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p495.5646 = bf16[4096]{0} parameter(495), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.5647 = f32[4096]{0} convert(bf16[4096]{0} %p495.5646), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.5648 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.5647), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.243/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5616 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.5615), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.458 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5617 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.458), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.5618 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.5616, f32[1,310,4096]{2,1,0} %broadcast.5617), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5619 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.5625 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.5618, f32[] %constant.5619), dimensions={2}, to_apply=%AddComputation.5621, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5620 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5626 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.5631 = pred[] compare(s32[] %constant.5620, s32[] %constant.5626), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5627 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5629 = f32[] convert(s32[] %constant.5620), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.5630 = f32[] divide(f32[] %constant.5627, f32[] %convert.5629), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5628 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.5632 = f32[] select(pred[] %compare.5631, f32[] %divide.5630, f32[] %constant.5628), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5633 = f32[1,310]{1,0} broadcast(f32[] %select.5632), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.5634 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.5625, f32[1,310]{1,0} %broadcast.5633), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.5635 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.5634), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5636 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.5635), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.457 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5637 = f32[] multiply(f32[] %p4.23, f32[] %constant.457), metadata={op_type="aten__add" op_name="aten__add.241/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5638 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.5637), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.241/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.5639 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.5636, f32[1,310,1]{2,1,0} %broadcast.5638), metadata={op_type="aten__add" op_name="aten__add.241/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.5640 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.5639), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.5641 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.5640), metadata={op_type="aten__mul" op_name="aten__mul.242/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5642 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.5641), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.242/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5643 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.5616, f32[1,310,4096]{2,1,0} %broadcast.5642), metadata={op_type="aten__mul" op_name="aten__mul.242/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.5644 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5643), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5645 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.5644), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.5649 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.5648, f32[1,310,4096]{2,1,0} %convert.5645), metadata={op_type="aten__mul" op_name="aten__mul.243/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5650 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5649), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.5651 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5650), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p128.455 = bf16[6144,4096]{1,0} parameter(128), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.456 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p128.455), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5652 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.5651, bf16[4096,6144]{0,1} %transpose.456), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5653 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.5652), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5654 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.5653), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.5739 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5654), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.5740 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5739), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.5741 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5740), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.5742 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.5741), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.5753 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.5742), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p497.5712 = bf16[32768,128]{1,0} parameter(497), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.5713 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p497.5712), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.5706 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5707 = s64[1,310]{1,0} broadcast(s64[] %constant.5706), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.5708 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5707), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5701 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5702 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5701), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5703 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5702), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5704 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5703), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.5705 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5704), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.5709 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5708, s64[1,310]{1,0} %add.5705, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5710 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5709), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.5711 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5710), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.5714 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5713, s64[1,310,1]{2,1,0} %concatenate.5711), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5715 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5714), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.5752 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5715), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5754 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5752), metadata={op_type="aten__mul" op_name="aten__mul.244/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5755 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5754), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.244/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5756 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.5753, f32[1,32,310,128]{3,2,1,0} %broadcast.5755), metadata={op_type="aten__mul" op_name="aten__mul.244/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5757 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5756), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.5744 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5742), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5745 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.5744), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5743 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5742), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5746 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.5745, bf16[1,32,310,64]{3,2,1,0} %slice.5743), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5747 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.5746), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p496.5683 = bf16[32768,128]{1,0} parameter(496), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.5684 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p496.5683), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.5677 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5678 = s64[1,310]{1,0} broadcast(s64[] %constant.5677), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.5679 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5678), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5672 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5673 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5672), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5674 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5673), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5675 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5674), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.5676 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5675), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.5680 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5679, s64[1,310]{1,0} %add.5676, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5681 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5680), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.5682 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5681), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.5685 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5684, s64[1,310,1]{2,1,0} %concatenate.5682), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5686 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5685), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.5738 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5686), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5748 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5738), metadata={op_type="aten__mul" op_name="aten__mul.245/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5749 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5748), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.245/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5750 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.5747, f32[1,32,310,128]{3,2,1,0} %broadcast.5749), metadata={op_type="aten__mul" op_name="aten__mul.245/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5751 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5750), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.5737 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5758 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.5737), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.246/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5759 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.5751, bf16[1,32,310,128]{3,2,1,0} %broadcast.5758), metadata={op_type="aten__add" op_name="aten__add.246/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.5760 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.5757, bf16[1,32,310,128]{3,2,1,0} %multiply.5759), metadata={op_type="aten__add" op_name="aten__add.246/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5761 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.5760), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5762 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.5761), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.5688 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5654), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.5689 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5688), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.5690 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5689), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.5691 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5690), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.5717 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.5691), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5716 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5715), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5718 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5716), metadata={op_type="aten__mul" op_name="aten__mul.247/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5719 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5718), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.247/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5720 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.5717, f32[1,8,310,128]{3,2,1,0} %broadcast.5719), metadata={op_type="aten__mul" op_name="aten__mul.247/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5721 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5720), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5693 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5691), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5694 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.5693), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5692 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5691), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5695 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.5694, bf16[1,8,310,64]{3,2,1,0} %slice.5692), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5696 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.5695), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5687 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5686), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5697 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5687), metadata={op_type="aten__mul" op_name="aten__mul.248/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5698 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5697), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.248/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5699 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.5696, f32[1,8,310,128]{3,2,1,0} %broadcast.5698), metadata={op_type="aten__mul" op_name="aten__mul.248/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5700 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5699), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.5671 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5722 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.5671), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.249/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5723 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.5700, bf16[1,8,310,128]{3,2,1,0} %broadcast.5722), metadata={op_type="aten__add" op_name="aten__add.249/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.5724 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.5721, bf16[1,8,310,128]{3,2,1,0} %multiply.5723), metadata={op_type="aten__add" op_name="aten__add.249/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5725 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.5724), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5726 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5725), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5727 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5726), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5728 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5727), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5729 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5728), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5730 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5729), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5731 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5730), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5732 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5731), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5733 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5732), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.5734 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.5733), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.5735 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.5734), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5736 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.5735), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.5763 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.5762, bf16[32,128,310]{2,1,0} %reshape.5736), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5764 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.5763), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.5765 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.5766 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.5764, bf16[1,32,310,310]{3,2,1,0} %broadcast.5765), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.5670 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.5767 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5670), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.250/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.5768 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.5767), metadata={op_type="aten__add" op_name="aten__add.250/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.5769 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.5768), metadata={op_type="aten__add" op_name="aten__add.250/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.5770 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.5769), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.250/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.5771 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.5766, bf16[1,32,310,310]{3,2,1,0} %broadcast.5770), metadata={op_type="aten__add" op_name="aten__add.250/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.5772 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.5771), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.5773 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.5778 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.5772, f32[] %constant.5773), dimensions={3}, to_apply=%MaxComputation.5774, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.5779 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.5778), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.5780 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.5772, f32[1,32,310,310]{3,2,1,0} %broadcast.5779), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.5781 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.5780), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.5782 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.5787 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.5781, f32[] %constant.5782), dimensions={3}, to_apply=%AddComputation.5783, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.5788 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.5787), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.5789 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.5781, f32[1,32,310,310]{3,2,1,0} %broadcast.5788), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.5790 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.5789), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.5791 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.5790), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5792 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.5791), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.5655 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5654), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.5656 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5655), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.5657 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5656), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.5658 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5657), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.5659 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5658), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5660 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5659), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5661 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5660), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5662 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5661), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5663 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5662), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5664 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5663), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5665 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5664), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5666 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5665), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5667 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5666), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.5668 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.5667), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5669 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.5668), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.5793 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.5792, bf16[32,310,128]{2,1,0} %reshape.5669), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5794 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.5793), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.5795 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.5794), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.5796 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.5795), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.5797 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.5796), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p127.453 = bf16[4096,4096]{1,0} parameter(127), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.454 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p127.453), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5798 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.5797, bf16[4096,4096]{0,1} %transpose.454), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5799 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.5798), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.452 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.5800 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.452), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.251/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.5801 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.5799, bf16[1,310,4096]{2,1,0} %broadcast.5800), metadata={op_type="aten__add" op_name="aten__add.251/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.5802 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.5615, bf16[1,310,4096]{2,1,0} %multiply.5801), metadata={op_type="aten__add" op_name="aten__add.251/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p498.5833 = bf16[4096]{0} parameter(498), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.5834 = f32[4096]{0} convert(bf16[4096]{0} %p498.5833), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.5835 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.5834), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.254/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5803 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.5802), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.451 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5804 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.451), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.5805 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.5803, f32[1,310,4096]{2,1,0} %broadcast.5804), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5806 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.5812 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.5805, f32[] %constant.5806), dimensions={2}, to_apply=%AddComputation.5808, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5807 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5813 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.5818 = pred[] compare(s32[] %constant.5807, s32[] %constant.5813), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5814 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5816 = f32[] convert(s32[] %constant.5807), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.5817 = f32[] divide(f32[] %constant.5814, f32[] %convert.5816), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5815 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.5819 = f32[] select(pred[] %compare.5818, f32[] %divide.5817, f32[] %constant.5815), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5820 = f32[1,310]{1,0} broadcast(f32[] %select.5819), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.5821 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.5812, f32[1,310]{1,0} %broadcast.5820), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.5822 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.5821), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5823 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.5822), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.450 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5824 = f32[] multiply(f32[] %p4.23, f32[] %constant.450), metadata={op_type="aten__add" op_name="aten__add.252/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5825 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.5824), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.252/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.5826 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.5823, f32[1,310,1]{2,1,0} %broadcast.5825), metadata={op_type="aten__add" op_name="aten__add.252/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.5827 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.5826), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.5828 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.5827), metadata={op_type="aten__mul" op_name="aten__mul.253/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5829 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.5828), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.253/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5830 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.5803, f32[1,310,4096]{2,1,0} %broadcast.5829), metadata={op_type="aten__mul" op_name="aten__mul.253/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.5831 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5830), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5832 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.5831), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.5836 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.5835, f32[1,310,4096]{2,1,0} %convert.5832), metadata={op_type="aten__mul" op_name="aten__mul.254/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5837 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5836), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.5844 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5837), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p499.5842 = bf16[14336,4096]{1,0} parameter(499), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.5843 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p499.5842), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5845 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.5844, bf16[4096,14336]{0,1} %transpose.5843), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5846 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.5845), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.5847 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.5846), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.5848 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.5846, bf16[1,310,14336]{2,1,0} %logistic.5847), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.5849 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.5848), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.5838 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5837), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p126.448 = bf16[14336,4096]{1,0} parameter(126), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.449 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p126.448), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5839 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.5838, bf16[4096,14336]{0,1} %transpose.449), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5840 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.5839), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.5841 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.5840), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.5850 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.5849, f32[1,310,14336]{2,1,0} %convert.5841), metadata={op_type="aten__mul" op_name="aten__mul.255/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.5851 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.5850), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.5852 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.5851), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p125.446 = bf16[4096,14336]{1,0} parameter(125), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.447 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p125.446), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5853 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.5852, bf16[14336,4096]{0,1} %transpose.447), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5854 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.5853), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.445 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.5855 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.445), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.256/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.5856 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.5854, bf16[1,310,4096]{2,1,0} %broadcast.5855), metadata={op_type="aten__add" op_name="aten__add.256/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.5857 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.5802, bf16[1,310,4096]{2,1,0} %multiply.5856), metadata={op_type="aten__add" op_name="aten__add.256/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p500.5888 = bf16[4096]{0} parameter(500), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.5889 = f32[4096]{0} convert(bf16[4096]{0} %p500.5888), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.5890 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.5889), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.259/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5858 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.5857), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.444 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5859 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.444), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.5860 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.5858, f32[1,310,4096]{2,1,0} %broadcast.5859), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5861 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.5867 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.5860, f32[] %constant.5861), dimensions={2}, to_apply=%AddComputation.5863, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5862 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5868 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.5873 = pred[] compare(s32[] %constant.5862, s32[] %constant.5868), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5869 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5871 = f32[] convert(s32[] %constant.5862), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.5872 = f32[] divide(f32[] %constant.5869, f32[] %convert.5871), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.5870 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.5874 = f32[] select(pred[] %compare.5873, f32[] %divide.5872, f32[] %constant.5870), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.5875 = f32[1,310]{1,0} broadcast(f32[] %select.5874), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.5876 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.5867, f32[1,310]{1,0} %broadcast.5875), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.5877 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.5876), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.5878 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.5877), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.443 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5879 = f32[] multiply(f32[] %p4.23, f32[] %constant.443), metadata={op_type="aten__add" op_name="aten__add.257/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5880 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.5879), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.257/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.5881 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.5878, f32[1,310,1]{2,1,0} %broadcast.5880), metadata={op_type="aten__add" op_name="aten__add.257/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.5882 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.5881), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.5883 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.5882), metadata={op_type="aten__mul" op_name="aten__mul.258/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.5884 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.5883), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.258/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.5885 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.5858, f32[1,310,4096]{2,1,0} %broadcast.5884), metadata={op_type="aten__mul" op_name="aten__mul.258/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.5886 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5885), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5887 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.5886), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.5891 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.5890, f32[1,310,4096]{2,1,0} %convert.5887), metadata={op_type="aten__mul" op_name="aten__mul.259/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.5892 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.5891), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.5893 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.5892), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p124.441 = bf16[6144,4096]{1,0} parameter(124), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.442 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p124.441), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.5894 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.5893, bf16[4096,6144]{0,1} %transpose.442), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5895 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.5894), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.5896 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.5895), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.5981 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5896), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.5982 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5981), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.5983 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.5982), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.5984 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.5983), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.5995 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.5984), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p502.5954 = bf16[32768,128]{1,0} parameter(502), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.5955 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p502.5954), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.5948 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5949 = s64[1,310]{1,0} broadcast(s64[] %constant.5948), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.5950 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5949), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5943 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5944 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5943), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5945 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5944), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.5946 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5945), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.5947 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5946), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.5951 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5950, s64[1,310]{1,0} %add.5947, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5952 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5951), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.5953 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5952), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.5956 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5955, s64[1,310,1]{2,1,0} %concatenate.5953), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.5957 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5956), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.5994 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5957), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5996 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5994), metadata={op_type="aten__mul" op_name="aten__mul.260/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5997 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5996), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.260/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5998 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.5995, f32[1,32,310,128]{3,2,1,0} %broadcast.5997), metadata={op_type="aten__mul" op_name="aten__mul.260/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5999 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5998), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.5986 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5984), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5987 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.5986), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5985 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.5984), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5988 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.5987, bf16[1,32,310,64]{3,2,1,0} %slice.5985), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5989 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.5988), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p501.5925 = bf16[32768,128]{1,0} parameter(501), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.5926 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p501.5925), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.5919 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5920 = s64[1,310]{1,0} broadcast(s64[] %constant.5919), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.5921 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5920), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5914 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5915 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.5914), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5916 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.5915), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.5917 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.5916), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.5918 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.5917), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.5922 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.5921, s64[1,310]{1,0} %add.5918, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5923 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.5922), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.5924 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.5923), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.5927 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.5926, s64[1,310,1]{2,1,0} %concatenate.5924), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.5928 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.5927), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.5980 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5928), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.5990 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5980), metadata={op_type="aten__mul" op_name="aten__mul.261/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.5991 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5990), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.261/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.5992 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.5989, f32[1,32,310,128]{3,2,1,0} %broadcast.5991), metadata={op_type="aten__mul" op_name="aten__mul.261/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.5993 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.5992), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.5979 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6000 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.5979), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.262/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6001 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.5993, bf16[1,32,310,128]{3,2,1,0} %broadcast.6000), metadata={op_type="aten__add" op_name="aten__add.262/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.6002 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.5999, bf16[1,32,310,128]{3,2,1,0} %multiply.6001), metadata={op_type="aten__add" op_name="aten__add.262/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6003 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.6002), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6004 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6003), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.5930 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5896), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.5931 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5930), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.5932 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5931), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.5933 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5932), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.5959 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.5933), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5958 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5957), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5960 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5958), metadata={op_type="aten__mul" op_name="aten__mul.263/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5961 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5960), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.263/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5962 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.5959, f32[1,8,310,128]{3,2,1,0} %broadcast.5961), metadata={op_type="aten__mul" op_name="aten__mul.263/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5963 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5962), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5935 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5933), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.5936 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.5935), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.5934 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5933), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.5937 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.5936, bf16[1,8,310,64]{3,2,1,0} %slice.5934), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.5938 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.5937), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5929 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.5928), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.5939 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.5929), metadata={op_type="aten__mul" op_name="aten__mul.264/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5940 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.5939), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.264/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5941 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.5938, f32[1,8,310,128]{3,2,1,0} %broadcast.5940), metadata={op_type="aten__mul" op_name="aten__mul.264/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.5942 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.5941), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.5913 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.5964 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.5913), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.265/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.5965 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.5942, bf16[1,8,310,128]{3,2,1,0} %broadcast.5964), metadata={op_type="aten__add" op_name="aten__add.265/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.5966 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.5963, bf16[1,8,310,128]{3,2,1,0} %multiply.5965), metadata={op_type="aten__add" op_name="aten__add.265/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.5967 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.5966), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5968 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5967), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5969 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5968), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5970 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5969), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5971 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5970), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5972 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5971), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5973 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5972), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5974 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5973), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5975 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5974), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.5976 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.5975), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.5977 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.5976), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.5978 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.5977), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.6005 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.6004, bf16[32,128,310]{2,1,0} %reshape.5978), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6006 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.6005), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6007 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.6008 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.6006, bf16[1,32,310,310]{3,2,1,0} %broadcast.6007), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.5912 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6009 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.5912), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.266/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.6010 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.6009), metadata={op_type="aten__add" op_name="aten__add.266/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.6011 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.6010), metadata={op_type="aten__add" op_name="aten__add.266/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6012 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.6011), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.266/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.6013 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.6008, bf16[1,32,310,310]{3,2,1,0} %broadcast.6012), metadata={op_type="aten__add" op_name="aten__add.266/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.6014 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.6013), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6015 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6020 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.6014, f32[] %constant.6015), dimensions={3}, to_apply=%MaxComputation.6016, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6021 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6020), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.6022 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.6014, f32[1,32,310,310]{3,2,1,0} %broadcast.6021), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.6023 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.6022), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6024 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6029 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.6023, f32[] %constant.6024), dimensions={3}, to_apply=%AddComputation.6025, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6030 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6029), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.6031 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.6023, f32[1,32,310,310]{3,2,1,0} %broadcast.6030), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.6032 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.6031), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.6033 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.6032), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6034 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.6033), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.5897 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.5896), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.5898 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.5897), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.5899 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.5898), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.5900 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.5899), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.5901 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.5900), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5902 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.5901), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5903 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.5902), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5904 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.5903), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.5905 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5904), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5906 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.5905), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5907 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.5906), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.5908 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.5907), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.5909 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.5908), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.5910 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.5909), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.5911 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.5910), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.6035 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.6034, bf16[32,310,128]{2,1,0} %reshape.5911), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6036 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.6035), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.6037 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6036), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.6038 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.6037), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.6039 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.6038), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p123.439 = bf16[4096,4096]{1,0} parameter(123), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.440 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p123.439), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6040 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.6039, bf16[4096,4096]{0,1} %transpose.440), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6041 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6040), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.438 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.6042 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.438), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.267/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.6043 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6041, bf16[1,310,4096]{2,1,0} %broadcast.6042), metadata={op_type="aten__add" op_name="aten__add.267/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.6044 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.5857, bf16[1,310,4096]{2,1,0} %multiply.6043), metadata={op_type="aten__add" op_name="aten__add.267/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p503.6075 = bf16[4096]{0} parameter(503), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6076 = f32[4096]{0} convert(bf16[4096]{0} %p503.6075), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6077 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6076), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.270/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6045 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6044), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.437 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6046 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.437), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6047 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6045, f32[1,310,4096]{2,1,0} %broadcast.6046), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6048 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6054 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6047, f32[] %constant.6048), dimensions={2}, to_apply=%AddComputation.6050, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6049 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6055 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6060 = pred[] compare(s32[] %constant.6049, s32[] %constant.6055), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6056 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6058 = f32[] convert(s32[] %constant.6049), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6059 = f32[] divide(f32[] %constant.6056, f32[] %convert.6058), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6057 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6061 = f32[] select(pred[] %compare.6060, f32[] %divide.6059, f32[] %constant.6057), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6062 = f32[1,310]{1,0} broadcast(f32[] %select.6061), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6063 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6054, f32[1,310]{1,0} %broadcast.6062), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6064 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6063), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6065 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6064), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.436 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6066 = f32[] multiply(f32[] %p4.23, f32[] %constant.436), metadata={op_type="aten__add" op_name="aten__add.268/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6067 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6066), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.268/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6068 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6065, f32[1,310,1]{2,1,0} %broadcast.6067), metadata={op_type="aten__add" op_name="aten__add.268/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6069 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6068), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6070 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6069), metadata={op_type="aten__mul" op_name="aten__mul.269/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6071 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6070), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.269/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6072 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6045, f32[1,310,4096]{2,1,0} %broadcast.6071), metadata={op_type="aten__mul" op_name="aten__mul.269/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6073 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6072), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6074 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6073), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6078 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6077, f32[1,310,4096]{2,1,0} %convert.6074), metadata={op_type="aten__mul" op_name="aten__mul.270/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6079 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6078), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6086 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6079), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p504.6084 = bf16[14336,4096]{1,0} parameter(504), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.6085 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p504.6084), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6087 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6086, bf16[4096,14336]{0,1} %transpose.6085), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6088 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6087), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.6089 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.6088), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.6090 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.6088, bf16[1,310,14336]{2,1,0} %logistic.6089), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.6091 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.6090), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6080 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6079), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p122.434 = bf16[14336,4096]{1,0} parameter(122), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.435 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p122.434), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6081 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6080, bf16[4096,14336]{0,1} %transpose.435), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6082 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6081), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.6083 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.6082), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.6092 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.6091, f32[1,310,14336]{2,1,0} %convert.6083), metadata={op_type="aten__mul" op_name="aten__mul.271/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.6093 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.6092), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6094 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.6093), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p121.432 = bf16[4096,14336]{1,0} parameter(121), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.433 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p121.432), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6095 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.6094, bf16[14336,4096]{0,1} %transpose.433), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6096 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6095), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.431 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.6097 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.431), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.272/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.6098 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6096, bf16[1,310,4096]{2,1,0} %broadcast.6097), metadata={op_type="aten__add" op_name="aten__add.272/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.6099 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6044, bf16[1,310,4096]{2,1,0} %multiply.6098), metadata={op_type="aten__add" op_name="aten__add.272/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p505.6130 = bf16[4096]{0} parameter(505), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6131 = f32[4096]{0} convert(bf16[4096]{0} %p505.6130), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6132 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6131), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.275/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6100 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6099), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.430 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6101 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.430), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6102 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6100, f32[1,310,4096]{2,1,0} %broadcast.6101), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6103 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6109 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6102, f32[] %constant.6103), dimensions={2}, to_apply=%AddComputation.6105, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6104 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6110 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6115 = pred[] compare(s32[] %constant.6104, s32[] %constant.6110), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6111 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6113 = f32[] convert(s32[] %constant.6104), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6114 = f32[] divide(f32[] %constant.6111, f32[] %convert.6113), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6112 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6116 = f32[] select(pred[] %compare.6115, f32[] %divide.6114, f32[] %constant.6112), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6117 = f32[1,310]{1,0} broadcast(f32[] %select.6116), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6118 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6109, f32[1,310]{1,0} %broadcast.6117), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6119 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6118), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6120 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6119), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.429 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6121 = f32[] multiply(f32[] %p4.23, f32[] %constant.429), metadata={op_type="aten__add" op_name="aten__add.273/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6122 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6121), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.273/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6123 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6120, f32[1,310,1]{2,1,0} %broadcast.6122), metadata={op_type="aten__add" op_name="aten__add.273/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6124 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6123), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6125 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6124), metadata={op_type="aten__mul" op_name="aten__mul.274/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6126 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6125), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.274/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6127 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6100, f32[1,310,4096]{2,1,0} %broadcast.6126), metadata={op_type="aten__mul" op_name="aten__mul.274/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6128 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6127), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6129 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6128), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6133 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6132, f32[1,310,4096]{2,1,0} %convert.6129), metadata={op_type="aten__mul" op_name="aten__mul.275/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6134 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6133), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6135 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6134), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p120.427 = bf16[6144,4096]{1,0} parameter(120), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.428 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p120.427), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6136 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.6135, bf16[4096,6144]{0,1} %transpose.428), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6137 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.6136), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6138 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.6137), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.6223 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6138), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.6224 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6223), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.6225 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6224), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.6226 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.6225), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.6237 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.6226), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p507.6196 = bf16[32768,128]{1,0} parameter(507), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.6197 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p507.6196), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.6190 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6191 = s64[1,310]{1,0} broadcast(s64[] %constant.6190), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.6192 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6191), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6185 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6186 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6185), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6187 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6186), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6188 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6187), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.6189 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6188), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.6193 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6192, s64[1,310]{1,0} %add.6189, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6194 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6193), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.6195 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6194), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.6198 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6197, s64[1,310,1]{2,1,0} %concatenate.6195), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6199 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6198), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.6236 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6199), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6238 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6236), metadata={op_type="aten__mul" op_name="aten__mul.276/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6239 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6238), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.276/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6240 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.6237, f32[1,32,310,128]{3,2,1,0} %broadcast.6239), metadata={op_type="aten__mul" op_name="aten__mul.276/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6241 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6240), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.6228 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6226), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6229 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.6228), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6227 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6226), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6230 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.6229, bf16[1,32,310,64]{3,2,1,0} %slice.6227), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6231 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.6230), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p506.6167 = bf16[32768,128]{1,0} parameter(506), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.6168 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p506.6167), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.6161 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6162 = s64[1,310]{1,0} broadcast(s64[] %constant.6161), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.6163 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6162), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6156 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6157 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6156), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6158 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6157), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6159 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6158), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.6160 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6159), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.6164 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6163, s64[1,310]{1,0} %add.6160, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6165 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6164), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.6166 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6165), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.6169 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6168, s64[1,310,1]{2,1,0} %concatenate.6166), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6170 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6169), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.6222 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6170), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6232 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6222), metadata={op_type="aten__mul" op_name="aten__mul.277/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6233 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6232), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.277/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6234 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.6231, f32[1,32,310,128]{3,2,1,0} %broadcast.6233), metadata={op_type="aten__mul" op_name="aten__mul.277/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6235 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6234), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.6221 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6242 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.6221), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.278/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6243 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.6235, bf16[1,32,310,128]{3,2,1,0} %broadcast.6242), metadata={op_type="aten__add" op_name="aten__add.278/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.6244 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.6241, bf16[1,32,310,128]{3,2,1,0} %multiply.6243), metadata={op_type="aten__add" op_name="aten__add.278/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6245 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.6244), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6246 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6245), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.6172 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6138), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.6173 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6172), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.6174 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6173), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.6175 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6174), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.6201 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.6175), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6200 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6199), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6202 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6200), metadata={op_type="aten__mul" op_name="aten__mul.279/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6203 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6202), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.279/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6204 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.6201, f32[1,8,310,128]{3,2,1,0} %broadcast.6203), metadata={op_type="aten__mul" op_name="aten__mul.279/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6205 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6204), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6177 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6175), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6178 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.6177), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6176 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6175), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6179 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.6178, bf16[1,8,310,64]{3,2,1,0} %slice.6176), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6180 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.6179), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6171 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6170), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6181 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6171), metadata={op_type="aten__mul" op_name="aten__mul.280/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6182 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6181), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.280/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6183 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.6180, f32[1,8,310,128]{3,2,1,0} %broadcast.6182), metadata={op_type="aten__mul" op_name="aten__mul.280/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6184 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6183), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.6155 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6206 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.6155), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.281/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6207 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.6184, bf16[1,8,310,128]{3,2,1,0} %broadcast.6206), metadata={op_type="aten__add" op_name="aten__add.281/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.6208 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.6205, bf16[1,8,310,128]{3,2,1,0} %multiply.6207), metadata={op_type="aten__add" op_name="aten__add.281/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6209 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.6208), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6210 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6209), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6211 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6210), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6212 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6211), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6213 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6212), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6214 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6213), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6215 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6214), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6216 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6215), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6217 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6216), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.6218 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6217), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6219 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.6218), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6220 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.6219), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.6247 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.6246, bf16[32,128,310]{2,1,0} %reshape.6220), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6248 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.6247), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6249 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.6250 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.6248, bf16[1,32,310,310]{3,2,1,0} %broadcast.6249), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.6154 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6251 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.6154), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.282/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.6252 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.6251), metadata={op_type="aten__add" op_name="aten__add.282/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.6253 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.6252), metadata={op_type="aten__add" op_name="aten__add.282/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6254 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.6253), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.282/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.6255 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.6250, bf16[1,32,310,310]{3,2,1,0} %broadcast.6254), metadata={op_type="aten__add" op_name="aten__add.282/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.6256 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.6255), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6257 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6262 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.6256, f32[] %constant.6257), dimensions={3}, to_apply=%MaxComputation.6258, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6263 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6262), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.6264 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.6256, f32[1,32,310,310]{3,2,1,0} %broadcast.6263), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.6265 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.6264), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6266 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6271 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.6265, f32[] %constant.6266), dimensions={3}, to_apply=%AddComputation.6267, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6272 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6271), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.6273 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.6265, f32[1,32,310,310]{3,2,1,0} %broadcast.6272), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.6274 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.6273), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.6275 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.6274), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6276 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.6275), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.6139 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6138), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.6140 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6139), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.6141 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6140), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.6142 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6141), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.6143 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6142), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6144 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6143), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6145 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6144), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6146 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6145), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6147 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6146), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6148 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6147), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6149 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6148), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6150 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6149), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6151 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6150), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.6152 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.6151), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6153 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6152), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.6277 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.6276, bf16[32,310,128]{2,1,0} %reshape.6153), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6278 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.6277), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.6279 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6278), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.6280 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.6279), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.6281 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.6280), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p119.425 = bf16[4096,4096]{1,0} parameter(119), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.426 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p119.425), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6282 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.6281, bf16[4096,4096]{0,1} %transpose.426), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6283 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6282), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.424 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.6284 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.424), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.283/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.6285 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6283, bf16[1,310,4096]{2,1,0} %broadcast.6284), metadata={op_type="aten__add" op_name="aten__add.283/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.6286 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6099, bf16[1,310,4096]{2,1,0} %multiply.6285), metadata={op_type="aten__add" op_name="aten__add.283/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p508.6317 = bf16[4096]{0} parameter(508), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6318 = f32[4096]{0} convert(bf16[4096]{0} %p508.6317), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6319 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6318), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.286/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6287 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6286), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.423 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6288 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.423), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6289 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6287, f32[1,310,4096]{2,1,0} %broadcast.6288), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6290 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6296 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6289, f32[] %constant.6290), dimensions={2}, to_apply=%AddComputation.6292, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6291 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6297 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6302 = pred[] compare(s32[] %constant.6291, s32[] %constant.6297), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6298 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6300 = f32[] convert(s32[] %constant.6291), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6301 = f32[] divide(f32[] %constant.6298, f32[] %convert.6300), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6299 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6303 = f32[] select(pred[] %compare.6302, f32[] %divide.6301, f32[] %constant.6299), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6304 = f32[1,310]{1,0} broadcast(f32[] %select.6303), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6305 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6296, f32[1,310]{1,0} %broadcast.6304), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6306 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6305), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6307 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6306), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.422 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6308 = f32[] multiply(f32[] %p4.23, f32[] %constant.422), metadata={op_type="aten__add" op_name="aten__add.284/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6309 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6308), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.284/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6310 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6307, f32[1,310,1]{2,1,0} %broadcast.6309), metadata={op_type="aten__add" op_name="aten__add.284/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6311 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6310), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6312 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6311), metadata={op_type="aten__mul" op_name="aten__mul.285/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6313 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6312), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.285/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6314 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6287, f32[1,310,4096]{2,1,0} %broadcast.6313), metadata={op_type="aten__mul" op_name="aten__mul.285/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6315 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6314), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6316 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6315), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6320 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6319, f32[1,310,4096]{2,1,0} %convert.6316), metadata={op_type="aten__mul" op_name="aten__mul.286/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6321 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6320), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6328 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6321), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p509.6326 = bf16[14336,4096]{1,0} parameter(509), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.6327 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p509.6326), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6329 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6328, bf16[4096,14336]{0,1} %transpose.6327), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6330 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6329), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.6331 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.6330), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.6332 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.6330, bf16[1,310,14336]{2,1,0} %logistic.6331), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.6333 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.6332), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6322 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6321), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p118.420 = bf16[14336,4096]{1,0} parameter(118), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.421 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p118.420), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6323 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6322, bf16[4096,14336]{0,1} %transpose.421), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6324 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6323), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.6325 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.6324), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.6334 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.6333, f32[1,310,14336]{2,1,0} %convert.6325), metadata={op_type="aten__mul" op_name="aten__mul.287/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.6335 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.6334), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6336 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.6335), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p117.418 = bf16[4096,14336]{1,0} parameter(117), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.419 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p117.418), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6337 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.6336, bf16[14336,4096]{0,1} %transpose.419), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6338 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6337), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.417 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.6339 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.417), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.288/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.6340 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6338, bf16[1,310,4096]{2,1,0} %broadcast.6339), metadata={op_type="aten__add" op_name="aten__add.288/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.6341 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6286, bf16[1,310,4096]{2,1,0} %multiply.6340), metadata={op_type="aten__add" op_name="aten__add.288/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p510.6372 = bf16[4096]{0} parameter(510), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6373 = f32[4096]{0} convert(bf16[4096]{0} %p510.6372), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6374 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6373), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.291/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6342 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6341), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.416 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6343 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.416), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6344 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6342, f32[1,310,4096]{2,1,0} %broadcast.6343), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6345 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6351 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6344, f32[] %constant.6345), dimensions={2}, to_apply=%AddComputation.6347, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6346 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6352 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6357 = pred[] compare(s32[] %constant.6346, s32[] %constant.6352), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6353 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6355 = f32[] convert(s32[] %constant.6346), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6356 = f32[] divide(f32[] %constant.6353, f32[] %convert.6355), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6354 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6358 = f32[] select(pred[] %compare.6357, f32[] %divide.6356, f32[] %constant.6354), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6359 = f32[1,310]{1,0} broadcast(f32[] %select.6358), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6360 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6351, f32[1,310]{1,0} %broadcast.6359), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6361 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6360), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6362 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6361), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.415 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6363 = f32[] multiply(f32[] %p4.23, f32[] %constant.415), metadata={op_type="aten__add" op_name="aten__add.289/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6364 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6363), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.289/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6365 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6362, f32[1,310,1]{2,1,0} %broadcast.6364), metadata={op_type="aten__add" op_name="aten__add.289/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6366 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6365), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6367 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6366), metadata={op_type="aten__mul" op_name="aten__mul.290/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6368 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6367), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.290/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6369 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6342, f32[1,310,4096]{2,1,0} %broadcast.6368), metadata={op_type="aten__mul" op_name="aten__mul.290/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6370 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6369), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6371 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6370), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6375 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6374, f32[1,310,4096]{2,1,0} %convert.6371), metadata={op_type="aten__mul" op_name="aten__mul.291/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6376 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6375), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6377 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6376), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p116.413 = bf16[6144,4096]{1,0} parameter(116), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.414 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p116.413), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6378 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.6377, bf16[4096,6144]{0,1} %transpose.414), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6379 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.6378), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6380 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.6379), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.6465 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6380), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.6466 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6465), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.6467 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6466), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.6468 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.6467), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.6479 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.6468), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p512.6438 = bf16[32768,128]{1,0} parameter(512), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.6439 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p512.6438), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.6432 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6433 = s64[1,310]{1,0} broadcast(s64[] %constant.6432), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.6434 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6433), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6427 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6428 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6427), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6429 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6428), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6430 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6429), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.6431 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6430), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.6435 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6434, s64[1,310]{1,0} %add.6431, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6436 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6435), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.6437 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6436), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.6440 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6439, s64[1,310,1]{2,1,0} %concatenate.6437), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6441 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6440), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.6478 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6441), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6480 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6478), metadata={op_type="aten__mul" op_name="aten__mul.292/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6481 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6480), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.292/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6482 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.6479, f32[1,32,310,128]{3,2,1,0} %broadcast.6481), metadata={op_type="aten__mul" op_name="aten__mul.292/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6483 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6482), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.6470 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6468), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6471 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.6470), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6469 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6468), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6472 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.6471, bf16[1,32,310,64]{3,2,1,0} %slice.6469), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6473 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.6472), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p511.6409 = bf16[32768,128]{1,0} parameter(511), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.6410 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p511.6409), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.6403 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6404 = s64[1,310]{1,0} broadcast(s64[] %constant.6403), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.6405 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6404), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6398 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6399 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6398), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6400 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6399), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6401 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6400), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.6402 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6401), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.6406 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6405, s64[1,310]{1,0} %add.6402, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6407 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6406), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.6408 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6407), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.6411 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6410, s64[1,310,1]{2,1,0} %concatenate.6408), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6412 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6411), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.6464 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6412), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6474 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6464), metadata={op_type="aten__mul" op_name="aten__mul.293/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6475 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6474), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.293/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6476 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.6473, f32[1,32,310,128]{3,2,1,0} %broadcast.6475), metadata={op_type="aten__mul" op_name="aten__mul.293/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6477 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6476), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.6463 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6484 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.6463), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.294/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6485 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.6477, bf16[1,32,310,128]{3,2,1,0} %broadcast.6484), metadata={op_type="aten__add" op_name="aten__add.294/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.6486 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.6483, bf16[1,32,310,128]{3,2,1,0} %multiply.6485), metadata={op_type="aten__add" op_name="aten__add.294/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6487 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.6486), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6488 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6487), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.6414 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6380), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.6415 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6414), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.6416 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6415), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.6417 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6416), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.6443 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.6417), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6442 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6441), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6444 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6442), metadata={op_type="aten__mul" op_name="aten__mul.295/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6445 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6444), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.295/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6446 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.6443, f32[1,8,310,128]{3,2,1,0} %broadcast.6445), metadata={op_type="aten__mul" op_name="aten__mul.295/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6447 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6446), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6419 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6417), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6420 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.6419), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6418 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6417), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6421 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.6420, bf16[1,8,310,64]{3,2,1,0} %slice.6418), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6422 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.6421), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6413 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6412), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6423 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6413), metadata={op_type="aten__mul" op_name="aten__mul.296/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6424 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6423), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.296/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6425 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.6422, f32[1,8,310,128]{3,2,1,0} %broadcast.6424), metadata={op_type="aten__mul" op_name="aten__mul.296/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6426 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6425), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.6397 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6448 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.6397), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.297/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6449 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.6426, bf16[1,8,310,128]{3,2,1,0} %broadcast.6448), metadata={op_type="aten__add" op_name="aten__add.297/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.6450 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.6447, bf16[1,8,310,128]{3,2,1,0} %multiply.6449), metadata={op_type="aten__add" op_name="aten__add.297/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6451 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.6450), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6452 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6451), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6453 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6452), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6454 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6453), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6455 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6454), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6456 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6455), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6457 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6456), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6458 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6457), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6459 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6458), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.6460 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6459), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6461 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.6460), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6462 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.6461), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.6489 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.6488, bf16[32,128,310]{2,1,0} %reshape.6462), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6490 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.6489), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6491 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.6492 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.6490, bf16[1,32,310,310]{3,2,1,0} %broadcast.6491), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.6396 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6493 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.6396), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.298/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.6494 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.6493), metadata={op_type="aten__add" op_name="aten__add.298/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.6495 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.6494), metadata={op_type="aten__add" op_name="aten__add.298/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6496 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.6495), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.298/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.6497 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.6492, bf16[1,32,310,310]{3,2,1,0} %broadcast.6496), metadata={op_type="aten__add" op_name="aten__add.298/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.6498 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.6497), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6499 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6504 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.6498, f32[] %constant.6499), dimensions={3}, to_apply=%MaxComputation.6500, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6505 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6504), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.6506 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.6498, f32[1,32,310,310]{3,2,1,0} %broadcast.6505), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.6507 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.6506), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6508 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6513 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.6507, f32[] %constant.6508), dimensions={3}, to_apply=%AddComputation.6509, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6514 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6513), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.6515 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.6507, f32[1,32,310,310]{3,2,1,0} %broadcast.6514), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.6516 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.6515), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.6517 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.6516), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6518 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.6517), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.6381 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6380), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.6382 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6381), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.6383 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6382), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.6384 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6383), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.6385 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6384), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6386 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6385), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6387 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6386), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6388 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6387), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6389 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6388), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6390 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6389), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6391 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6390), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6392 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6391), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6393 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6392), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.6394 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.6393), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6395 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6394), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.6519 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.6518, bf16[32,310,128]{2,1,0} %reshape.6395), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6520 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.6519), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.6521 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6520), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.6522 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.6521), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.6523 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.6522), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p115.411 = bf16[4096,4096]{1,0} parameter(115), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.412 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p115.411), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6524 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.6523, bf16[4096,4096]{0,1} %transpose.412), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6525 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6524), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.410 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.6526 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.410), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.299/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.6527 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6525, bf16[1,310,4096]{2,1,0} %broadcast.6526), metadata={op_type="aten__add" op_name="aten__add.299/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.6528 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6341, bf16[1,310,4096]{2,1,0} %multiply.6527), metadata={op_type="aten__add" op_name="aten__add.299/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p513.6559 = bf16[4096]{0} parameter(513), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6560 = f32[4096]{0} convert(bf16[4096]{0} %p513.6559), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6561 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6560), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.302/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6529 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6528), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.409 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6530 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.409), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6531 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6529, f32[1,310,4096]{2,1,0} %broadcast.6530), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6532 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6538 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6531, f32[] %constant.6532), dimensions={2}, to_apply=%AddComputation.6534, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6533 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6539 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6544 = pred[] compare(s32[] %constant.6533, s32[] %constant.6539), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6540 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6542 = f32[] convert(s32[] %constant.6533), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6543 = f32[] divide(f32[] %constant.6540, f32[] %convert.6542), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6541 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6545 = f32[] select(pred[] %compare.6544, f32[] %divide.6543, f32[] %constant.6541), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6546 = f32[1,310]{1,0} broadcast(f32[] %select.6545), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6547 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6538, f32[1,310]{1,0} %broadcast.6546), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6548 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6547), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6549 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6548), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.408 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6550 = f32[] multiply(f32[] %p4.23, f32[] %constant.408), metadata={op_type="aten__add" op_name="aten__add.300/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6551 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6550), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.300/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6552 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6549, f32[1,310,1]{2,1,0} %broadcast.6551), metadata={op_type="aten__add" op_name="aten__add.300/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6553 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6552), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6554 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6553), metadata={op_type="aten__mul" op_name="aten__mul.301/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6555 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6554), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.301/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6556 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6529, f32[1,310,4096]{2,1,0} %broadcast.6555), metadata={op_type="aten__mul" op_name="aten__mul.301/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6557 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6556), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6558 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6557), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6562 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6561, f32[1,310,4096]{2,1,0} %convert.6558), metadata={op_type="aten__mul" op_name="aten__mul.302/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6563 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6562), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6570 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6563), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p514.6568 = bf16[14336,4096]{1,0} parameter(514), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.6569 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p514.6568), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6571 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6570, bf16[4096,14336]{0,1} %transpose.6569), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6572 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6571), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.6573 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.6572), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.6574 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.6572, bf16[1,310,14336]{2,1,0} %logistic.6573), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.6575 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.6574), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6564 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6563), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p114.406 = bf16[14336,4096]{1,0} parameter(114), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.407 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p114.406), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6565 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6564, bf16[4096,14336]{0,1} %transpose.407), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6566 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6565), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.6567 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.6566), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.6576 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.6575, f32[1,310,14336]{2,1,0} %convert.6567), metadata={op_type="aten__mul" op_name="aten__mul.303/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.6577 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.6576), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6578 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.6577), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p113.404 = bf16[4096,14336]{1,0} parameter(113), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.405 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p113.404), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6579 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.6578, bf16[14336,4096]{0,1} %transpose.405), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6580 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6579), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.403 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.6581 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.403), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.304/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.6582 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6580, bf16[1,310,4096]{2,1,0} %broadcast.6581), metadata={op_type="aten__add" op_name="aten__add.304/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.6583 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6528, bf16[1,310,4096]{2,1,0} %multiply.6582), metadata={op_type="aten__add" op_name="aten__add.304/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p515.6614 = bf16[4096]{0} parameter(515), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6615 = f32[4096]{0} convert(bf16[4096]{0} %p515.6614), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6616 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6615), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.307/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6584 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6583), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.402 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6585 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.402), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6586 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6584, f32[1,310,4096]{2,1,0} %broadcast.6585), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6587 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6593 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6586, f32[] %constant.6587), dimensions={2}, to_apply=%AddComputation.6589, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6588 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6594 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6599 = pred[] compare(s32[] %constant.6588, s32[] %constant.6594), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6595 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6597 = f32[] convert(s32[] %constant.6588), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6598 = f32[] divide(f32[] %constant.6595, f32[] %convert.6597), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6596 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6600 = f32[] select(pred[] %compare.6599, f32[] %divide.6598, f32[] %constant.6596), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6601 = f32[1,310]{1,0} broadcast(f32[] %select.6600), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6602 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6593, f32[1,310]{1,0} %broadcast.6601), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6603 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6602), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6604 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6603), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.401 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6605 = f32[] multiply(f32[] %p4.23, f32[] %constant.401), metadata={op_type="aten__add" op_name="aten__add.305/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6606 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6605), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.305/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6607 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6604, f32[1,310,1]{2,1,0} %broadcast.6606), metadata={op_type="aten__add" op_name="aten__add.305/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6608 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6607), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6609 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6608), metadata={op_type="aten__mul" op_name="aten__mul.306/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6610 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6609), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.306/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6611 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6584, f32[1,310,4096]{2,1,0} %broadcast.6610), metadata={op_type="aten__mul" op_name="aten__mul.306/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6612 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6611), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6613 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6612), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6617 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6616, f32[1,310,4096]{2,1,0} %convert.6613), metadata={op_type="aten__mul" op_name="aten__mul.307/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6618 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6617), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6619 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6618), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p112.399 = bf16[6144,4096]{1,0} parameter(112), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.400 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p112.399), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6620 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.6619, bf16[4096,6144]{0,1} %transpose.400), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6621 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.6620), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6622 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.6621), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.6707 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6622), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.6708 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6707), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.6709 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6708), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.6710 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.6709), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.6721 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.6710), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p517.6680 = bf16[32768,128]{1,0} parameter(517), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.6681 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p517.6680), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.6674 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6675 = s64[1,310]{1,0} broadcast(s64[] %constant.6674), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.6676 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6675), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6669 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6670 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6669), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6671 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6670), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6672 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6671), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.6673 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6672), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.6677 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6676, s64[1,310]{1,0} %add.6673, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6678 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6677), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.6679 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6678), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.6682 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6681, s64[1,310,1]{2,1,0} %concatenate.6679), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6683 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6682), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.6720 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6683), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6722 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6720), metadata={op_type="aten__mul" op_name="aten__mul.308/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6723 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6722), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.308/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6724 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.6721, f32[1,32,310,128]{3,2,1,0} %broadcast.6723), metadata={op_type="aten__mul" op_name="aten__mul.308/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6725 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6724), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.6712 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6710), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6713 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.6712), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6711 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6710), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6714 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.6713, bf16[1,32,310,64]{3,2,1,0} %slice.6711), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6715 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.6714), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p516.6651 = bf16[32768,128]{1,0} parameter(516), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.6652 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p516.6651), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.6645 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6646 = s64[1,310]{1,0} broadcast(s64[] %constant.6645), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.6647 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6646), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6640 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6641 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6640), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6642 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6641), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6643 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6642), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.6644 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6643), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.6648 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6647, s64[1,310]{1,0} %add.6644, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6649 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6648), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.6650 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6649), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.6653 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6652, s64[1,310,1]{2,1,0} %concatenate.6650), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6654 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6653), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.6706 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6654), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6716 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6706), metadata={op_type="aten__mul" op_name="aten__mul.309/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6717 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6716), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.309/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6718 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.6715, f32[1,32,310,128]{3,2,1,0} %broadcast.6717), metadata={op_type="aten__mul" op_name="aten__mul.309/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6719 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6718), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.6705 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6726 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.6705), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.310/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6727 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.6719, bf16[1,32,310,128]{3,2,1,0} %broadcast.6726), metadata={op_type="aten__add" op_name="aten__add.310/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.6728 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.6725, bf16[1,32,310,128]{3,2,1,0} %multiply.6727), metadata={op_type="aten__add" op_name="aten__add.310/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6729 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.6728), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6730 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6729), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.6656 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6622), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.6657 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6656), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.6658 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6657), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.6659 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6658), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.6685 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.6659), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6684 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6683), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6686 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6684), metadata={op_type="aten__mul" op_name="aten__mul.311/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6687 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6686), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.311/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6688 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.6685, f32[1,8,310,128]{3,2,1,0} %broadcast.6687), metadata={op_type="aten__mul" op_name="aten__mul.311/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6689 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6688), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6661 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6659), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6662 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.6661), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6660 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6659), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6663 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.6662, bf16[1,8,310,64]{3,2,1,0} %slice.6660), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6664 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.6663), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6655 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6654), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6665 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6655), metadata={op_type="aten__mul" op_name="aten__mul.312/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6666 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6665), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.312/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6667 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.6664, f32[1,8,310,128]{3,2,1,0} %broadcast.6666), metadata={op_type="aten__mul" op_name="aten__mul.312/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6668 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6667), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.6639 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6690 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.6639), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.313/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6691 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.6668, bf16[1,8,310,128]{3,2,1,0} %broadcast.6690), metadata={op_type="aten__add" op_name="aten__add.313/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.6692 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.6689, bf16[1,8,310,128]{3,2,1,0} %multiply.6691), metadata={op_type="aten__add" op_name="aten__add.313/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6693 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.6692), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6694 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6693), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6695 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6694), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6696 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6695), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6697 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6696), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6698 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6697), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6699 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6698), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6700 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6699), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6701 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6700), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.6702 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6701), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6703 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.6702), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6704 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.6703), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.6731 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.6730, bf16[32,128,310]{2,1,0} %reshape.6704), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6732 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.6731), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6733 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.6734 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.6732, bf16[1,32,310,310]{3,2,1,0} %broadcast.6733), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.6638 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6735 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.6638), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.314/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.6736 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.6735), metadata={op_type="aten__add" op_name="aten__add.314/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.6737 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.6736), metadata={op_type="aten__add" op_name="aten__add.314/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6738 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.6737), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.314/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.6739 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.6734, bf16[1,32,310,310]{3,2,1,0} %broadcast.6738), metadata={op_type="aten__add" op_name="aten__add.314/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.6740 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.6739), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6741 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6746 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.6740, f32[] %constant.6741), dimensions={3}, to_apply=%MaxComputation.6742, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6747 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6746), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.6748 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.6740, f32[1,32,310,310]{3,2,1,0} %broadcast.6747), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.6749 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.6748), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6750 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6755 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.6749, f32[] %constant.6750), dimensions={3}, to_apply=%AddComputation.6751, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6756 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6755), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.6757 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.6749, f32[1,32,310,310]{3,2,1,0} %broadcast.6756), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.6758 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.6757), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.6759 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.6758), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6760 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.6759), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.6623 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6622), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.6624 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6623), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.6625 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6624), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.6626 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6625), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.6627 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6626), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6628 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6627), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6629 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6628), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6630 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6629), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6631 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6630), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6632 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6631), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6633 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6632), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6634 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6633), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6635 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6634), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.6636 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.6635), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6637 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6636), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.6761 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.6760, bf16[32,310,128]{2,1,0} %reshape.6637), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6762 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.6761), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.6763 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6762), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.6764 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.6763), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.6765 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.6764), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p111.397 = bf16[4096,4096]{1,0} parameter(111), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.398 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p111.397), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6766 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.6765, bf16[4096,4096]{0,1} %transpose.398), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6767 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6766), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.396 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.6768 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.396), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.315/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.6769 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6767, bf16[1,310,4096]{2,1,0} %broadcast.6768), metadata={op_type="aten__add" op_name="aten__add.315/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.6770 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6583, bf16[1,310,4096]{2,1,0} %multiply.6769), metadata={op_type="aten__add" op_name="aten__add.315/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p518.6801 = bf16[4096]{0} parameter(518), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6802 = f32[4096]{0} convert(bf16[4096]{0} %p518.6801), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6803 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6802), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.318/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6771 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6770), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.395 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6772 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.395), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6773 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6771, f32[1,310,4096]{2,1,0} %broadcast.6772), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6774 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6780 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6773, f32[] %constant.6774), dimensions={2}, to_apply=%AddComputation.6776, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6775 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6781 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6786 = pred[] compare(s32[] %constant.6775, s32[] %constant.6781), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6782 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6784 = f32[] convert(s32[] %constant.6775), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6785 = f32[] divide(f32[] %constant.6782, f32[] %convert.6784), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6783 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6787 = f32[] select(pred[] %compare.6786, f32[] %divide.6785, f32[] %constant.6783), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6788 = f32[1,310]{1,0} broadcast(f32[] %select.6787), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6789 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6780, f32[1,310]{1,0} %broadcast.6788), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6790 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6789), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6791 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6790), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.394 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6792 = f32[] multiply(f32[] %p4.23, f32[] %constant.394), metadata={op_type="aten__add" op_name="aten__add.316/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6793 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6792), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.316/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6794 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6791, f32[1,310,1]{2,1,0} %broadcast.6793), metadata={op_type="aten__add" op_name="aten__add.316/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6795 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6794), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6796 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6795), metadata={op_type="aten__mul" op_name="aten__mul.317/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6797 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6796), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.317/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6798 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6771, f32[1,310,4096]{2,1,0} %broadcast.6797), metadata={op_type="aten__mul" op_name="aten__mul.317/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6799 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6798), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6800 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6799), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6804 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6803, f32[1,310,4096]{2,1,0} %convert.6800), metadata={op_type="aten__mul" op_name="aten__mul.318/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6805 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6804), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6812 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6805), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p519.6810 = bf16[14336,4096]{1,0} parameter(519), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.6811 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p519.6810), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6813 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6812, bf16[4096,14336]{0,1} %transpose.6811), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6814 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6813), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.6815 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.6814), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.6816 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.6814, bf16[1,310,14336]{2,1,0} %logistic.6815), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.6817 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.6816), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6806 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6805), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p110.392 = bf16[14336,4096]{1,0} parameter(110), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.393 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p110.392), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6807 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.6806, bf16[4096,14336]{0,1} %transpose.393), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6808 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.6807), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.6809 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.6808), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.6818 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.6817, f32[1,310,14336]{2,1,0} %convert.6809), metadata={op_type="aten__mul" op_name="aten__mul.319/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.6819 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.6818), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.6820 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.6819), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p109.390 = bf16[4096,14336]{1,0} parameter(109), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.391 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p109.390), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6821 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.6820, bf16[14336,4096]{0,1} %transpose.391), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6822 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.6821), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.389 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.6823 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.389), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.320/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.6824 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.6822, bf16[1,310,4096]{2,1,0} %broadcast.6823), metadata={op_type="aten__add" op_name="aten__add.320/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.6825 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6770, bf16[1,310,4096]{2,1,0} %multiply.6824), metadata={op_type="aten__add" op_name="aten__add.320/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p520.6856 = bf16[4096]{0} parameter(520), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.6857 = f32[4096]{0} convert(bf16[4096]{0} %p520.6856), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.6858 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.6857), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.323/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6826 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.6825), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.388 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6827 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.388), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.6828 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.6826, f32[1,310,4096]{2,1,0} %broadcast.6827), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6829 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.6835 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.6828, f32[] %constant.6829), dimensions={2}, to_apply=%AddComputation.6831, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6830 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6836 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.6841 = pred[] compare(s32[] %constant.6830, s32[] %constant.6836), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6837 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6839 = f32[] convert(s32[] %constant.6830), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.6840 = f32[] divide(f32[] %constant.6837, f32[] %convert.6839), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.6838 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.6842 = f32[] select(pred[] %compare.6841, f32[] %divide.6840, f32[] %constant.6838), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.6843 = f32[1,310]{1,0} broadcast(f32[] %select.6842), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.6844 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.6835, f32[1,310]{1,0} %broadcast.6843), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.6845 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.6844), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.6846 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.6845), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.387 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6847 = f32[] multiply(f32[] %p4.23, f32[] %constant.387), metadata={op_type="aten__add" op_name="aten__add.321/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6848 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.6847), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.321/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.6849 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.6846, f32[1,310,1]{2,1,0} %broadcast.6848), metadata={op_type="aten__add" op_name="aten__add.321/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.6850 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.6849), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.6851 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.6850), metadata={op_type="aten__mul" op_name="aten__mul.322/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.6852 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.6851), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.322/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.6853 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.6826, f32[1,310,4096]{2,1,0} %broadcast.6852), metadata={op_type="aten__mul" op_name="aten__mul.322/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.6854 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6853), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6855 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.6854), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.6859 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.6858, f32[1,310,4096]{2,1,0} %convert.6855), metadata={op_type="aten__mul" op_name="aten__mul.323/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.6860 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.6859), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.6861 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.6860), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p108.385 = bf16[6144,4096]{1,0} parameter(108), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.386 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p108.385), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.6862 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.6861, bf16[4096,6144]{0,1} %transpose.386), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6863 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.6862), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.6864 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.6863), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.6949 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6864), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.6950 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6949), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.6951 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.6950), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.6952 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.6951), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.6963 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.6952), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p522.6922 = bf16[32768,128]{1,0} parameter(522), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.6923 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p522.6922), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.6916 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6917 = s64[1,310]{1,0} broadcast(s64[] %constant.6916), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.6918 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6917), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6911 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6912 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6911), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6913 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6912), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.6914 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6913), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.6915 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6914), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.6919 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6918, s64[1,310]{1,0} %add.6915, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6920 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6919), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.6921 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6920), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.6924 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6923, s64[1,310,1]{2,1,0} %concatenate.6921), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.6925 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6924), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.6962 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6925), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6964 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6962), metadata={op_type="aten__mul" op_name="aten__mul.324/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6965 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6964), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.324/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6966 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.6963, f32[1,32,310,128]{3,2,1,0} %broadcast.6965), metadata={op_type="aten__mul" op_name="aten__mul.324/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6967 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6966), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.6954 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6952), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6955 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.6954), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6953 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.6952), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6956 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.6955, bf16[1,32,310,64]{3,2,1,0} %slice.6953), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6957 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.6956), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p521.6893 = bf16[32768,128]{1,0} parameter(521), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.6894 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p521.6893), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.6887 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6888 = s64[1,310]{1,0} broadcast(s64[] %constant.6887), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.6889 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6888), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6882 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6883 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.6882), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6884 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.6883), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.6885 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.6884), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.6886 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.6885), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.6890 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.6889, s64[1,310]{1,0} %add.6886, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6891 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.6890), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.6892 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.6891), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.6895 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.6894, s64[1,310,1]{2,1,0} %concatenate.6892), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.6896 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.6895), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.6948 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6896), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.6958 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6948), metadata={op_type="aten__mul" op_name="aten__mul.325/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6959 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6958), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.325/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6960 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.6957, f32[1,32,310,128]{3,2,1,0} %broadcast.6959), metadata={op_type="aten__mul" op_name="aten__mul.325/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.6961 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.6960), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.6947 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6968 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.6947), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.326/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.6969 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.6961, bf16[1,32,310,128]{3,2,1,0} %broadcast.6968), metadata={op_type="aten__add" op_name="aten__add.326/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.6970 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.6967, bf16[1,32,310,128]{3,2,1,0} %multiply.6969), metadata={op_type="aten__add" op_name="aten__add.326/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.6971 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.6970), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6972 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6971), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.6898 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6864), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.6899 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6898), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.6900 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6899), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.6901 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6900), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.6927 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.6901), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6926 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6925), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6928 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6926), metadata={op_type="aten__mul" op_name="aten__mul.327/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6929 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6928), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.327/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6930 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.6927, f32[1,8,310,128]{3,2,1,0} %broadcast.6929), metadata={op_type="aten__mul" op_name="aten__mul.327/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6931 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6930), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6903 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6901), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.6904 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.6903), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.6902 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6901), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.6905 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.6904, bf16[1,8,310,64]{3,2,1,0} %slice.6902), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.6906 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.6905), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6897 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.6896), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.6907 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.6897), metadata={op_type="aten__mul" op_name="aten__mul.328/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6908 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.6907), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.328/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6909 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.6906, f32[1,8,310,128]{3,2,1,0} %broadcast.6908), metadata={op_type="aten__mul" op_name="aten__mul.328/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.6910 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.6909), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.6881 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.6932 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.6881), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.329/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.6933 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.6910, bf16[1,8,310,128]{3,2,1,0} %broadcast.6932), metadata={op_type="aten__add" op_name="aten__add.329/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.6934 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.6931, bf16[1,8,310,128]{3,2,1,0} %multiply.6933), metadata={op_type="aten__add" op_name="aten__add.329/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.6935 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.6934), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6936 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6935), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6937 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6936), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6938 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6937), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6939 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6938), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6940 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6939), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6941 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6940), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6942 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6941), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6943 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6942), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.6944 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.6943), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6945 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.6944), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6946 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.6945), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.6973 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.6972, bf16[32,128,310]{2,1,0} %reshape.6946), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.6974 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.6973), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.6975 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.6976 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.6974, bf16[1,32,310,310]{3,2,1,0} %broadcast.6975), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.6880 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6977 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.6880), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.330/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.6978 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.6977), metadata={op_type="aten__add" op_name="aten__add.330/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.6979 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.6978), metadata={op_type="aten__add" op_name="aten__add.330/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.6980 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.6979), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.330/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.6981 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.6976, bf16[1,32,310,310]{3,2,1,0} %broadcast.6980), metadata={op_type="aten__add" op_name="aten__add.330/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.6982 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.6981), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6983 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6988 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.6982, f32[] %constant.6983), dimensions={3}, to_apply=%MaxComputation.6984, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6989 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6988), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.6990 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.6982, f32[1,32,310,310]{3,2,1,0} %broadcast.6989), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.6991 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.6990), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.6992 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.6997 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.6991, f32[] %constant.6992), dimensions={3}, to_apply=%AddComputation.6993, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.6998 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.6997), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.6999 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.6991, f32[1,32,310,310]{3,2,1,0} %broadcast.6998), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.7000 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.6999), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.7001 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.7000), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7002 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.7001), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.6865 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.6864), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.6866 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.6865), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.6867 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.6866), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.6868 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.6867), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.6869 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.6868), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6870 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.6869), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6871 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.6870), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6872 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.6871), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.6873 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6872), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6874 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.6873), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6875 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.6874), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.6876 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.6875), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.6877 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.6876), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.6878 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.6877), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.6879 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.6878), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.7003 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.7002, bf16[32,310,128]{2,1,0} %reshape.6879), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7004 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.7003), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.7005 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7004), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.7006 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.7005), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.7007 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.7006), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p107.383 = bf16[4096,4096]{1,0} parameter(107), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.384 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p107.383), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7008 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.7007, bf16[4096,4096]{0,1} %transpose.384), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7009 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7008), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.382 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.7010 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.382), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.331/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.7011 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7009, bf16[1,310,4096]{2,1,0} %broadcast.7010), metadata={op_type="aten__add" op_name="aten__add.331/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.7012 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.6825, bf16[1,310,4096]{2,1,0} %multiply.7011), metadata={op_type="aten__add" op_name="aten__add.331/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p523.7043 = bf16[4096]{0} parameter(523), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7044 = f32[4096]{0} convert(bf16[4096]{0} %p523.7043), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7045 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7044), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.334/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7013 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7012), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.381 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7014 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.381), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7015 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7013, f32[1,310,4096]{2,1,0} %broadcast.7014), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7016 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7022 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7015, f32[] %constant.7016), dimensions={2}, to_apply=%AddComputation.7018, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7017 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7023 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7028 = pred[] compare(s32[] %constant.7017, s32[] %constant.7023), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7024 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7026 = f32[] convert(s32[] %constant.7017), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7027 = f32[] divide(f32[] %constant.7024, f32[] %convert.7026), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7025 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7029 = f32[] select(pred[] %compare.7028, f32[] %divide.7027, f32[] %constant.7025), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7030 = f32[1,310]{1,0} broadcast(f32[] %select.7029), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7031 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7022, f32[1,310]{1,0} %broadcast.7030), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7032 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7031), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7033 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7032), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.380 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7034 = f32[] multiply(f32[] %p4.23, f32[] %constant.380), metadata={op_type="aten__add" op_name="aten__add.332/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7035 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7034), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.332/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7036 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7033, f32[1,310,1]{2,1,0} %broadcast.7035), metadata={op_type="aten__add" op_name="aten__add.332/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7037 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7036), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7038 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7037), metadata={op_type="aten__mul" op_name="aten__mul.333/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7039 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7038), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.333/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7040 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7013, f32[1,310,4096]{2,1,0} %broadcast.7039), metadata={op_type="aten__mul" op_name="aten__mul.333/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7041 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7040), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7042 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7041), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7046 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7045, f32[1,310,4096]{2,1,0} %convert.7042), metadata={op_type="aten__mul" op_name="aten__mul.334/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7047 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7046), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7054 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7047), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p524.7052 = bf16[14336,4096]{1,0} parameter(524), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.7053 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p524.7052), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7055 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7054, bf16[4096,14336]{0,1} %transpose.7053), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7056 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7055), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.7057 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.7056), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.7058 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.7056, bf16[1,310,14336]{2,1,0} %logistic.7057), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.7059 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.7058), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7048 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7047), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p106.378 = bf16[14336,4096]{1,0} parameter(106), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.379 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p106.378), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7049 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7048, bf16[4096,14336]{0,1} %transpose.379), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7050 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7049), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.7051 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.7050), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.7060 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.7059, f32[1,310,14336]{2,1,0} %convert.7051), metadata={op_type="aten__mul" op_name="aten__mul.335/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.7061 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.7060), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7062 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.7061), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p105.376 = bf16[4096,14336]{1,0} parameter(105), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.377 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p105.376), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7063 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.7062, bf16[14336,4096]{0,1} %transpose.377), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7064 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7063), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.375 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.7065 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.375), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.336/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.7066 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7064, bf16[1,310,4096]{2,1,0} %broadcast.7065), metadata={op_type="aten__add" op_name="aten__add.336/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.7067 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7012, bf16[1,310,4096]{2,1,0} %multiply.7066), metadata={op_type="aten__add" op_name="aten__add.336/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p525.7098 = bf16[4096]{0} parameter(525), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7099 = f32[4096]{0} convert(bf16[4096]{0} %p525.7098), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7100 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7099), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.339/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7068 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7067), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.374 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7069 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.374), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7070 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7068, f32[1,310,4096]{2,1,0} %broadcast.7069), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7071 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7077 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7070, f32[] %constant.7071), dimensions={2}, to_apply=%AddComputation.7073, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7072 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7078 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7083 = pred[] compare(s32[] %constant.7072, s32[] %constant.7078), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7079 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7081 = f32[] convert(s32[] %constant.7072), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7082 = f32[] divide(f32[] %constant.7079, f32[] %convert.7081), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7080 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7084 = f32[] select(pred[] %compare.7083, f32[] %divide.7082, f32[] %constant.7080), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7085 = f32[1,310]{1,0} broadcast(f32[] %select.7084), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7086 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7077, f32[1,310]{1,0} %broadcast.7085), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7087 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7086), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7088 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7087), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.373 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7089 = f32[] multiply(f32[] %p4.23, f32[] %constant.373), metadata={op_type="aten__add" op_name="aten__add.337/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7090 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7089), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.337/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7091 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7088, f32[1,310,1]{2,1,0} %broadcast.7090), metadata={op_type="aten__add" op_name="aten__add.337/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7092 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7091), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7093 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7092), metadata={op_type="aten__mul" op_name="aten__mul.338/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7094 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7093), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.338/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7095 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7068, f32[1,310,4096]{2,1,0} %broadcast.7094), metadata={op_type="aten__mul" op_name="aten__mul.338/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7096 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7095), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7097 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7096), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7101 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7100, f32[1,310,4096]{2,1,0} %convert.7097), metadata={op_type="aten__mul" op_name="aten__mul.339/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7102 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7101), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7103 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7102), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p104.371 = bf16[6144,4096]{1,0} parameter(104), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.372 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p104.371), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7104 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.7103, bf16[4096,6144]{0,1} %transpose.372), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7105 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.7104), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7106 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.7105), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.7191 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7106), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.7192 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7191), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.7193 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7192), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.7194 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.7193), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.7205 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.7194), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p527.7164 = bf16[32768,128]{1,0} parameter(527), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.7165 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p527.7164), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.7158 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7159 = s64[1,310]{1,0} broadcast(s64[] %constant.7158), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.7160 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7159), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7153 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7154 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7153), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7155 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7154), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7156 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7155), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.7157 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7156), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.7161 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7160, s64[1,310]{1,0} %add.7157, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7162 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7161), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.7163 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7162), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.7166 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7165, s64[1,310,1]{2,1,0} %concatenate.7163), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7167 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7166), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.7204 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7167), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7206 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7204), metadata={op_type="aten__mul" op_name="aten__mul.340/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7207 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7206), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.340/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7208 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.7205, f32[1,32,310,128]{3,2,1,0} %broadcast.7207), metadata={op_type="aten__mul" op_name="aten__mul.340/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7209 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7208), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.7196 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7194), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7197 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.7196), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7195 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7194), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7198 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.7197, bf16[1,32,310,64]{3,2,1,0} %slice.7195), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7199 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.7198), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p526.7135 = bf16[32768,128]{1,0} parameter(526), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.7136 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p526.7135), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.7129 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7130 = s64[1,310]{1,0} broadcast(s64[] %constant.7129), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.7131 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7130), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7124 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7125 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7124), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7126 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7125), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7127 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7126), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.7128 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7127), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.7132 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7131, s64[1,310]{1,0} %add.7128, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7133 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7132), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.7134 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7133), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.7137 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7136, s64[1,310,1]{2,1,0} %concatenate.7134), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7138 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7137), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.7190 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7138), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7200 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7190), metadata={op_type="aten__mul" op_name="aten__mul.341/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7201 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7200), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.341/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7202 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.7199, f32[1,32,310,128]{3,2,1,0} %broadcast.7201), metadata={op_type="aten__mul" op_name="aten__mul.341/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7203 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7202), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.7189 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7210 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.7189), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.342/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7211 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.7203, bf16[1,32,310,128]{3,2,1,0} %broadcast.7210), metadata={op_type="aten__add" op_name="aten__add.342/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.7212 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.7209, bf16[1,32,310,128]{3,2,1,0} %multiply.7211), metadata={op_type="aten__add" op_name="aten__add.342/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7213 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.7212), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7214 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7213), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.7140 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7106), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.7141 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7140), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.7142 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7141), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.7143 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7142), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.7169 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.7143), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7168 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7167), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7170 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7168), metadata={op_type="aten__mul" op_name="aten__mul.343/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7171 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7170), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.343/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7172 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.7169, f32[1,8,310,128]{3,2,1,0} %broadcast.7171), metadata={op_type="aten__mul" op_name="aten__mul.343/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7173 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7172), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7145 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7143), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7146 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.7145), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7144 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7143), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7147 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.7146, bf16[1,8,310,64]{3,2,1,0} %slice.7144), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7148 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.7147), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7139 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7138), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7149 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7139), metadata={op_type="aten__mul" op_name="aten__mul.344/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7150 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7149), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.344/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7151 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.7148, f32[1,8,310,128]{3,2,1,0} %broadcast.7150), metadata={op_type="aten__mul" op_name="aten__mul.344/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7152 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7151), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.7123 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7174 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.7123), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.345/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7175 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.7152, bf16[1,8,310,128]{3,2,1,0} %broadcast.7174), metadata={op_type="aten__add" op_name="aten__add.345/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.7176 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.7173, bf16[1,8,310,128]{3,2,1,0} %multiply.7175), metadata={op_type="aten__add" op_name="aten__add.345/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7177 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.7176), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7178 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7177), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7179 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7178), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7180 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7179), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7181 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7180), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7182 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7181), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7183 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7182), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7184 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7183), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7185 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7184), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.7186 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7185), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7187 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.7186), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7188 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.7187), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.7215 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.7214, bf16[32,128,310]{2,1,0} %reshape.7188), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7216 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.7215), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7217 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.7218 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.7216, bf16[1,32,310,310]{3,2,1,0} %broadcast.7217), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.7122 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7219 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.7122), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.346/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.7220 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.7219), metadata={op_type="aten__add" op_name="aten__add.346/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.7221 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.7220), metadata={op_type="aten__add" op_name="aten__add.346/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7222 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.7221), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.346/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.7223 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.7218, bf16[1,32,310,310]{3,2,1,0} %broadcast.7222), metadata={op_type="aten__add" op_name="aten__add.346/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.7224 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.7223), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7225 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7230 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.7224, f32[] %constant.7225), dimensions={3}, to_apply=%MaxComputation.7226, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7231 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7230), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.7232 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.7224, f32[1,32,310,310]{3,2,1,0} %broadcast.7231), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.7233 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.7232), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7234 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7239 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.7233, f32[] %constant.7234), dimensions={3}, to_apply=%AddComputation.7235, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7240 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7239), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.7241 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.7233, f32[1,32,310,310]{3,2,1,0} %broadcast.7240), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.7242 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.7241), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.7243 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.7242), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7244 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.7243), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.7107 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7106), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.7108 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7107), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.7109 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7108), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.7110 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7109), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.7111 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7110), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7112 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7111), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7113 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7112), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7114 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7113), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7115 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7114), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7116 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7115), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7117 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7116), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7118 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7117), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7119 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7118), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.7120 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.7119), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7121 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7120), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.7245 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.7244, bf16[32,310,128]{2,1,0} %reshape.7121), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7246 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.7245), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.7247 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7246), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.7248 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.7247), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.7249 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.7248), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p103.369 = bf16[4096,4096]{1,0} parameter(103), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.370 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p103.369), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7250 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.7249, bf16[4096,4096]{0,1} %transpose.370), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7251 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7250), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.368 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.7252 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.368), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.347/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.7253 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7251, bf16[1,310,4096]{2,1,0} %broadcast.7252), metadata={op_type="aten__add" op_name="aten__add.347/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.7254 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7067, bf16[1,310,4096]{2,1,0} %multiply.7253), metadata={op_type="aten__add" op_name="aten__add.347/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p528.7285 = bf16[4096]{0} parameter(528), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7286 = f32[4096]{0} convert(bf16[4096]{0} %p528.7285), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7287 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7286), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.350/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7255 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7254), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.367 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7256 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.367), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7257 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7255, f32[1,310,4096]{2,1,0} %broadcast.7256), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7258 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7264 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7257, f32[] %constant.7258), dimensions={2}, to_apply=%AddComputation.7260, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7259 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7265 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7270 = pred[] compare(s32[] %constant.7259, s32[] %constant.7265), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7266 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7268 = f32[] convert(s32[] %constant.7259), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7269 = f32[] divide(f32[] %constant.7266, f32[] %convert.7268), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7267 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7271 = f32[] select(pred[] %compare.7270, f32[] %divide.7269, f32[] %constant.7267), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7272 = f32[1,310]{1,0} broadcast(f32[] %select.7271), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7273 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7264, f32[1,310]{1,0} %broadcast.7272), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7274 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7273), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7275 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7274), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.366 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7276 = f32[] multiply(f32[] %p4.23, f32[] %constant.366), metadata={op_type="aten__add" op_name="aten__add.348/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7277 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7276), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.348/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7278 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7275, f32[1,310,1]{2,1,0} %broadcast.7277), metadata={op_type="aten__add" op_name="aten__add.348/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7279 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7278), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7280 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7279), metadata={op_type="aten__mul" op_name="aten__mul.349/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7281 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7280), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.349/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7282 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7255, f32[1,310,4096]{2,1,0} %broadcast.7281), metadata={op_type="aten__mul" op_name="aten__mul.349/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7283 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7282), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7284 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7283), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7288 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7287, f32[1,310,4096]{2,1,0} %convert.7284), metadata={op_type="aten__mul" op_name="aten__mul.350/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7289 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7288), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7296 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7289), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p529.7294 = bf16[14336,4096]{1,0} parameter(529), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.7295 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p529.7294), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7297 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7296, bf16[4096,14336]{0,1} %transpose.7295), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7298 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7297), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.7299 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.7298), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.7300 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.7298, bf16[1,310,14336]{2,1,0} %logistic.7299), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.7301 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.7300), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7290 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7289), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p102.364 = bf16[14336,4096]{1,0} parameter(102), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.365 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p102.364), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7291 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7290, bf16[4096,14336]{0,1} %transpose.365), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7292 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7291), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.7293 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.7292), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.7302 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.7301, f32[1,310,14336]{2,1,0} %convert.7293), metadata={op_type="aten__mul" op_name="aten__mul.351/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.7303 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.7302), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7304 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.7303), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p101.362 = bf16[4096,14336]{1,0} parameter(101), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.363 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p101.362), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7305 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.7304, bf16[14336,4096]{0,1} %transpose.363), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7306 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7305), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.361 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.7307 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.361), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.352/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.7308 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7306, bf16[1,310,4096]{2,1,0} %broadcast.7307), metadata={op_type="aten__add" op_name="aten__add.352/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.7309 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7254, bf16[1,310,4096]{2,1,0} %multiply.7308), metadata={op_type="aten__add" op_name="aten__add.352/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p530.7340 = bf16[4096]{0} parameter(530), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7341 = f32[4096]{0} convert(bf16[4096]{0} %p530.7340), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7342 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7341), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.355/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7310 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7309), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.360 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7311 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.360), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7312 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7310, f32[1,310,4096]{2,1,0} %broadcast.7311), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7313 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7319 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7312, f32[] %constant.7313), dimensions={2}, to_apply=%AddComputation.7315, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7314 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7320 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7325 = pred[] compare(s32[] %constant.7314, s32[] %constant.7320), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7321 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7323 = f32[] convert(s32[] %constant.7314), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7324 = f32[] divide(f32[] %constant.7321, f32[] %convert.7323), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7322 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7326 = f32[] select(pred[] %compare.7325, f32[] %divide.7324, f32[] %constant.7322), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7327 = f32[1,310]{1,0} broadcast(f32[] %select.7326), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7328 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7319, f32[1,310]{1,0} %broadcast.7327), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7329 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7328), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7330 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7329), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.359 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7331 = f32[] multiply(f32[] %p4.23, f32[] %constant.359), metadata={op_type="aten__add" op_name="aten__add.353/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7332 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7331), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.353/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7333 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7330, f32[1,310,1]{2,1,0} %broadcast.7332), metadata={op_type="aten__add" op_name="aten__add.353/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7334 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7333), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7335 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7334), metadata={op_type="aten__mul" op_name="aten__mul.354/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7336 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7335), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.354/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7337 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7310, f32[1,310,4096]{2,1,0} %broadcast.7336), metadata={op_type="aten__mul" op_name="aten__mul.354/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7338 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7337), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7339 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7338), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7343 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7342, f32[1,310,4096]{2,1,0} %convert.7339), metadata={op_type="aten__mul" op_name="aten__mul.355/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7344 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7343), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7345 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7344), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p100.357 = bf16[6144,4096]{1,0} parameter(100), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.358 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p100.357), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7346 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.7345, bf16[4096,6144]{0,1} %transpose.358), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7347 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.7346), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7348 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.7347), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.7433 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7348), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.7434 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7433), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.7435 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7434), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.7436 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.7435), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.7447 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.7436), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p532.7406 = bf16[32768,128]{1,0} parameter(532), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.7407 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p532.7406), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.7400 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7401 = s64[1,310]{1,0} broadcast(s64[] %constant.7400), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.7402 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7401), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7395 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7396 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7395), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7397 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7396), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7398 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7397), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.7399 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7398), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.7403 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7402, s64[1,310]{1,0} %add.7399, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7404 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7403), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.7405 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7404), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.7408 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7407, s64[1,310,1]{2,1,0} %concatenate.7405), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7409 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7408), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.7446 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7409), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7448 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7446), metadata={op_type="aten__mul" op_name="aten__mul.356/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7449 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7448), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.356/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7450 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.7447, f32[1,32,310,128]{3,2,1,0} %broadcast.7449), metadata={op_type="aten__mul" op_name="aten__mul.356/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7451 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7450), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.7438 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7436), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7439 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.7438), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7437 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7436), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7440 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.7439, bf16[1,32,310,64]{3,2,1,0} %slice.7437), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7441 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.7440), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p531.7377 = bf16[32768,128]{1,0} parameter(531), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.7378 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p531.7377), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.7371 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7372 = s64[1,310]{1,0} broadcast(s64[] %constant.7371), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.7373 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7372), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7366 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7367 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7366), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7368 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7367), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7369 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7368), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.7370 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7369), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.7374 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7373, s64[1,310]{1,0} %add.7370, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7375 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7374), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.7376 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7375), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.7379 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7378, s64[1,310,1]{2,1,0} %concatenate.7376), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7380 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7379), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.7432 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7380), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7442 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7432), metadata={op_type="aten__mul" op_name="aten__mul.357/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7443 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7442), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.357/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7444 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.7441, f32[1,32,310,128]{3,2,1,0} %broadcast.7443), metadata={op_type="aten__mul" op_name="aten__mul.357/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7445 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7444), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.7431 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7452 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.7431), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.358/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7453 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.7445, bf16[1,32,310,128]{3,2,1,0} %broadcast.7452), metadata={op_type="aten__add" op_name="aten__add.358/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.7454 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.7451, bf16[1,32,310,128]{3,2,1,0} %multiply.7453), metadata={op_type="aten__add" op_name="aten__add.358/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7455 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.7454), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7456 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7455), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.7382 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7348), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.7383 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7382), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.7384 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7383), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.7385 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7384), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.7411 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.7385), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7410 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7409), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7412 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7410), metadata={op_type="aten__mul" op_name="aten__mul.359/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7413 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7412), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.359/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7414 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.7411, f32[1,8,310,128]{3,2,1,0} %broadcast.7413), metadata={op_type="aten__mul" op_name="aten__mul.359/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7415 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7414), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7387 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7385), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7388 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.7387), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7386 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7385), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7389 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.7388, bf16[1,8,310,64]{3,2,1,0} %slice.7386), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7390 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.7389), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7381 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7380), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7391 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7381), metadata={op_type="aten__mul" op_name="aten__mul.360/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7392 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7391), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.360/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7393 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.7390, f32[1,8,310,128]{3,2,1,0} %broadcast.7392), metadata={op_type="aten__mul" op_name="aten__mul.360/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7394 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7393), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.7365 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7416 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.7365), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.361/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7417 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.7394, bf16[1,8,310,128]{3,2,1,0} %broadcast.7416), metadata={op_type="aten__add" op_name="aten__add.361/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.7418 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.7415, bf16[1,8,310,128]{3,2,1,0} %multiply.7417), metadata={op_type="aten__add" op_name="aten__add.361/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7419 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.7418), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7420 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7419), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7421 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7420), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7422 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7421), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7423 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7422), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7424 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7423), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7425 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7424), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7426 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7425), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7427 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7426), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.7428 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7427), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7429 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.7428), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7430 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.7429), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.7457 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.7456, bf16[32,128,310]{2,1,0} %reshape.7430), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7458 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.7457), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7459 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.7460 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.7458, bf16[1,32,310,310]{3,2,1,0} %broadcast.7459), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.7364 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7461 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.7364), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.362/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.7462 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.7461), metadata={op_type="aten__add" op_name="aten__add.362/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.7463 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.7462), metadata={op_type="aten__add" op_name="aten__add.362/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7464 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.7463), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.362/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.7465 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.7460, bf16[1,32,310,310]{3,2,1,0} %broadcast.7464), metadata={op_type="aten__add" op_name="aten__add.362/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.7466 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.7465), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7467 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7472 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.7466, f32[] %constant.7467), dimensions={3}, to_apply=%MaxComputation.7468, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7473 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7472), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.7474 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.7466, f32[1,32,310,310]{3,2,1,0} %broadcast.7473), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.7475 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.7474), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7476 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7481 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.7475, f32[] %constant.7476), dimensions={3}, to_apply=%AddComputation.7477, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7482 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7481), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.7483 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.7475, f32[1,32,310,310]{3,2,1,0} %broadcast.7482), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.7484 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.7483), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.7485 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.7484), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7486 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.7485), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.7349 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7348), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.7350 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7349), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.7351 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7350), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.7352 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7351), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.7353 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7352), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7354 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7353), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7355 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7354), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7356 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7355), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7357 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7356), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7358 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7357), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7359 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7358), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7360 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7359), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7361 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7360), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.7362 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.7361), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7363 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7362), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.7487 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.7486, bf16[32,310,128]{2,1,0} %reshape.7363), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7488 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.7487), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.7489 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7488), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.7490 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.7489), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.7491 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.7490), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p99.355 = bf16[4096,4096]{1,0} parameter(99), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.356 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p99.355), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7492 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.7491, bf16[4096,4096]{0,1} %transpose.356), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7493 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7492), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.354 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.7494 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.354), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.363/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.7495 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7493, bf16[1,310,4096]{2,1,0} %broadcast.7494), metadata={op_type="aten__add" op_name="aten__add.363/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.7496 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7309, bf16[1,310,4096]{2,1,0} %multiply.7495), metadata={op_type="aten__add" op_name="aten__add.363/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p533.7527 = bf16[4096]{0} parameter(533), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7528 = f32[4096]{0} convert(bf16[4096]{0} %p533.7527), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7529 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7528), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.366/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7497 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7496), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.353 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7498 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.353), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7499 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7497, f32[1,310,4096]{2,1,0} %broadcast.7498), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7500 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7506 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7499, f32[] %constant.7500), dimensions={2}, to_apply=%AddComputation.7502, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7501 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7507 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7512 = pred[] compare(s32[] %constant.7501, s32[] %constant.7507), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7508 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7510 = f32[] convert(s32[] %constant.7501), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7511 = f32[] divide(f32[] %constant.7508, f32[] %convert.7510), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7509 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7513 = f32[] select(pred[] %compare.7512, f32[] %divide.7511, f32[] %constant.7509), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7514 = f32[1,310]{1,0} broadcast(f32[] %select.7513), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7515 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7506, f32[1,310]{1,0} %broadcast.7514), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7516 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7515), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7517 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7516), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.352 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7518 = f32[] multiply(f32[] %p4.23, f32[] %constant.352), metadata={op_type="aten__add" op_name="aten__add.364/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7519 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7518), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.364/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7520 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7517, f32[1,310,1]{2,1,0} %broadcast.7519), metadata={op_type="aten__add" op_name="aten__add.364/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7521 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7520), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7522 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7521), metadata={op_type="aten__mul" op_name="aten__mul.365/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7523 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7522), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.365/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7524 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7497, f32[1,310,4096]{2,1,0} %broadcast.7523), metadata={op_type="aten__mul" op_name="aten__mul.365/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7525 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7524), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7526 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7525), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7530 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7529, f32[1,310,4096]{2,1,0} %convert.7526), metadata={op_type="aten__mul" op_name="aten__mul.366/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7531 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7530), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7538 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7531), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p534.7536 = bf16[14336,4096]{1,0} parameter(534), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.7537 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p534.7536), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7539 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7538, bf16[4096,14336]{0,1} %transpose.7537), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7540 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7539), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.7541 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.7540), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.7542 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.7540, bf16[1,310,14336]{2,1,0} %logistic.7541), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.7543 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.7542), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7532 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7531), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p98.350 = bf16[14336,4096]{1,0} parameter(98), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.351 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p98.350), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7533 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7532, bf16[4096,14336]{0,1} %transpose.351), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7534 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7533), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.7535 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.7534), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.7544 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.7543, f32[1,310,14336]{2,1,0} %convert.7535), metadata={op_type="aten__mul" op_name="aten__mul.367/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.7545 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.7544), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7546 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.7545), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p97.348 = bf16[4096,14336]{1,0} parameter(97), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.349 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p97.348), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7547 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.7546, bf16[14336,4096]{0,1} %transpose.349), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7548 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7547), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.347 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.7549 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.347), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.368/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.7550 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7548, bf16[1,310,4096]{2,1,0} %broadcast.7549), metadata={op_type="aten__add" op_name="aten__add.368/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.7551 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7496, bf16[1,310,4096]{2,1,0} %multiply.7550), metadata={op_type="aten__add" op_name="aten__add.368/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p535.7582 = bf16[4096]{0} parameter(535), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7583 = f32[4096]{0} convert(bf16[4096]{0} %p535.7582), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7584 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7583), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.371/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7552 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7551), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.346 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7553 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.346), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7554 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7552, f32[1,310,4096]{2,1,0} %broadcast.7553), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7555 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7561 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7554, f32[] %constant.7555), dimensions={2}, to_apply=%AddComputation.7557, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7556 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7562 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7567 = pred[] compare(s32[] %constant.7556, s32[] %constant.7562), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7563 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7565 = f32[] convert(s32[] %constant.7556), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7566 = f32[] divide(f32[] %constant.7563, f32[] %convert.7565), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7564 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7568 = f32[] select(pred[] %compare.7567, f32[] %divide.7566, f32[] %constant.7564), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7569 = f32[1,310]{1,0} broadcast(f32[] %select.7568), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7570 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7561, f32[1,310]{1,0} %broadcast.7569), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7571 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7570), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7572 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7571), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.345 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7573 = f32[] multiply(f32[] %p4.23, f32[] %constant.345), metadata={op_type="aten__add" op_name="aten__add.369/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7574 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7573), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.369/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7575 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7572, f32[1,310,1]{2,1,0} %broadcast.7574), metadata={op_type="aten__add" op_name="aten__add.369/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7576 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7575), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7577 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7576), metadata={op_type="aten__mul" op_name="aten__mul.370/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7578 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7577), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.370/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7579 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7552, f32[1,310,4096]{2,1,0} %broadcast.7578), metadata={op_type="aten__mul" op_name="aten__mul.370/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7580 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7579), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7581 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7580), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7585 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7584, f32[1,310,4096]{2,1,0} %convert.7581), metadata={op_type="aten__mul" op_name="aten__mul.371/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7586 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7585), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7587 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7586), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p96.343 = bf16[6144,4096]{1,0} parameter(96), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.344 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p96.343), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7588 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.7587, bf16[4096,6144]{0,1} %transpose.344), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7589 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.7588), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7590 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.7589), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.7675 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7590), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.7676 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7675), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.7677 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7676), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.7678 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.7677), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.7689 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.7678), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p537.7648 = bf16[32768,128]{1,0} parameter(537), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.7649 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p537.7648), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.7642 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7643 = s64[1,310]{1,0} broadcast(s64[] %constant.7642), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.7644 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7643), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7637 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7638 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7637), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7639 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7638), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7640 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7639), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.7641 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7640), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.7645 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7644, s64[1,310]{1,0} %add.7641, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7646 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7645), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.7647 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7646), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.7650 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7649, s64[1,310,1]{2,1,0} %concatenate.7647), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7651 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7650), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.7688 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7651), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7690 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7688), metadata={op_type="aten__mul" op_name="aten__mul.372/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7691 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7690), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.372/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7692 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.7689, f32[1,32,310,128]{3,2,1,0} %broadcast.7691), metadata={op_type="aten__mul" op_name="aten__mul.372/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7693 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7692), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.7680 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7678), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7681 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.7680), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7679 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7678), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7682 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.7681, bf16[1,32,310,64]{3,2,1,0} %slice.7679), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7683 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.7682), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p536.7619 = bf16[32768,128]{1,0} parameter(536), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.7620 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p536.7619), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.7613 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7614 = s64[1,310]{1,0} broadcast(s64[] %constant.7613), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.7615 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7614), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7608 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7609 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7608), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7610 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7609), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7611 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7610), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.7612 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7611), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.7616 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7615, s64[1,310]{1,0} %add.7612, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7617 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7616), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.7618 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7617), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.7621 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7620, s64[1,310,1]{2,1,0} %concatenate.7618), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7622 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7621), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.7674 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7622), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7684 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7674), metadata={op_type="aten__mul" op_name="aten__mul.373/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7685 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7684), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.373/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7686 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.7683, f32[1,32,310,128]{3,2,1,0} %broadcast.7685), metadata={op_type="aten__mul" op_name="aten__mul.373/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7687 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7686), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.7673 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7694 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.7673), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.374/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7695 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.7687, bf16[1,32,310,128]{3,2,1,0} %broadcast.7694), metadata={op_type="aten__add" op_name="aten__add.374/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.7696 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.7693, bf16[1,32,310,128]{3,2,1,0} %multiply.7695), metadata={op_type="aten__add" op_name="aten__add.374/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7697 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.7696), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7698 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7697), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.7624 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7590), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.7625 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7624), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.7626 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7625), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.7627 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7626), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.7653 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.7627), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7652 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7651), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7654 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7652), metadata={op_type="aten__mul" op_name="aten__mul.375/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7655 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7654), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.375/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7656 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.7653, f32[1,8,310,128]{3,2,1,0} %broadcast.7655), metadata={op_type="aten__mul" op_name="aten__mul.375/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7657 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7656), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7629 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7627), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7630 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.7629), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7628 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7627), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7631 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.7630, bf16[1,8,310,64]{3,2,1,0} %slice.7628), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7632 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.7631), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7623 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7622), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7633 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7623), metadata={op_type="aten__mul" op_name="aten__mul.376/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7634 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7633), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.376/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7635 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.7632, f32[1,8,310,128]{3,2,1,0} %broadcast.7634), metadata={op_type="aten__mul" op_name="aten__mul.376/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7636 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7635), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.7607 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7658 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.7607), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.377/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7659 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.7636, bf16[1,8,310,128]{3,2,1,0} %broadcast.7658), metadata={op_type="aten__add" op_name="aten__add.377/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.7660 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.7657, bf16[1,8,310,128]{3,2,1,0} %multiply.7659), metadata={op_type="aten__add" op_name="aten__add.377/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7661 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.7660), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7662 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7661), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7663 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7662), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7664 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7663), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7665 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7664), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7666 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7665), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7667 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7666), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7668 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7667), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7669 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7668), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.7670 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7669), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7671 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.7670), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7672 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.7671), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.7699 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.7698, bf16[32,128,310]{2,1,0} %reshape.7672), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7700 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.7699), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7701 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.7702 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.7700, bf16[1,32,310,310]{3,2,1,0} %broadcast.7701), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.7606 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7703 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.7606), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.378/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.7704 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.7703), metadata={op_type="aten__add" op_name="aten__add.378/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.7705 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.7704), metadata={op_type="aten__add" op_name="aten__add.378/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7706 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.7705), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.378/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.7707 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.7702, bf16[1,32,310,310]{3,2,1,0} %broadcast.7706), metadata={op_type="aten__add" op_name="aten__add.378/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.7708 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.7707), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7709 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7714 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.7708, f32[] %constant.7709), dimensions={3}, to_apply=%MaxComputation.7710, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7715 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7714), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.7716 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.7708, f32[1,32,310,310]{3,2,1,0} %broadcast.7715), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.7717 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.7716), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7718 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7723 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.7717, f32[] %constant.7718), dimensions={3}, to_apply=%AddComputation.7719, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7724 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7723), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.7725 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.7717, f32[1,32,310,310]{3,2,1,0} %broadcast.7724), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.7726 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.7725), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.7727 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.7726), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7728 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.7727), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.7591 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7590), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.7592 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7591), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.7593 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7592), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.7594 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7593), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.7595 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7594), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7596 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7595), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7597 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7596), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7598 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7597), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7599 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7598), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7600 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7599), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7601 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7600), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7602 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7601), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7603 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7602), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.7604 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.7603), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7605 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7604), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.7729 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.7728, bf16[32,310,128]{2,1,0} %reshape.7605), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7730 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.7729), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.7731 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7730), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.7732 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.7731), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.7733 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.7732), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p95.341 = bf16[4096,4096]{1,0} parameter(95), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.342 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p95.341), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7734 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.7733, bf16[4096,4096]{0,1} %transpose.342), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7735 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7734), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.340 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.7736 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.340), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.379/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.7737 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7735, bf16[1,310,4096]{2,1,0} %broadcast.7736), metadata={op_type="aten__add" op_name="aten__add.379/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.7738 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7551, bf16[1,310,4096]{2,1,0} %multiply.7737), metadata={op_type="aten__add" op_name="aten__add.379/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p538.7769 = bf16[4096]{0} parameter(538), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7770 = f32[4096]{0} convert(bf16[4096]{0} %p538.7769), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7771 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7770), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.382/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7739 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7738), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.339 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7740 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.339), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7741 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7739, f32[1,310,4096]{2,1,0} %broadcast.7740), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7742 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7748 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7741, f32[] %constant.7742), dimensions={2}, to_apply=%AddComputation.7744, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7743 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7749 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7754 = pred[] compare(s32[] %constant.7743, s32[] %constant.7749), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7750 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7752 = f32[] convert(s32[] %constant.7743), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7753 = f32[] divide(f32[] %constant.7750, f32[] %convert.7752), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7751 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7755 = f32[] select(pred[] %compare.7754, f32[] %divide.7753, f32[] %constant.7751), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7756 = f32[1,310]{1,0} broadcast(f32[] %select.7755), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7757 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7748, f32[1,310]{1,0} %broadcast.7756), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7758 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7757), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7759 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7758), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.338 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7760 = f32[] multiply(f32[] %p4.23, f32[] %constant.338), metadata={op_type="aten__add" op_name="aten__add.380/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7761 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7760), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.380/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7762 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7759, f32[1,310,1]{2,1,0} %broadcast.7761), metadata={op_type="aten__add" op_name="aten__add.380/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7763 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7762), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7764 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7763), metadata={op_type="aten__mul" op_name="aten__mul.381/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7765 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7764), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.381/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7766 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7739, f32[1,310,4096]{2,1,0} %broadcast.7765), metadata={op_type="aten__mul" op_name="aten__mul.381/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7767 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7766), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7768 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7767), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7772 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7771, f32[1,310,4096]{2,1,0} %convert.7768), metadata={op_type="aten__mul" op_name="aten__mul.382/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7773 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7772), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7780 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7773), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p539.7778 = bf16[14336,4096]{1,0} parameter(539), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.7779 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p539.7778), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7781 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7780, bf16[4096,14336]{0,1} %transpose.7779), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7782 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7781), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.7783 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.7782), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.7784 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.7782, bf16[1,310,14336]{2,1,0} %logistic.7783), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.7785 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.7784), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7774 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7773), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p94.336 = bf16[14336,4096]{1,0} parameter(94), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.337 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p94.336), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7775 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.7774, bf16[4096,14336]{0,1} %transpose.337), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7776 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.7775), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.7777 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.7776), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.7786 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.7785, f32[1,310,14336]{2,1,0} %convert.7777), metadata={op_type="aten__mul" op_name="aten__mul.383/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.7787 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.7786), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.7788 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.7787), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p93.334 = bf16[4096,14336]{1,0} parameter(93), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.335 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p93.334), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7789 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.7788, bf16[14336,4096]{0,1} %transpose.335), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7790 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7789), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.333 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.7791 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.333), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.384/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.7792 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7790, bf16[1,310,4096]{2,1,0} %broadcast.7791), metadata={op_type="aten__add" op_name="aten__add.384/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.7793 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7738, bf16[1,310,4096]{2,1,0} %multiply.7792), metadata={op_type="aten__add" op_name="aten__add.384/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p540.7824 = bf16[4096]{0} parameter(540), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.7825 = f32[4096]{0} convert(bf16[4096]{0} %p540.7824), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.7826 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.7825), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.387/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7794 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7793), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.332 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7795 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.332), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7796 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7794, f32[1,310,4096]{2,1,0} %broadcast.7795), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7797 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7803 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7796, f32[] %constant.7797), dimensions={2}, to_apply=%AddComputation.7799, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7798 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7804 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7809 = pred[] compare(s32[] %constant.7798, s32[] %constant.7804), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7805 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7807 = f32[] convert(s32[] %constant.7798), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7808 = f32[] divide(f32[] %constant.7805, f32[] %convert.7807), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7806 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7810 = f32[] select(pred[] %compare.7809, f32[] %divide.7808, f32[] %constant.7806), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7811 = f32[1,310]{1,0} broadcast(f32[] %select.7810), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7812 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7803, f32[1,310]{1,0} %broadcast.7811), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.7813 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7812), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7814 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.7813), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.331 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7815 = f32[] multiply(f32[] %p4.23, f32[] %constant.331), metadata={op_type="aten__add" op_name="aten__add.385/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7816 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.7815), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.385/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.7817 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.7814, f32[1,310,1]{2,1,0} %broadcast.7816), metadata={op_type="aten__add" op_name="aten__add.385/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.7818 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.7817), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.7819 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.7818), metadata={op_type="aten__mul" op_name="aten__mul.386/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.7820 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.7819), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.386/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.7821 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7794, f32[1,310,4096]{2,1,0} %broadcast.7820), metadata={op_type="aten__mul" op_name="aten__mul.386/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.7822 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7821), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7823 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.7822), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.7827 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.7826, f32[1,310,4096]{2,1,0} %convert.7823), metadata={op_type="aten__mul" op_name="aten__mul.387/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7828 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.7827), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.7829 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.7828), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p92.329 = bf16[6144,4096]{1,0} parameter(92), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.330 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p92.329), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7830 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.7829, bf16[4096,6144]{0,1} %transpose.330), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7831 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.7830), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7832 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.7831), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.7917 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7832), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.7918 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7917), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.7919 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.7918), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.7920 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.7919), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.7931 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.7920), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p542.7890 = bf16[32768,128]{1,0} parameter(542), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.7891 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p542.7890), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.7884 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7885 = s64[1,310]{1,0} broadcast(s64[] %constant.7884), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.7886 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7885), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7879 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7880 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7879), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7881 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7880), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.7882 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7881), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.7883 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7882), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.7887 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7886, s64[1,310]{1,0} %add.7883, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7888 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7887), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.7889 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7888), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.7892 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7891, s64[1,310,1]{2,1,0} %concatenate.7889), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.7893 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7892), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.7930 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7893), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7932 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7930), metadata={op_type="aten__mul" op_name="aten__mul.388/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7933 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7932), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.388/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7934 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.7931, f32[1,32,310,128]{3,2,1,0} %broadcast.7933), metadata={op_type="aten__mul" op_name="aten__mul.388/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7935 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7934), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.7922 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7920), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7923 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.7922), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7921 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.7920), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7924 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.7923, bf16[1,32,310,64]{3,2,1,0} %slice.7921), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7925 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.7924), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p541.7861 = bf16[32768,128]{1,0} parameter(541), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.7862 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p541.7861), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.7855 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7856 = s64[1,310]{1,0} broadcast(s64[] %constant.7855), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.7857 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7856), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7850 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7851 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.7850), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7852 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.7851), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.7853 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.7852), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.7854 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.7853), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.7858 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.7857, s64[1,310]{1,0} %add.7854, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7859 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.7858), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.7860 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.7859), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.7863 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.7862, s64[1,310,1]{2,1,0} %concatenate.7860), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.7864 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.7863), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.7916 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7864), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.7926 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7916), metadata={op_type="aten__mul" op_name="aten__mul.389/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7927 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7926), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.389/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7928 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.7925, f32[1,32,310,128]{3,2,1,0} %broadcast.7927), metadata={op_type="aten__mul" op_name="aten__mul.389/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.7929 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.7928), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.7915 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7936 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.7915), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.390/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.7937 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.7929, bf16[1,32,310,128]{3,2,1,0} %broadcast.7936), metadata={op_type="aten__add" op_name="aten__add.390/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.7938 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.7935, bf16[1,32,310,128]{3,2,1,0} %multiply.7937), metadata={op_type="aten__add" op_name="aten__add.390/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.7939 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.7938), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7940 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7939), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.7866 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7832), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.7867 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7866), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.7868 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7867), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.7869 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7868), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.7895 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.7869), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7894 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7893), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7896 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7894), metadata={op_type="aten__mul" op_name="aten__mul.391/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7897 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7896), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.391/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7898 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.7895, f32[1,8,310,128]{3,2,1,0} %broadcast.7897), metadata={op_type="aten__mul" op_name="aten__mul.391/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7899 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7898), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7871 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7869), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.7872 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.7871), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.7870 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7869), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.7873 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.7872, bf16[1,8,310,64]{3,2,1,0} %slice.7870), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.7874 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.7873), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7865 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.7864), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.7875 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.7865), metadata={op_type="aten__mul" op_name="aten__mul.392/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7876 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.7875), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.392/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7877 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.7874, f32[1,8,310,128]{3,2,1,0} %broadcast.7876), metadata={op_type="aten__mul" op_name="aten__mul.392/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.7878 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.7877), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.7849 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.7900 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.7849), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.393/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.7901 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.7878, bf16[1,8,310,128]{3,2,1,0} %broadcast.7900), metadata={op_type="aten__add" op_name="aten__add.393/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.7902 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.7899, bf16[1,8,310,128]{3,2,1,0} %multiply.7901), metadata={op_type="aten__add" op_name="aten__add.393/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.7903 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.7902), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7904 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7903), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7905 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7904), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7906 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7905), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7907 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7906), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7908 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7907), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7909 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7908), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7910 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7909), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7911 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7910), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.7912 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7911), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7913 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.7912), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7914 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.7913), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.7941 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.7940, bf16[32,128,310]{2,1,0} %reshape.7914), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.7942 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.7941), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.7943 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.7944 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.7942, bf16[1,32,310,310]{3,2,1,0} %broadcast.7943), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.7848 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7945 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.7848), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.394/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.7946 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.7945), metadata={op_type="aten__add" op_name="aten__add.394/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.7947 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.7946), metadata={op_type="aten__add" op_name="aten__add.394/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.7948 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.7947), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.394/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.7949 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.7944, bf16[1,32,310,310]{3,2,1,0} %broadcast.7948), metadata={op_type="aten__add" op_name="aten__add.394/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.7950 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.7949), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7951 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7956 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.7950, f32[] %constant.7951), dimensions={3}, to_apply=%MaxComputation.7952, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7957 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7956), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.7958 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.7950, f32[1,32,310,310]{3,2,1,0} %broadcast.7957), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.7959 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.7958), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.7960 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.7965 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.7959, f32[] %constant.7960), dimensions={3}, to_apply=%AddComputation.7961, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.7966 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.7965), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.7967 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.7959, f32[1,32,310,310]{3,2,1,0} %broadcast.7966), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.7968 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.7967), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.7969 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.7968), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7970 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.7969), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.7833 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.7832), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.7834 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.7833), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.7835 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.7834), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.7836 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.7835), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.7837 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.7836), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7838 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.7837), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7839 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.7838), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7840 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.7839), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.7841 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7840), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7842 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.7841), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7843 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.7842), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.7844 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.7843), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.7845 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.7844), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.7846 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.7845), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7847 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.7846), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.7971 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.7970, bf16[32,310,128]{2,1,0} %reshape.7847), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.7972 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.7971), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.7973 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.7972), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.7974 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.7973), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.7975 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.7974), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p91.327 = bf16[4096,4096]{1,0} parameter(91), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.328 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p91.327), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.7976 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.7975, bf16[4096,4096]{0,1} %transpose.328), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.7977 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.7976), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.326 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.7978 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.326), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.395/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.7979 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.7977, bf16[1,310,4096]{2,1,0} %broadcast.7978), metadata={op_type="aten__add" op_name="aten__add.395/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.7980 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7793, bf16[1,310,4096]{2,1,0} %multiply.7979), metadata={op_type="aten__add" op_name="aten__add.395/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p543.8011 = bf16[4096]{0} parameter(543), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8012 = f32[4096]{0} convert(bf16[4096]{0} %p543.8011), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8013 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8012), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.398/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.7981 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.7980), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.325 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7982 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.325), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.7983 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.7981, f32[1,310,4096]{2,1,0} %broadcast.7982), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7984 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.7990 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.7983, f32[] %constant.7984), dimensions={2}, to_apply=%AddComputation.7986, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7985 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7991 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.7996 = pred[] compare(s32[] %constant.7985, s32[] %constant.7991), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7992 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.7994 = f32[] convert(s32[] %constant.7985), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.7995 = f32[] divide(f32[] %constant.7992, f32[] %convert.7994), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.7993 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.7997 = f32[] select(pred[] %compare.7996, f32[] %divide.7995, f32[] %constant.7993), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.7998 = f32[1,310]{1,0} broadcast(f32[] %select.7997), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.7999 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.7990, f32[1,310]{1,0} %broadcast.7998), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8000 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.7999), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8001 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8000), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.324 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8002 = f32[] multiply(f32[] %p4.23, f32[] %constant.324), metadata={op_type="aten__add" op_name="aten__add.396/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8003 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8002), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.396/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8004 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8001, f32[1,310,1]{2,1,0} %broadcast.8003), metadata={op_type="aten__add" op_name="aten__add.396/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8005 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8004), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8006 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8005), metadata={op_type="aten__mul" op_name="aten__mul.397/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8007 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8006), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.397/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8008 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.7981, f32[1,310,4096]{2,1,0} %broadcast.8007), metadata={op_type="aten__mul" op_name="aten__mul.397/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8009 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8008), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8010 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8009), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8014 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8013, f32[1,310,4096]{2,1,0} %convert.8010), metadata={op_type="aten__mul" op_name="aten__mul.398/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8015 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8014), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8022 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8015), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p544.8020 = bf16[14336,4096]{1,0} parameter(544), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.8021 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p544.8020), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8023 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8022, bf16[4096,14336]{0,1} %transpose.8021), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8024 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8023), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.8025 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.8024), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.8026 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.8024, bf16[1,310,14336]{2,1,0} %logistic.8025), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.8027 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.8026), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8016 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8015), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p90.322 = bf16[14336,4096]{1,0} parameter(90), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.323 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p90.322), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8017 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8016, bf16[4096,14336]{0,1} %transpose.323), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8018 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8017), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.8019 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.8018), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.8028 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.8027, f32[1,310,14336]{2,1,0} %convert.8019), metadata={op_type="aten__mul" op_name="aten__mul.399/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.8029 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.8028), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8030 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.8029), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p89.320 = bf16[4096,14336]{1,0} parameter(89), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.321 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p89.320), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8031 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.8030, bf16[14336,4096]{0,1} %transpose.321), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8032 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8031), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.319 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.8033 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.319), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.400/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.8034 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8032, bf16[1,310,4096]{2,1,0} %broadcast.8033), metadata={op_type="aten__add" op_name="aten__add.400/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.8035 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.7980, bf16[1,310,4096]{2,1,0} %multiply.8034), metadata={op_type="aten__add" op_name="aten__add.400/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p545.8066 = bf16[4096]{0} parameter(545), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8067 = f32[4096]{0} convert(bf16[4096]{0} %p545.8066), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8068 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8067), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.403/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8036 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8035), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.318 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8037 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.318), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8038 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8036, f32[1,310,4096]{2,1,0} %broadcast.8037), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8039 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8045 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8038, f32[] %constant.8039), dimensions={2}, to_apply=%AddComputation.8041, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8040 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8046 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8051 = pred[] compare(s32[] %constant.8040, s32[] %constant.8046), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8047 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8049 = f32[] convert(s32[] %constant.8040), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8050 = f32[] divide(f32[] %constant.8047, f32[] %convert.8049), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8048 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8052 = f32[] select(pred[] %compare.8051, f32[] %divide.8050, f32[] %constant.8048), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8053 = f32[1,310]{1,0} broadcast(f32[] %select.8052), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8054 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8045, f32[1,310]{1,0} %broadcast.8053), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8055 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8054), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8056 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8055), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.317 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8057 = f32[] multiply(f32[] %p4.23, f32[] %constant.317), metadata={op_type="aten__add" op_name="aten__add.401/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8058 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8057), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.401/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8059 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8056, f32[1,310,1]{2,1,0} %broadcast.8058), metadata={op_type="aten__add" op_name="aten__add.401/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8060 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8059), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8061 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8060), metadata={op_type="aten__mul" op_name="aten__mul.402/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8062 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8061), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.402/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8063 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8036, f32[1,310,4096]{2,1,0} %broadcast.8062), metadata={op_type="aten__mul" op_name="aten__mul.402/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8064 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8063), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8065 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8064), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8069 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8068, f32[1,310,4096]{2,1,0} %convert.8065), metadata={op_type="aten__mul" op_name="aten__mul.403/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8070 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8069), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8071 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8070), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p88.315 = bf16[6144,4096]{1,0} parameter(88), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.316 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p88.315), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8072 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.8071, bf16[4096,6144]{0,1} %transpose.316), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8073 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.8072), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8074 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.8073), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.8159 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8074), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.8160 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8159), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.8161 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8160), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.8162 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.8161), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.8173 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.8162), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p547.8132 = bf16[32768,128]{1,0} parameter(547), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.8133 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p547.8132), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.8126 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8127 = s64[1,310]{1,0} broadcast(s64[] %constant.8126), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.8128 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8127), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8121 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8122 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8121), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8123 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8122), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8124 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8123), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.8125 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8124), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.8129 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8128, s64[1,310]{1,0} %add.8125, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8130 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8129), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.8131 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8130), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.8134 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8133, s64[1,310,1]{2,1,0} %concatenate.8131), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8135 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8134), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.8172 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8135), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8174 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8172), metadata={op_type="aten__mul" op_name="aten__mul.404/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8175 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8174), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.404/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8176 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.8173, f32[1,32,310,128]{3,2,1,0} %broadcast.8175), metadata={op_type="aten__mul" op_name="aten__mul.404/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8177 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8176), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.8164 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8162), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8165 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.8164), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8163 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8162), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8166 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.8165, bf16[1,32,310,64]{3,2,1,0} %slice.8163), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8167 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.8166), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p546.8103 = bf16[32768,128]{1,0} parameter(546), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.8104 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p546.8103), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.8097 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8098 = s64[1,310]{1,0} broadcast(s64[] %constant.8097), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.8099 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8098), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8092 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8093 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8092), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8094 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8093), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8095 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8094), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.8096 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8095), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.8100 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8099, s64[1,310]{1,0} %add.8096, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8101 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8100), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.8102 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8101), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.8105 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8104, s64[1,310,1]{2,1,0} %concatenate.8102), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8106 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8105), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.8158 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8106), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8168 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8158), metadata={op_type="aten__mul" op_name="aten__mul.405/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8169 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8168), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.405/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8170 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.8167, f32[1,32,310,128]{3,2,1,0} %broadcast.8169), metadata={op_type="aten__mul" op_name="aten__mul.405/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8171 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8170), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.8157 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8178 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.8157), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.406/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8179 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.8171, bf16[1,32,310,128]{3,2,1,0} %broadcast.8178), metadata={op_type="aten__add" op_name="aten__add.406/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.8180 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.8177, bf16[1,32,310,128]{3,2,1,0} %multiply.8179), metadata={op_type="aten__add" op_name="aten__add.406/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8181 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.8180), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8182 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8181), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.8108 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8074), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.8109 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8108), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.8110 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8109), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.8111 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8110), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.8137 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.8111), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8136 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8135), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8138 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8136), metadata={op_type="aten__mul" op_name="aten__mul.407/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8139 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8138), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.407/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8140 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.8137, f32[1,8,310,128]{3,2,1,0} %broadcast.8139), metadata={op_type="aten__mul" op_name="aten__mul.407/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8141 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8140), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8113 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8111), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8114 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.8113), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8112 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8111), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8115 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.8114, bf16[1,8,310,64]{3,2,1,0} %slice.8112), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8116 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.8115), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8107 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8106), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8117 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8107), metadata={op_type="aten__mul" op_name="aten__mul.408/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8118 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8117), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.408/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8119 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.8116, f32[1,8,310,128]{3,2,1,0} %broadcast.8118), metadata={op_type="aten__mul" op_name="aten__mul.408/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8120 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8119), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.8091 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8142 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.8091), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.409/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8143 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.8120, bf16[1,8,310,128]{3,2,1,0} %broadcast.8142), metadata={op_type="aten__add" op_name="aten__add.409/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.8144 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.8141, bf16[1,8,310,128]{3,2,1,0} %multiply.8143), metadata={op_type="aten__add" op_name="aten__add.409/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8145 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.8144), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8146 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8145), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8147 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8146), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8148 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8147), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8149 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8148), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8150 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8149), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8151 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8150), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8152 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8151), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8153 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8152), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.8154 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8153), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8155 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.8154), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8156 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.8155), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.8183 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.8182, bf16[32,128,310]{2,1,0} %reshape.8156), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8184 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.8183), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8185 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.8186 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.8184, bf16[1,32,310,310]{3,2,1,0} %broadcast.8185), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.8090 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8187 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.8090), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.410/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.8188 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.8187), metadata={op_type="aten__add" op_name="aten__add.410/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.8189 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.8188), metadata={op_type="aten__add" op_name="aten__add.410/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8190 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.8189), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.410/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.8191 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.8186, bf16[1,32,310,310]{3,2,1,0} %broadcast.8190), metadata={op_type="aten__add" op_name="aten__add.410/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.8192 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.8191), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8193 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8198 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.8192, f32[] %constant.8193), dimensions={3}, to_apply=%MaxComputation.8194, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8199 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8198), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.8200 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.8192, f32[1,32,310,310]{3,2,1,0} %broadcast.8199), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.8201 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.8200), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8202 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8207 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.8201, f32[] %constant.8202), dimensions={3}, to_apply=%AddComputation.8203, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8208 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8207), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.8209 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.8201, f32[1,32,310,310]{3,2,1,0} %broadcast.8208), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.8210 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.8209), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.8211 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.8210), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8212 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.8211), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.8075 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8074), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.8076 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8075), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.8077 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8076), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.8078 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8077), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.8079 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8078), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8080 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8079), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8081 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8080), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8082 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8081), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8083 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8082), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8084 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8083), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8085 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8084), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8086 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8085), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8087 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8086), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.8088 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.8087), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8089 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8088), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.8213 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.8212, bf16[32,310,128]{2,1,0} %reshape.8089), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8214 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.8213), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.8215 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8214), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.8216 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.8215), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.8217 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.8216), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p87.313 = bf16[4096,4096]{1,0} parameter(87), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.314 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p87.313), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8218 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.8217, bf16[4096,4096]{0,1} %transpose.314), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8219 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8218), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.312 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.8220 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.312), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.411/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.8221 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8219, bf16[1,310,4096]{2,1,0} %broadcast.8220), metadata={op_type="aten__add" op_name="aten__add.411/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.8222 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8035, bf16[1,310,4096]{2,1,0} %multiply.8221), metadata={op_type="aten__add" op_name="aten__add.411/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p548.8253 = bf16[4096]{0} parameter(548), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8254 = f32[4096]{0} convert(bf16[4096]{0} %p548.8253), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8255 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8254), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.414/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8223 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8222), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.311 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8224 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.311), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8225 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8223, f32[1,310,4096]{2,1,0} %broadcast.8224), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8226 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8232 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8225, f32[] %constant.8226), dimensions={2}, to_apply=%AddComputation.8228, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8227 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8233 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8238 = pred[] compare(s32[] %constant.8227, s32[] %constant.8233), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8234 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8236 = f32[] convert(s32[] %constant.8227), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8237 = f32[] divide(f32[] %constant.8234, f32[] %convert.8236), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8235 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8239 = f32[] select(pred[] %compare.8238, f32[] %divide.8237, f32[] %constant.8235), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8240 = f32[1,310]{1,0} broadcast(f32[] %select.8239), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8241 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8232, f32[1,310]{1,0} %broadcast.8240), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8242 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8241), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8243 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8242), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.310 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8244 = f32[] multiply(f32[] %p4.23, f32[] %constant.310), metadata={op_type="aten__add" op_name="aten__add.412/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8245 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8244), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.412/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8246 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8243, f32[1,310,1]{2,1,0} %broadcast.8245), metadata={op_type="aten__add" op_name="aten__add.412/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8247 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8246), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8248 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8247), metadata={op_type="aten__mul" op_name="aten__mul.413/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8249 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8248), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.413/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8250 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8223, f32[1,310,4096]{2,1,0} %broadcast.8249), metadata={op_type="aten__mul" op_name="aten__mul.413/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8251 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8250), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8252 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8251), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8256 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8255, f32[1,310,4096]{2,1,0} %convert.8252), metadata={op_type="aten__mul" op_name="aten__mul.414/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8257 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8256), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8264 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8257), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p549.8262 = bf16[14336,4096]{1,0} parameter(549), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.8263 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p549.8262), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8265 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8264, bf16[4096,14336]{0,1} %transpose.8263), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8266 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8265), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.8267 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.8266), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.8268 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.8266, bf16[1,310,14336]{2,1,0} %logistic.8267), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.8269 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.8268), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8258 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8257), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p86.308 = bf16[14336,4096]{1,0} parameter(86), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.309 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p86.308), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8259 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8258, bf16[4096,14336]{0,1} %transpose.309), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8260 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8259), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.8261 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.8260), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.8270 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.8269, f32[1,310,14336]{2,1,0} %convert.8261), metadata={op_type="aten__mul" op_name="aten__mul.415/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.8271 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.8270), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8272 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.8271), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p85.306 = bf16[4096,14336]{1,0} parameter(85), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.307 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p85.306), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8273 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.8272, bf16[14336,4096]{0,1} %transpose.307), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8274 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8273), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.305 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.8275 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.305), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.416/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.8276 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8274, bf16[1,310,4096]{2,1,0} %broadcast.8275), metadata={op_type="aten__add" op_name="aten__add.416/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.8277 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8222, bf16[1,310,4096]{2,1,0} %multiply.8276), metadata={op_type="aten__add" op_name="aten__add.416/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p550.8308 = bf16[4096]{0} parameter(550), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8309 = f32[4096]{0} convert(bf16[4096]{0} %p550.8308), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8310 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8309), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.419/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8278 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8277), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.304 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8279 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.304), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8280 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8278, f32[1,310,4096]{2,1,0} %broadcast.8279), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8281 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8287 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8280, f32[] %constant.8281), dimensions={2}, to_apply=%AddComputation.8283, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8282 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8288 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8293 = pred[] compare(s32[] %constant.8282, s32[] %constant.8288), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8289 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8291 = f32[] convert(s32[] %constant.8282), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8292 = f32[] divide(f32[] %constant.8289, f32[] %convert.8291), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8290 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8294 = f32[] select(pred[] %compare.8293, f32[] %divide.8292, f32[] %constant.8290), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8295 = f32[1,310]{1,0} broadcast(f32[] %select.8294), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8296 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8287, f32[1,310]{1,0} %broadcast.8295), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8297 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8296), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8298 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8297), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.303 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8299 = f32[] multiply(f32[] %p4.23, f32[] %constant.303), metadata={op_type="aten__add" op_name="aten__add.417/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8300 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8299), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.417/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8301 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8298, f32[1,310,1]{2,1,0} %broadcast.8300), metadata={op_type="aten__add" op_name="aten__add.417/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8302 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8301), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8303 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8302), metadata={op_type="aten__mul" op_name="aten__mul.418/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8304 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8303), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.418/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8305 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8278, f32[1,310,4096]{2,1,0} %broadcast.8304), metadata={op_type="aten__mul" op_name="aten__mul.418/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8306 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8305), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8307 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8306), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8311 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8310, f32[1,310,4096]{2,1,0} %convert.8307), metadata={op_type="aten__mul" op_name="aten__mul.419/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8312 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8311), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8313 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8312), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p84.301 = bf16[6144,4096]{1,0} parameter(84), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.302 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p84.301), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8314 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.8313, bf16[4096,6144]{0,1} %transpose.302), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8315 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.8314), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8316 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.8315), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.8401 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8316), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.8402 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8401), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.8403 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8402), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.8404 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.8403), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.8415 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.8404), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p552.8374 = bf16[32768,128]{1,0} parameter(552), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.8375 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p552.8374), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.8368 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8369 = s64[1,310]{1,0} broadcast(s64[] %constant.8368), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.8370 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8369), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8363 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8364 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8363), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8365 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8364), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8366 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8365), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.8367 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8366), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.8371 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8370, s64[1,310]{1,0} %add.8367, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8372 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8371), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.8373 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8372), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.8376 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8375, s64[1,310,1]{2,1,0} %concatenate.8373), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8377 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8376), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.8414 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8377), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8416 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8414), metadata={op_type="aten__mul" op_name="aten__mul.420/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8417 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8416), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.420/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8418 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.8415, f32[1,32,310,128]{3,2,1,0} %broadcast.8417), metadata={op_type="aten__mul" op_name="aten__mul.420/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8419 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8418), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.8406 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8404), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8407 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.8406), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8405 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8404), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8408 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.8407, bf16[1,32,310,64]{3,2,1,0} %slice.8405), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8409 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.8408), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p551.8345 = bf16[32768,128]{1,0} parameter(551), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.8346 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p551.8345), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.8339 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8340 = s64[1,310]{1,0} broadcast(s64[] %constant.8339), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.8341 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8340), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8334 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8335 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8334), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8336 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8335), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8337 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8336), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.8338 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8337), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.8342 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8341, s64[1,310]{1,0} %add.8338, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8343 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8342), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.8344 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8343), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.8347 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8346, s64[1,310,1]{2,1,0} %concatenate.8344), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8348 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8347), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.8400 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8348), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8410 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8400), metadata={op_type="aten__mul" op_name="aten__mul.421/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8411 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8410), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.421/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8412 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.8409, f32[1,32,310,128]{3,2,1,0} %broadcast.8411), metadata={op_type="aten__mul" op_name="aten__mul.421/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8413 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8412), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.8399 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8420 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.8399), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.422/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8421 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.8413, bf16[1,32,310,128]{3,2,1,0} %broadcast.8420), metadata={op_type="aten__add" op_name="aten__add.422/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.8422 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.8419, bf16[1,32,310,128]{3,2,1,0} %multiply.8421), metadata={op_type="aten__add" op_name="aten__add.422/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8423 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.8422), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8424 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8423), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.8350 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8316), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.8351 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8350), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.8352 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8351), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.8353 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8352), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.8379 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.8353), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8378 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8377), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8380 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8378), metadata={op_type="aten__mul" op_name="aten__mul.423/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8381 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8380), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.423/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8382 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.8379, f32[1,8,310,128]{3,2,1,0} %broadcast.8381), metadata={op_type="aten__mul" op_name="aten__mul.423/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8383 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8382), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8355 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8353), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8356 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.8355), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8354 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8353), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8357 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.8356, bf16[1,8,310,64]{3,2,1,0} %slice.8354), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8358 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.8357), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8349 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8348), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8359 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8349), metadata={op_type="aten__mul" op_name="aten__mul.424/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8360 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8359), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.424/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8361 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.8358, f32[1,8,310,128]{3,2,1,0} %broadcast.8360), metadata={op_type="aten__mul" op_name="aten__mul.424/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8362 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8361), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.8333 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8384 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.8333), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.425/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8385 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.8362, bf16[1,8,310,128]{3,2,1,0} %broadcast.8384), metadata={op_type="aten__add" op_name="aten__add.425/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.8386 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.8383, bf16[1,8,310,128]{3,2,1,0} %multiply.8385), metadata={op_type="aten__add" op_name="aten__add.425/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8387 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.8386), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8388 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8387), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8389 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8388), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8390 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8389), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8391 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8390), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8392 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8391), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8393 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8392), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8394 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8393), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8395 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8394), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.8396 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8395), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8397 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.8396), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8398 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.8397), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.8425 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.8424, bf16[32,128,310]{2,1,0} %reshape.8398), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8426 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.8425), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8427 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.8428 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.8426, bf16[1,32,310,310]{3,2,1,0} %broadcast.8427), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.8332 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8429 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.8332), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.426/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.8430 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.8429), metadata={op_type="aten__add" op_name="aten__add.426/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.8431 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.8430), metadata={op_type="aten__add" op_name="aten__add.426/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8432 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.8431), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.426/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.8433 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.8428, bf16[1,32,310,310]{3,2,1,0} %broadcast.8432), metadata={op_type="aten__add" op_name="aten__add.426/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.8434 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.8433), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8435 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8440 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.8434, f32[] %constant.8435), dimensions={3}, to_apply=%MaxComputation.8436, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8441 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8440), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.8442 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.8434, f32[1,32,310,310]{3,2,1,0} %broadcast.8441), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.8443 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.8442), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8444 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8449 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.8443, f32[] %constant.8444), dimensions={3}, to_apply=%AddComputation.8445, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8450 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8449), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.8451 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.8443, f32[1,32,310,310]{3,2,1,0} %broadcast.8450), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.8452 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.8451), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.8453 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.8452), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8454 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.8453), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.8317 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8316), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.8318 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8317), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.8319 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8318), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.8320 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8319), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.8321 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8320), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8322 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8321), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8323 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8322), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8324 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8323), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8325 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8324), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8326 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8325), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8327 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8326), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8328 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8327), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8329 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8328), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.8330 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.8329), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8331 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8330), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.8455 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.8454, bf16[32,310,128]{2,1,0} %reshape.8331), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8456 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.8455), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.8457 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8456), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.8458 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.8457), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.8459 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.8458), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p83.299 = bf16[4096,4096]{1,0} parameter(83), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.300 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p83.299), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8460 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.8459, bf16[4096,4096]{0,1} %transpose.300), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8461 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8460), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.298 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.8462 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.298), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.427/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.8463 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8461, bf16[1,310,4096]{2,1,0} %broadcast.8462), metadata={op_type="aten__add" op_name="aten__add.427/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.8464 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8277, bf16[1,310,4096]{2,1,0} %multiply.8463), metadata={op_type="aten__add" op_name="aten__add.427/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p553.8495 = bf16[4096]{0} parameter(553), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8496 = f32[4096]{0} convert(bf16[4096]{0} %p553.8495), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8497 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8496), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.430/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8465 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8464), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.297 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8466 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.297), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8467 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8465, f32[1,310,4096]{2,1,0} %broadcast.8466), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8468 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8474 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8467, f32[] %constant.8468), dimensions={2}, to_apply=%AddComputation.8470, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8469 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8475 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8480 = pred[] compare(s32[] %constant.8469, s32[] %constant.8475), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8476 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8478 = f32[] convert(s32[] %constant.8469), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8479 = f32[] divide(f32[] %constant.8476, f32[] %convert.8478), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8477 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8481 = f32[] select(pred[] %compare.8480, f32[] %divide.8479, f32[] %constant.8477), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8482 = f32[1,310]{1,0} broadcast(f32[] %select.8481), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8483 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8474, f32[1,310]{1,0} %broadcast.8482), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8484 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8483), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8485 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8484), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.296 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8486 = f32[] multiply(f32[] %p4.23, f32[] %constant.296), metadata={op_type="aten__add" op_name="aten__add.428/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8487 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8486), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.428/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8488 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8485, f32[1,310,1]{2,1,0} %broadcast.8487), metadata={op_type="aten__add" op_name="aten__add.428/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8489 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8488), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8490 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8489), metadata={op_type="aten__mul" op_name="aten__mul.429/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8491 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8490), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.429/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8492 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8465, f32[1,310,4096]{2,1,0} %broadcast.8491), metadata={op_type="aten__mul" op_name="aten__mul.429/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8493 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8492), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8494 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8493), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8498 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8497, f32[1,310,4096]{2,1,0} %convert.8494), metadata={op_type="aten__mul" op_name="aten__mul.430/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8499 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8498), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8506 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8499), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p554.8504 = bf16[14336,4096]{1,0} parameter(554), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.8505 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p554.8504), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8507 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8506, bf16[4096,14336]{0,1} %transpose.8505), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8508 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8507), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.8509 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.8508), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.8510 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.8508, bf16[1,310,14336]{2,1,0} %logistic.8509), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.8511 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.8510), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8500 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8499), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p82.294 = bf16[14336,4096]{1,0} parameter(82), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.295 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p82.294), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8501 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8500, bf16[4096,14336]{0,1} %transpose.295), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8502 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8501), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.8503 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.8502), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.8512 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.8511, f32[1,310,14336]{2,1,0} %convert.8503), metadata={op_type="aten__mul" op_name="aten__mul.431/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.8513 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.8512), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8514 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.8513), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p81.292 = bf16[4096,14336]{1,0} parameter(81), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.293 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p81.292), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8515 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.8514, bf16[14336,4096]{0,1} %transpose.293), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8516 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8515), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.291 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.8517 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.291), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.432/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.8518 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8516, bf16[1,310,4096]{2,1,0} %broadcast.8517), metadata={op_type="aten__add" op_name="aten__add.432/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.8519 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8464, bf16[1,310,4096]{2,1,0} %multiply.8518), metadata={op_type="aten__add" op_name="aten__add.432/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p555.8550 = bf16[4096]{0} parameter(555), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8551 = f32[4096]{0} convert(bf16[4096]{0} %p555.8550), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8552 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8551), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.435/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8520 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8519), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.290 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8521 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.290), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8522 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8520, f32[1,310,4096]{2,1,0} %broadcast.8521), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8523 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8529 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8522, f32[] %constant.8523), dimensions={2}, to_apply=%AddComputation.8525, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8524 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8530 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8535 = pred[] compare(s32[] %constant.8524, s32[] %constant.8530), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8531 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8533 = f32[] convert(s32[] %constant.8524), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8534 = f32[] divide(f32[] %constant.8531, f32[] %convert.8533), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8532 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8536 = f32[] select(pred[] %compare.8535, f32[] %divide.8534, f32[] %constant.8532), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8537 = f32[1,310]{1,0} broadcast(f32[] %select.8536), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8538 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8529, f32[1,310]{1,0} %broadcast.8537), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8539 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8538), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8540 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8539), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.289 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8541 = f32[] multiply(f32[] %p4.23, f32[] %constant.289), metadata={op_type="aten__add" op_name="aten__add.433/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8542 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8541), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.433/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8543 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8540, f32[1,310,1]{2,1,0} %broadcast.8542), metadata={op_type="aten__add" op_name="aten__add.433/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8544 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8543), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8545 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8544), metadata={op_type="aten__mul" op_name="aten__mul.434/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8546 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8545), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.434/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8547 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8520, f32[1,310,4096]{2,1,0} %broadcast.8546), metadata={op_type="aten__mul" op_name="aten__mul.434/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8548 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8547), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8549 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8548), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8553 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8552, f32[1,310,4096]{2,1,0} %convert.8549), metadata={op_type="aten__mul" op_name="aten__mul.435/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8554 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8553), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8555 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8554), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p80.287 = bf16[6144,4096]{1,0} parameter(80), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.288 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p80.287), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8556 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.8555, bf16[4096,6144]{0,1} %transpose.288), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8557 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.8556), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8558 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.8557), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.8643 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8558), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.8644 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8643), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.8645 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8644), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.8646 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.8645), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.8657 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.8646), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p557.8616 = bf16[32768,128]{1,0} parameter(557), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.8617 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p557.8616), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.8610 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8611 = s64[1,310]{1,0} broadcast(s64[] %constant.8610), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.8612 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8611), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8605 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8606 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8605), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8607 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8606), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8608 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8607), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.8609 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8608), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.8613 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8612, s64[1,310]{1,0} %add.8609, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8614 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8613), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.8615 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8614), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.8618 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8617, s64[1,310,1]{2,1,0} %concatenate.8615), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8619 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8618), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.8656 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8619), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8658 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8656), metadata={op_type="aten__mul" op_name="aten__mul.436/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8659 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8658), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.436/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8660 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.8657, f32[1,32,310,128]{3,2,1,0} %broadcast.8659), metadata={op_type="aten__mul" op_name="aten__mul.436/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8661 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8660), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.8648 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8646), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8649 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.8648), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8647 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8646), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8650 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.8649, bf16[1,32,310,64]{3,2,1,0} %slice.8647), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8651 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.8650), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p556.8587 = bf16[32768,128]{1,0} parameter(556), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.8588 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p556.8587), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.8581 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8582 = s64[1,310]{1,0} broadcast(s64[] %constant.8581), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.8583 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8582), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8576 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8577 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8576), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8578 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8577), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8579 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8578), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.8580 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8579), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.8584 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8583, s64[1,310]{1,0} %add.8580, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8585 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8584), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.8586 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8585), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.8589 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8588, s64[1,310,1]{2,1,0} %concatenate.8586), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8590 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8589), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.8642 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8590), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8652 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8642), metadata={op_type="aten__mul" op_name="aten__mul.437/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8653 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8652), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.437/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8654 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.8651, f32[1,32,310,128]{3,2,1,0} %broadcast.8653), metadata={op_type="aten__mul" op_name="aten__mul.437/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8655 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8654), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.8641 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8662 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.8641), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.438/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8663 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.8655, bf16[1,32,310,128]{3,2,1,0} %broadcast.8662), metadata={op_type="aten__add" op_name="aten__add.438/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.8664 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.8661, bf16[1,32,310,128]{3,2,1,0} %multiply.8663), metadata={op_type="aten__add" op_name="aten__add.438/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8665 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.8664), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8666 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8665), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.8592 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8558), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.8593 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8592), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.8594 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8593), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.8595 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8594), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.8621 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.8595), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8620 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8619), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8622 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8620), metadata={op_type="aten__mul" op_name="aten__mul.439/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8623 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8622), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.439/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8624 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.8621, f32[1,8,310,128]{3,2,1,0} %broadcast.8623), metadata={op_type="aten__mul" op_name="aten__mul.439/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8625 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8624), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8597 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8595), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8598 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.8597), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8596 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8595), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8599 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.8598, bf16[1,8,310,64]{3,2,1,0} %slice.8596), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8600 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.8599), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8591 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8590), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8601 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8591), metadata={op_type="aten__mul" op_name="aten__mul.440/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8602 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8601), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.440/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8603 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.8600, f32[1,8,310,128]{3,2,1,0} %broadcast.8602), metadata={op_type="aten__mul" op_name="aten__mul.440/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8604 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8603), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.8575 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8626 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.8575), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.441/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8627 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.8604, bf16[1,8,310,128]{3,2,1,0} %broadcast.8626), metadata={op_type="aten__add" op_name="aten__add.441/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.8628 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.8625, bf16[1,8,310,128]{3,2,1,0} %multiply.8627), metadata={op_type="aten__add" op_name="aten__add.441/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8629 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.8628), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8630 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8629), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8631 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8630), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8632 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8631), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8633 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8632), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8634 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8633), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8635 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8634), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8636 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8635), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8637 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8636), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.8638 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8637), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8639 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.8638), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8640 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.8639), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.8667 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.8666, bf16[32,128,310]{2,1,0} %reshape.8640), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8668 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.8667), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8669 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.8670 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.8668, bf16[1,32,310,310]{3,2,1,0} %broadcast.8669), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.8574 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8671 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.8574), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.442/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.8672 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.8671), metadata={op_type="aten__add" op_name="aten__add.442/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.8673 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.8672), metadata={op_type="aten__add" op_name="aten__add.442/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8674 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.8673), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.442/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.8675 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.8670, bf16[1,32,310,310]{3,2,1,0} %broadcast.8674), metadata={op_type="aten__add" op_name="aten__add.442/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.8676 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.8675), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8677 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8682 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.8676, f32[] %constant.8677), dimensions={3}, to_apply=%MaxComputation.8678, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8683 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8682), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.8684 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.8676, f32[1,32,310,310]{3,2,1,0} %broadcast.8683), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.8685 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.8684), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8686 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8691 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.8685, f32[] %constant.8686), dimensions={3}, to_apply=%AddComputation.8687, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8692 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8691), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.8693 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.8685, f32[1,32,310,310]{3,2,1,0} %broadcast.8692), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.8694 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.8693), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.8695 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.8694), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8696 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.8695), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.8559 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8558), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.8560 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8559), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.8561 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8560), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.8562 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8561), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.8563 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8562), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8564 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8563), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8565 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8564), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8566 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8565), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8567 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8566), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8568 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8567), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8569 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8568), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8570 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8569), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8571 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8570), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.8572 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.8571), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8573 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8572), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.8697 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.8696, bf16[32,310,128]{2,1,0} %reshape.8573), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8698 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.8697), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.8699 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8698), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.8700 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.8699), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.8701 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.8700), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p79.285 = bf16[4096,4096]{1,0} parameter(79), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.286 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p79.285), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8702 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.8701, bf16[4096,4096]{0,1} %transpose.286), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8703 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8702), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.284 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.8704 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.284), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.443/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.8705 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8703, bf16[1,310,4096]{2,1,0} %broadcast.8704), metadata={op_type="aten__add" op_name="aten__add.443/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.8706 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8519, bf16[1,310,4096]{2,1,0} %multiply.8705), metadata={op_type="aten__add" op_name="aten__add.443/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p558.8737 = bf16[4096]{0} parameter(558), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8738 = f32[4096]{0} convert(bf16[4096]{0} %p558.8737), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8739 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8738), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.446/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8707 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8706), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.283 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8708 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.283), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8709 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8707, f32[1,310,4096]{2,1,0} %broadcast.8708), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8710 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8716 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8709, f32[] %constant.8710), dimensions={2}, to_apply=%AddComputation.8712, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8711 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8717 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8722 = pred[] compare(s32[] %constant.8711, s32[] %constant.8717), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8718 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8720 = f32[] convert(s32[] %constant.8711), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8721 = f32[] divide(f32[] %constant.8718, f32[] %convert.8720), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8719 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8723 = f32[] select(pred[] %compare.8722, f32[] %divide.8721, f32[] %constant.8719), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8724 = f32[1,310]{1,0} broadcast(f32[] %select.8723), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8725 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8716, f32[1,310]{1,0} %broadcast.8724), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8726 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8725), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8727 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8726), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.282 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8728 = f32[] multiply(f32[] %p4.23, f32[] %constant.282), metadata={op_type="aten__add" op_name="aten__add.444/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8729 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8728), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.444/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8730 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8727, f32[1,310,1]{2,1,0} %broadcast.8729), metadata={op_type="aten__add" op_name="aten__add.444/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8731 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8730), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8732 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8731), metadata={op_type="aten__mul" op_name="aten__mul.445/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8733 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8732), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.445/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8734 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8707, f32[1,310,4096]{2,1,0} %broadcast.8733), metadata={op_type="aten__mul" op_name="aten__mul.445/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8735 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8734), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8736 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8735), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8740 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8739, f32[1,310,4096]{2,1,0} %convert.8736), metadata={op_type="aten__mul" op_name="aten__mul.446/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8741 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8740), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8748 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8741), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p559.8746 = bf16[14336,4096]{1,0} parameter(559), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.8747 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p559.8746), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8749 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8748, bf16[4096,14336]{0,1} %transpose.8747), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8750 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8749), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.8751 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.8750), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.8752 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.8750, bf16[1,310,14336]{2,1,0} %logistic.8751), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.8753 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.8752), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8742 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8741), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p78.280 = bf16[14336,4096]{1,0} parameter(78), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.281 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p78.280), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8743 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8742, bf16[4096,14336]{0,1} %transpose.281), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8744 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8743), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.8745 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.8744), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.8754 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.8753, f32[1,310,14336]{2,1,0} %convert.8745), metadata={op_type="aten__mul" op_name="aten__mul.447/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.8755 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.8754), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8756 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.8755), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p77.278 = bf16[4096,14336]{1,0} parameter(77), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.279 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p77.278), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8757 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.8756, bf16[14336,4096]{0,1} %transpose.279), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8758 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8757), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.277 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.8759 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.277), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.448/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.8760 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8758, bf16[1,310,4096]{2,1,0} %broadcast.8759), metadata={op_type="aten__add" op_name="aten__add.448/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.8761 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8706, bf16[1,310,4096]{2,1,0} %multiply.8760), metadata={op_type="aten__add" op_name="aten__add.448/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p560.8792 = bf16[4096]{0} parameter(560), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8793 = f32[4096]{0} convert(bf16[4096]{0} %p560.8792), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8794 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8793), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.451/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8762 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8761), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.276 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8763 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.276), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8764 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8762, f32[1,310,4096]{2,1,0} %broadcast.8763), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8765 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8771 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8764, f32[] %constant.8765), dimensions={2}, to_apply=%AddComputation.8767, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8766 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8772 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8777 = pred[] compare(s32[] %constant.8766, s32[] %constant.8772), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8773 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8775 = f32[] convert(s32[] %constant.8766), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8776 = f32[] divide(f32[] %constant.8773, f32[] %convert.8775), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8774 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8778 = f32[] select(pred[] %compare.8777, f32[] %divide.8776, f32[] %constant.8774), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8779 = f32[1,310]{1,0} broadcast(f32[] %select.8778), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8780 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8771, f32[1,310]{1,0} %broadcast.8779), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8781 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8780), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8782 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8781), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.275 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8783 = f32[] multiply(f32[] %p4.23, f32[] %constant.275), metadata={op_type="aten__add" op_name="aten__add.449/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8784 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8783), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.449/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8785 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8782, f32[1,310,1]{2,1,0} %broadcast.8784), metadata={op_type="aten__add" op_name="aten__add.449/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8786 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8785), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8787 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8786), metadata={op_type="aten__mul" op_name="aten__mul.450/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8788 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8787), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.450/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8789 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8762, f32[1,310,4096]{2,1,0} %broadcast.8788), metadata={op_type="aten__mul" op_name="aten__mul.450/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8790 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8789), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8791 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8790), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8795 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8794, f32[1,310,4096]{2,1,0} %convert.8791), metadata={op_type="aten__mul" op_name="aten__mul.451/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8796 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8795), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8797 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8796), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p76.273 = bf16[6144,4096]{1,0} parameter(76), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.274 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p76.273), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8798 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.8797, bf16[4096,6144]{0,1} %transpose.274), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8799 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.8798), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8800 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.8799), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.8885 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8800), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.8886 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8885), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.8887 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.8886), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.8888 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.8887), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.8899 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.8888), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p562.8858 = bf16[32768,128]{1,0} parameter(562), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.8859 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p562.8858), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.8852 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8853 = s64[1,310]{1,0} broadcast(s64[] %constant.8852), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.8854 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8853), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8847 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8848 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8847), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8849 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8848), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.8850 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8849), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.8851 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8850), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.8855 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8854, s64[1,310]{1,0} %add.8851, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8856 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8855), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.8857 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8856), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.8860 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8859, s64[1,310,1]{2,1,0} %concatenate.8857), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.8861 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8860), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.8898 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8861), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8900 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8898), metadata={op_type="aten__mul" op_name="aten__mul.452/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8901 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8900), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.452/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8902 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.8899, f32[1,32,310,128]{3,2,1,0} %broadcast.8901), metadata={op_type="aten__mul" op_name="aten__mul.452/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8903 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8902), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.8890 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8888), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8891 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.8890), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8889 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.8888), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8892 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.8891, bf16[1,32,310,64]{3,2,1,0} %slice.8889), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8893 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.8892), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p561.8829 = bf16[32768,128]{1,0} parameter(561), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.8830 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p561.8829), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.8823 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8824 = s64[1,310]{1,0} broadcast(s64[] %constant.8823), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.8825 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8824), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8818 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8819 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.8818), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8820 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.8819), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.8821 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.8820), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.8822 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.8821), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.8826 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.8825, s64[1,310]{1,0} %add.8822, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8827 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.8826), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.8828 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.8827), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.8831 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.8830, s64[1,310,1]{2,1,0} %concatenate.8828), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.8832 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.8831), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.8884 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8832), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.8894 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8884), metadata={op_type="aten__mul" op_name="aten__mul.453/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8895 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8894), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.453/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8896 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.8893, f32[1,32,310,128]{3,2,1,0} %broadcast.8895), metadata={op_type="aten__mul" op_name="aten__mul.453/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.8897 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.8896), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.8883 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8904 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.8883), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.454/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.8905 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.8897, bf16[1,32,310,128]{3,2,1,0} %broadcast.8904), metadata={op_type="aten__add" op_name="aten__add.454/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.8906 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.8903, bf16[1,32,310,128]{3,2,1,0} %multiply.8905), metadata={op_type="aten__add" op_name="aten__add.454/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.8907 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.8906), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8908 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8907), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.8834 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8800), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.8835 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8834), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.8836 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8835), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.8837 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8836), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.8863 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.8837), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8862 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8861), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8864 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8862), metadata={op_type="aten__mul" op_name="aten__mul.455/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8865 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8864), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.455/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8866 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.8863, f32[1,8,310,128]{3,2,1,0} %broadcast.8865), metadata={op_type="aten__mul" op_name="aten__mul.455/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8867 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8866), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8839 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8837), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.8840 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.8839), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.8838 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8837), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.8841 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.8840, bf16[1,8,310,64]{3,2,1,0} %slice.8838), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.8842 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.8841), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8833 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.8832), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.8843 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.8833), metadata={op_type="aten__mul" op_name="aten__mul.456/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8844 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.8843), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.456/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8845 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.8842, f32[1,8,310,128]{3,2,1,0} %broadcast.8844), metadata={op_type="aten__mul" op_name="aten__mul.456/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.8846 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.8845), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.8817 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.8868 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.8817), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.457/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.8869 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.8846, bf16[1,8,310,128]{3,2,1,0} %broadcast.8868), metadata={op_type="aten__add" op_name="aten__add.457/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.8870 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.8867, bf16[1,8,310,128]{3,2,1,0} %multiply.8869), metadata={op_type="aten__add" op_name="aten__add.457/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.8871 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.8870), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8872 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8871), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8873 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8872), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8874 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8873), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8875 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8874), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8876 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8875), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8877 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8876), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8878 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8877), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8879 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8878), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.8880 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8879), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8881 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.8880), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8882 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.8881), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.8909 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.8908, bf16[32,128,310]{2,1,0} %reshape.8882), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.8910 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.8909), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.8911 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.8912 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.8910, bf16[1,32,310,310]{3,2,1,0} %broadcast.8911), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.8816 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8913 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.8816), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.458/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.8914 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.8913), metadata={op_type="aten__add" op_name="aten__add.458/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.8915 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.8914), metadata={op_type="aten__add" op_name="aten__add.458/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.8916 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.8915), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.458/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.8917 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.8912, bf16[1,32,310,310]{3,2,1,0} %broadcast.8916), metadata={op_type="aten__add" op_name="aten__add.458/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.8918 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.8917), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8919 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8924 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.8918, f32[] %constant.8919), dimensions={3}, to_apply=%MaxComputation.8920, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8925 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8924), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.8926 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.8918, f32[1,32,310,310]{3,2,1,0} %broadcast.8925), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.8927 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.8926), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.8928 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.8933 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.8927, f32[] %constant.8928), dimensions={3}, to_apply=%AddComputation.8929, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.8934 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.8933), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.8935 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.8927, f32[1,32,310,310]{3,2,1,0} %broadcast.8934), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.8936 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.8935), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.8937 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.8936), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8938 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.8937), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.8801 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.8800), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.8802 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.8801), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.8803 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.8802), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.8804 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.8803), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.8805 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.8804), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8806 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.8805), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8807 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.8806), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8808 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.8807), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.8809 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8808), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8810 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.8809), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8811 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.8810), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.8812 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.8811), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.8813 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.8812), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.8814 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.8813), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8815 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.8814), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.8939 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.8938, bf16[32,310,128]{2,1,0} %reshape.8815), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.8940 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.8939), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.8941 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.8940), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.8942 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.8941), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.8943 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.8942), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p75.271 = bf16[4096,4096]{1,0} parameter(75), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.272 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p75.271), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8944 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.8943, bf16[4096,4096]{0,1} %transpose.272), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8945 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8944), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.270 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.8946 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.270), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.459/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.8947 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.8945, bf16[1,310,4096]{2,1,0} %broadcast.8946), metadata={op_type="aten__add" op_name="aten__add.459/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.8948 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8761, bf16[1,310,4096]{2,1,0} %multiply.8947), metadata={op_type="aten__add" op_name="aten__add.459/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p563.8979 = bf16[4096]{0} parameter(563), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.8980 = f32[4096]{0} convert(bf16[4096]{0} %p563.8979), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.8981 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.8980), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.462/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8949 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.8948), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.269 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8950 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.269), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.8951 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.8949, f32[1,310,4096]{2,1,0} %broadcast.8950), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8952 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.8958 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.8951, f32[] %constant.8952), dimensions={2}, to_apply=%AddComputation.8954, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8953 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8959 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.8964 = pred[] compare(s32[] %constant.8953, s32[] %constant.8959), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8960 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8962 = f32[] convert(s32[] %constant.8953), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.8963 = f32[] divide(f32[] %constant.8960, f32[] %convert.8962), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.8961 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.8965 = f32[] select(pred[] %compare.8964, f32[] %divide.8963, f32[] %constant.8961), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.8966 = f32[1,310]{1,0} broadcast(f32[] %select.8965), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.8967 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.8958, f32[1,310]{1,0} %broadcast.8966), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.8968 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.8967), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.8969 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.8968), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.268 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8970 = f32[] multiply(f32[] %p4.23, f32[] %constant.268), metadata={op_type="aten__add" op_name="aten__add.460/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8971 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.8970), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.460/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.8972 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.8969, f32[1,310,1]{2,1,0} %broadcast.8971), metadata={op_type="aten__add" op_name="aten__add.460/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.8973 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.8972), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.8974 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.8973), metadata={op_type="aten__mul" op_name="aten__mul.461/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.8975 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.8974), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.461/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.8976 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.8949, f32[1,310,4096]{2,1,0} %broadcast.8975), metadata={op_type="aten__mul" op_name="aten__mul.461/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.8977 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8976), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8978 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.8977), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.8982 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.8981, f32[1,310,4096]{2,1,0} %convert.8978), metadata={op_type="aten__mul" op_name="aten__mul.462/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.8983 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.8982), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.8990 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8983), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p564.8988 = bf16[14336,4096]{1,0} parameter(564), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.8989 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p564.8988), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8991 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8990, bf16[4096,14336]{0,1} %transpose.8989), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8992 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8991), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.8993 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.8992), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.8994 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.8992, bf16[1,310,14336]{2,1,0} %logistic.8993), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.8995 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.8994), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8984 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.8983), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p74.266 = bf16[14336,4096]{1,0} parameter(74), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.267 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p74.266), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8985 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.8984, bf16[4096,14336]{0,1} %transpose.267), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.8986 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.8985), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.8987 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.8986), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.8996 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.8995, f32[1,310,14336]{2,1,0} %convert.8987), metadata={op_type="aten__mul" op_name="aten__mul.463/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.8997 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.8996), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.8998 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.8997), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p73.264 = bf16[4096,14336]{1,0} parameter(73), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.265 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p73.264), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.8999 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.8998, bf16[14336,4096]{0,1} %transpose.265), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9000 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.8999), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.263 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.9001 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.263), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.464/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.9002 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9000, bf16[1,310,4096]{2,1,0} %broadcast.9001), metadata={op_type="aten__add" op_name="aten__add.464/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.9003 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.8948, bf16[1,310,4096]{2,1,0} %multiply.9002), metadata={op_type="aten__add" op_name="aten__add.464/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p565.9034 = bf16[4096]{0} parameter(565), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9035 = f32[4096]{0} convert(bf16[4096]{0} %p565.9034), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9036 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9035), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.467/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9004 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9003), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.262 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9005 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.262), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9006 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9004, f32[1,310,4096]{2,1,0} %broadcast.9005), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9007 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9013 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9006, f32[] %constant.9007), dimensions={2}, to_apply=%AddComputation.9009, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9008 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9014 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9019 = pred[] compare(s32[] %constant.9008, s32[] %constant.9014), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9015 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9017 = f32[] convert(s32[] %constant.9008), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9018 = f32[] divide(f32[] %constant.9015, f32[] %convert.9017), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9016 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9020 = f32[] select(pred[] %compare.9019, f32[] %divide.9018, f32[] %constant.9016), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9021 = f32[1,310]{1,0} broadcast(f32[] %select.9020), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9022 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9013, f32[1,310]{1,0} %broadcast.9021), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9023 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9022), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9024 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9023), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.261 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9025 = f32[] multiply(f32[] %p4.23, f32[] %constant.261), metadata={op_type="aten__add" op_name="aten__add.465/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9026 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9025), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.465/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9027 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9024, f32[1,310,1]{2,1,0} %broadcast.9026), metadata={op_type="aten__add" op_name="aten__add.465/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9028 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9027), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9029 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9028), metadata={op_type="aten__mul" op_name="aten__mul.466/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9030 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9029), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.466/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9031 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9004, f32[1,310,4096]{2,1,0} %broadcast.9030), metadata={op_type="aten__mul" op_name="aten__mul.466/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9032 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9031), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9033 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9032), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9037 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9036, f32[1,310,4096]{2,1,0} %convert.9033), metadata={op_type="aten__mul" op_name="aten__mul.467/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9038 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9037), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9039 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9038), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p72.259 = bf16[6144,4096]{1,0} parameter(72), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.260 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p72.259), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9040 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.9039, bf16[4096,6144]{0,1} %transpose.260), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9041 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.9040), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9042 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.9041), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.9127 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9042), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.9128 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9127), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.9129 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9128), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.9130 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.9129), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.9141 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.9130), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p567.9100 = bf16[32768,128]{1,0} parameter(567), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.9101 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p567.9100), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.9094 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9095 = s64[1,310]{1,0} broadcast(s64[] %constant.9094), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.9096 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9095), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9089 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9090 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9089), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9091 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9090), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9092 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9091), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.9093 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9092), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.9097 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9096, s64[1,310]{1,0} %add.9093, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9098 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9097), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.9099 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9098), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.9102 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9101, s64[1,310,1]{2,1,0} %concatenate.9099), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9103 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9102), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.9140 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9103), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9142 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9140), metadata={op_type="aten__mul" op_name="aten__mul.468/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9143 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9142), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.468/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9144 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.9141, f32[1,32,310,128]{3,2,1,0} %broadcast.9143), metadata={op_type="aten__mul" op_name="aten__mul.468/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9145 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9144), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.9132 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9130), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9133 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.9132), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9131 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9130), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9134 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.9133, bf16[1,32,310,64]{3,2,1,0} %slice.9131), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9135 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.9134), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p566.9071 = bf16[32768,128]{1,0} parameter(566), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.9072 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p566.9071), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.9065 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9066 = s64[1,310]{1,0} broadcast(s64[] %constant.9065), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.9067 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9066), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9060 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9061 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9060), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9062 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9061), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9063 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9062), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.9064 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9063), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.9068 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9067, s64[1,310]{1,0} %add.9064, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9069 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9068), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.9070 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9069), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.9073 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9072, s64[1,310,1]{2,1,0} %concatenate.9070), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9074 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9073), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.9126 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9074), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9136 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9126), metadata={op_type="aten__mul" op_name="aten__mul.469/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9137 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9136), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.469/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9138 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.9135, f32[1,32,310,128]{3,2,1,0} %broadcast.9137), metadata={op_type="aten__mul" op_name="aten__mul.469/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9139 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9138), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.9125 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9146 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.9125), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.470/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9147 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.9139, bf16[1,32,310,128]{3,2,1,0} %broadcast.9146), metadata={op_type="aten__add" op_name="aten__add.470/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.9148 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.9145, bf16[1,32,310,128]{3,2,1,0} %multiply.9147), metadata={op_type="aten__add" op_name="aten__add.470/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9149 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.9148), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9150 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9149), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.9076 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9042), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.9077 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9076), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.9078 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9077), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.9079 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9078), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.9105 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.9079), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9104 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9103), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9106 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9104), metadata={op_type="aten__mul" op_name="aten__mul.471/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9107 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9106), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.471/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9108 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.9105, f32[1,8,310,128]{3,2,1,0} %broadcast.9107), metadata={op_type="aten__mul" op_name="aten__mul.471/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9109 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9108), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9081 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9079), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9082 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.9081), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9080 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9079), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9083 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.9082, bf16[1,8,310,64]{3,2,1,0} %slice.9080), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9084 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.9083), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9075 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9074), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9085 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9075), metadata={op_type="aten__mul" op_name="aten__mul.472/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9086 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9085), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.472/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9087 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.9084, f32[1,8,310,128]{3,2,1,0} %broadcast.9086), metadata={op_type="aten__mul" op_name="aten__mul.472/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9088 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9087), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.9059 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9110 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.9059), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.473/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9111 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.9088, bf16[1,8,310,128]{3,2,1,0} %broadcast.9110), metadata={op_type="aten__add" op_name="aten__add.473/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.9112 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.9109, bf16[1,8,310,128]{3,2,1,0} %multiply.9111), metadata={op_type="aten__add" op_name="aten__add.473/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9113 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.9112), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9114 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9113), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9115 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9114), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9116 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9115), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9117 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9116), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9118 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9117), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9119 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9118), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9120 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9119), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9121 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9120), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.9122 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9121), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9123 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.9122), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9124 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.9123), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.9151 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.9150, bf16[32,128,310]{2,1,0} %reshape.9124), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9152 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.9151), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9153 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.9154 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.9152, bf16[1,32,310,310]{3,2,1,0} %broadcast.9153), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.9058 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9155 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.9058), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.474/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.9156 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.9155), metadata={op_type="aten__add" op_name="aten__add.474/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.9157 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.9156), metadata={op_type="aten__add" op_name="aten__add.474/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9158 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.9157), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.474/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.9159 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.9154, bf16[1,32,310,310]{3,2,1,0} %broadcast.9158), metadata={op_type="aten__add" op_name="aten__add.474/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.9160 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.9159), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9161 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9166 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.9160, f32[] %constant.9161), dimensions={3}, to_apply=%MaxComputation.9162, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9167 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9166), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.9168 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.9160, f32[1,32,310,310]{3,2,1,0} %broadcast.9167), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.9169 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.9168), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9170 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9175 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.9169, f32[] %constant.9170), dimensions={3}, to_apply=%AddComputation.9171, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9176 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9175), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.9177 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.9169, f32[1,32,310,310]{3,2,1,0} %broadcast.9176), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.9178 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.9177), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.9179 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.9178), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9180 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.9179), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.9043 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9042), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.9044 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9043), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.9045 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9044), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.9046 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9045), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.9047 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9046), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9048 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9047), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9049 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9048), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9050 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9049), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9051 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9050), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9052 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9051), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9053 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9052), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9054 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9053), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9055 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9054), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.9056 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.9055), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9057 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9056), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.9181 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.9180, bf16[32,310,128]{2,1,0} %reshape.9057), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9182 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.9181), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.9183 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9182), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.9184 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.9183), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.9185 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.9184), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p71.257 = bf16[4096,4096]{1,0} parameter(71), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.258 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p71.257), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9186 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.9185, bf16[4096,4096]{0,1} %transpose.258), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9187 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9186), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.256 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.9188 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.256), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.475/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.9189 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9187, bf16[1,310,4096]{2,1,0} %broadcast.9188), metadata={op_type="aten__add" op_name="aten__add.475/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.9190 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9003, bf16[1,310,4096]{2,1,0} %multiply.9189), metadata={op_type="aten__add" op_name="aten__add.475/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p568.9221 = bf16[4096]{0} parameter(568), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9222 = f32[4096]{0} convert(bf16[4096]{0} %p568.9221), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9223 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9222), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.478/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9191 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9190), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.255 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9192 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.255), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9193 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9191, f32[1,310,4096]{2,1,0} %broadcast.9192), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9194 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9200 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9193, f32[] %constant.9194), dimensions={2}, to_apply=%AddComputation.9196, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9195 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9201 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9206 = pred[] compare(s32[] %constant.9195, s32[] %constant.9201), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9202 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9204 = f32[] convert(s32[] %constant.9195), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9205 = f32[] divide(f32[] %constant.9202, f32[] %convert.9204), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9203 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9207 = f32[] select(pred[] %compare.9206, f32[] %divide.9205, f32[] %constant.9203), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9208 = f32[1,310]{1,0} broadcast(f32[] %select.9207), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9209 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9200, f32[1,310]{1,0} %broadcast.9208), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9210 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9209), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9211 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9210), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.254 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9212 = f32[] multiply(f32[] %p4.23, f32[] %constant.254), metadata={op_type="aten__add" op_name="aten__add.476/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9213 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9212), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.476/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9214 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9211, f32[1,310,1]{2,1,0} %broadcast.9213), metadata={op_type="aten__add" op_name="aten__add.476/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9215 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9214), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9216 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9215), metadata={op_type="aten__mul" op_name="aten__mul.477/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9217 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9216), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.477/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9218 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9191, f32[1,310,4096]{2,1,0} %broadcast.9217), metadata={op_type="aten__mul" op_name="aten__mul.477/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9219 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9218), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9220 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9219), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9224 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9223, f32[1,310,4096]{2,1,0} %convert.9220), metadata={op_type="aten__mul" op_name="aten__mul.478/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9225 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9224), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9232 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9225), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p569.9230 = bf16[14336,4096]{1,0} parameter(569), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.9231 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p569.9230), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9233 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9232, bf16[4096,14336]{0,1} %transpose.9231), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9234 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9233), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.9235 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.9234), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.9236 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.9234, bf16[1,310,14336]{2,1,0} %logistic.9235), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.9237 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.9236), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9226 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9225), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p70.252 = bf16[14336,4096]{1,0} parameter(70), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.253 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p70.252), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9227 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9226, bf16[4096,14336]{0,1} %transpose.253), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9228 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9227), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.9229 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.9228), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.9238 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.9237, f32[1,310,14336]{2,1,0} %convert.9229), metadata={op_type="aten__mul" op_name="aten__mul.479/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.9239 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.9238), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9240 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.9239), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p69.250 = bf16[4096,14336]{1,0} parameter(69), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.251 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p69.250), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9241 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.9240, bf16[14336,4096]{0,1} %transpose.251), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9242 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9241), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.249 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.9243 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.249), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.480/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.9244 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9242, bf16[1,310,4096]{2,1,0} %broadcast.9243), metadata={op_type="aten__add" op_name="aten__add.480/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.9245 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9190, bf16[1,310,4096]{2,1,0} %multiply.9244), metadata={op_type="aten__add" op_name="aten__add.480/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p570.9276 = bf16[4096]{0} parameter(570), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9277 = f32[4096]{0} convert(bf16[4096]{0} %p570.9276), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9278 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9277), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.483/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9246 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9245), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.248 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9247 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.248), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9248 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9246, f32[1,310,4096]{2,1,0} %broadcast.9247), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9249 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9255 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9248, f32[] %constant.9249), dimensions={2}, to_apply=%AddComputation.9251, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9250 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9256 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9261 = pred[] compare(s32[] %constant.9250, s32[] %constant.9256), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9257 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9259 = f32[] convert(s32[] %constant.9250), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9260 = f32[] divide(f32[] %constant.9257, f32[] %convert.9259), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9258 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9262 = f32[] select(pred[] %compare.9261, f32[] %divide.9260, f32[] %constant.9258), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9263 = f32[1,310]{1,0} broadcast(f32[] %select.9262), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9264 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9255, f32[1,310]{1,0} %broadcast.9263), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9265 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9264), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9266 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9265), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.247 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9267 = f32[] multiply(f32[] %p4.23, f32[] %constant.247), metadata={op_type="aten__add" op_name="aten__add.481/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9268 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9267), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.481/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9269 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9266, f32[1,310,1]{2,1,0} %broadcast.9268), metadata={op_type="aten__add" op_name="aten__add.481/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9270 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9269), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9271 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9270), metadata={op_type="aten__mul" op_name="aten__mul.482/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9272 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9271), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.482/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9273 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9246, f32[1,310,4096]{2,1,0} %broadcast.9272), metadata={op_type="aten__mul" op_name="aten__mul.482/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9274 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9273), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9275 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9274), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9279 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9278, f32[1,310,4096]{2,1,0} %convert.9275), metadata={op_type="aten__mul" op_name="aten__mul.483/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9280 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9279), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9281 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9280), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p68.245 = bf16[6144,4096]{1,0} parameter(68), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.246 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p68.245), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9282 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.9281, bf16[4096,6144]{0,1} %transpose.246), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9283 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.9282), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9284 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.9283), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.9369 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9284), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.9370 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9369), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.9371 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9370), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.9372 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.9371), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.9383 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.9372), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p572.9342 = bf16[32768,128]{1,0} parameter(572), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.9343 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p572.9342), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.9336 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9337 = s64[1,310]{1,0} broadcast(s64[] %constant.9336), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.9338 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9337), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9331 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9332 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9331), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9333 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9332), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9334 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9333), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.9335 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9334), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.9339 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9338, s64[1,310]{1,0} %add.9335, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9340 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9339), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.9341 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9340), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.9344 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9343, s64[1,310,1]{2,1,0} %concatenate.9341), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9345 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9344), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.9382 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9345), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9384 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9382), metadata={op_type="aten__mul" op_name="aten__mul.484/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9385 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9384), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.484/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9386 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.9383, f32[1,32,310,128]{3,2,1,0} %broadcast.9385), metadata={op_type="aten__mul" op_name="aten__mul.484/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9387 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9386), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.9374 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9372), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9375 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.9374), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9373 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9372), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9376 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.9375, bf16[1,32,310,64]{3,2,1,0} %slice.9373), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9377 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.9376), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p571.9313 = bf16[32768,128]{1,0} parameter(571), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.9314 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p571.9313), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.9307 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9308 = s64[1,310]{1,0} broadcast(s64[] %constant.9307), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.9309 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9308), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9302 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9303 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9302), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9304 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9303), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9305 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9304), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.9306 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9305), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.9310 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9309, s64[1,310]{1,0} %add.9306, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9311 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9310), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.9312 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9311), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.9315 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9314, s64[1,310,1]{2,1,0} %concatenate.9312), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9316 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9315), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.9368 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9316), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9378 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9368), metadata={op_type="aten__mul" op_name="aten__mul.485/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9379 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9378), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.485/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9380 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.9377, f32[1,32,310,128]{3,2,1,0} %broadcast.9379), metadata={op_type="aten__mul" op_name="aten__mul.485/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9381 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9380), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.9367 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9388 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.9367), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.486/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9389 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.9381, bf16[1,32,310,128]{3,2,1,0} %broadcast.9388), metadata={op_type="aten__add" op_name="aten__add.486/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.9390 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.9387, bf16[1,32,310,128]{3,2,1,0} %multiply.9389), metadata={op_type="aten__add" op_name="aten__add.486/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9391 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.9390), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9392 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9391), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.9318 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9284), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.9319 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9318), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.9320 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9319), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.9321 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9320), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.9347 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.9321), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9346 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9345), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9348 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9346), metadata={op_type="aten__mul" op_name="aten__mul.487/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9349 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9348), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.487/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9350 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.9347, f32[1,8,310,128]{3,2,1,0} %broadcast.9349), metadata={op_type="aten__mul" op_name="aten__mul.487/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9351 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9350), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9323 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9321), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9324 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.9323), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9322 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9321), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9325 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.9324, bf16[1,8,310,64]{3,2,1,0} %slice.9322), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9326 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.9325), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9317 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9316), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9327 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9317), metadata={op_type="aten__mul" op_name="aten__mul.488/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9328 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9327), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.488/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9329 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.9326, f32[1,8,310,128]{3,2,1,0} %broadcast.9328), metadata={op_type="aten__mul" op_name="aten__mul.488/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9330 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9329), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.9301 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9352 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.9301), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.489/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9353 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.9330, bf16[1,8,310,128]{3,2,1,0} %broadcast.9352), metadata={op_type="aten__add" op_name="aten__add.489/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.9354 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.9351, bf16[1,8,310,128]{3,2,1,0} %multiply.9353), metadata={op_type="aten__add" op_name="aten__add.489/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9355 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.9354), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9356 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9355), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9357 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9356), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9358 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9357), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9359 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9358), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9360 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9359), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9361 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9360), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9362 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9361), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9363 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9362), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.9364 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9363), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9365 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.9364), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9366 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.9365), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.9393 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.9392, bf16[32,128,310]{2,1,0} %reshape.9366), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9394 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.9393), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9395 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.9396 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.9394, bf16[1,32,310,310]{3,2,1,0} %broadcast.9395), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.9300 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9397 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.9300), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.490/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.9398 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.9397), metadata={op_type="aten__add" op_name="aten__add.490/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.9399 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.9398), metadata={op_type="aten__add" op_name="aten__add.490/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9400 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.9399), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.490/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.9401 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.9396, bf16[1,32,310,310]{3,2,1,0} %broadcast.9400), metadata={op_type="aten__add" op_name="aten__add.490/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.9402 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.9401), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9403 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9408 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.9402, f32[] %constant.9403), dimensions={3}, to_apply=%MaxComputation.9404, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9409 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9408), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.9410 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.9402, f32[1,32,310,310]{3,2,1,0} %broadcast.9409), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.9411 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.9410), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9412 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9417 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.9411, f32[] %constant.9412), dimensions={3}, to_apply=%AddComputation.9413, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9418 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9417), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.9419 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.9411, f32[1,32,310,310]{3,2,1,0} %broadcast.9418), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.9420 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.9419), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.9421 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.9420), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9422 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.9421), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.9285 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9284), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.9286 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9285), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.9287 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9286), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.9288 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9287), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.9289 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9288), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9290 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9289), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9291 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9290), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9292 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9291), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9293 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9292), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9294 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9293), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9295 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9294), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9296 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9295), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9297 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9296), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.9298 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.9297), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9299 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9298), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.9423 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.9422, bf16[32,310,128]{2,1,0} %reshape.9299), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9424 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.9423), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.9425 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9424), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.9426 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.9425), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.9427 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.9426), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p67.243 = bf16[4096,4096]{1,0} parameter(67), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.244 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p67.243), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9428 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.9427, bf16[4096,4096]{0,1} %transpose.244), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9429 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9428), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.242 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.9430 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.242), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.491/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.9431 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9429, bf16[1,310,4096]{2,1,0} %broadcast.9430), metadata={op_type="aten__add" op_name="aten__add.491/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.9432 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9245, bf16[1,310,4096]{2,1,0} %multiply.9431), metadata={op_type="aten__add" op_name="aten__add.491/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p573.9463 = bf16[4096]{0} parameter(573), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9464 = f32[4096]{0} convert(bf16[4096]{0} %p573.9463), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9465 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9464), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.494/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9433 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9432), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.241 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9434 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.241), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9435 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9433, f32[1,310,4096]{2,1,0} %broadcast.9434), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9436 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9442 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9435, f32[] %constant.9436), dimensions={2}, to_apply=%AddComputation.9438, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9437 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9443 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9448 = pred[] compare(s32[] %constant.9437, s32[] %constant.9443), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9444 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9446 = f32[] convert(s32[] %constant.9437), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9447 = f32[] divide(f32[] %constant.9444, f32[] %convert.9446), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9445 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9449 = f32[] select(pred[] %compare.9448, f32[] %divide.9447, f32[] %constant.9445), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9450 = f32[1,310]{1,0} broadcast(f32[] %select.9449), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9451 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9442, f32[1,310]{1,0} %broadcast.9450), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9452 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9451), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9453 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9452), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.240 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9454 = f32[] multiply(f32[] %p4.23, f32[] %constant.240), metadata={op_type="aten__add" op_name="aten__add.492/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9455 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9454), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.492/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9456 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9453, f32[1,310,1]{2,1,0} %broadcast.9455), metadata={op_type="aten__add" op_name="aten__add.492/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9457 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9456), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9458 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9457), metadata={op_type="aten__mul" op_name="aten__mul.493/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9459 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9458), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.493/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9460 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9433, f32[1,310,4096]{2,1,0} %broadcast.9459), metadata={op_type="aten__mul" op_name="aten__mul.493/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9461 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9460), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9462 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9461), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9466 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9465, f32[1,310,4096]{2,1,0} %convert.9462), metadata={op_type="aten__mul" op_name="aten__mul.494/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9467 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9466), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9474 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9467), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p574.9472 = bf16[14336,4096]{1,0} parameter(574), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.9473 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p574.9472), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9475 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9474, bf16[4096,14336]{0,1} %transpose.9473), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9476 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9475), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.9477 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.9476), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.9478 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.9476, bf16[1,310,14336]{2,1,0} %logistic.9477), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.9479 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.9478), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9468 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9467), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p66.238 = bf16[14336,4096]{1,0} parameter(66), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.239 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p66.238), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9469 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9468, bf16[4096,14336]{0,1} %transpose.239), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9470 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9469), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.9471 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.9470), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.9480 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.9479, f32[1,310,14336]{2,1,0} %convert.9471), metadata={op_type="aten__mul" op_name="aten__mul.495/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.9481 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.9480), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9482 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.9481), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p65.236 = bf16[4096,14336]{1,0} parameter(65), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.237 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p65.236), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9483 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.9482, bf16[14336,4096]{0,1} %transpose.237), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9484 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9483), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.235 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.9485 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.235), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.496/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.9486 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9484, bf16[1,310,4096]{2,1,0} %broadcast.9485), metadata={op_type="aten__add" op_name="aten__add.496/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.9487 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9432, bf16[1,310,4096]{2,1,0} %multiply.9486), metadata={op_type="aten__add" op_name="aten__add.496/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p575.9518 = bf16[4096]{0} parameter(575), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9519 = f32[4096]{0} convert(bf16[4096]{0} %p575.9518), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9520 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9519), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.499/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9488 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9487), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.234 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9489 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.234), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9490 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9488, f32[1,310,4096]{2,1,0} %broadcast.9489), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9491 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9497 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9490, f32[] %constant.9491), dimensions={2}, to_apply=%AddComputation.9493, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9492 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9498 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9503 = pred[] compare(s32[] %constant.9492, s32[] %constant.9498), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9499 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9501 = f32[] convert(s32[] %constant.9492), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9502 = f32[] divide(f32[] %constant.9499, f32[] %convert.9501), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9500 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9504 = f32[] select(pred[] %compare.9503, f32[] %divide.9502, f32[] %constant.9500), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9505 = f32[1,310]{1,0} broadcast(f32[] %select.9504), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9506 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9497, f32[1,310]{1,0} %broadcast.9505), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9507 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9506), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9508 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9507), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.233 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9509 = f32[] multiply(f32[] %p4.23, f32[] %constant.233), metadata={op_type="aten__add" op_name="aten__add.497/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9510 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9509), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.497/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9511 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9508, f32[1,310,1]{2,1,0} %broadcast.9510), metadata={op_type="aten__add" op_name="aten__add.497/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9512 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9511), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9513 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9512), metadata={op_type="aten__mul" op_name="aten__mul.498/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9514 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9513), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.498/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9515 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9488, f32[1,310,4096]{2,1,0} %broadcast.9514), metadata={op_type="aten__mul" op_name="aten__mul.498/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9516 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9515), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9517 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9516), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9521 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9520, f32[1,310,4096]{2,1,0} %convert.9517), metadata={op_type="aten__mul" op_name="aten__mul.499/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9522 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9521), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9523 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9522), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p64.231 = bf16[6144,4096]{1,0} parameter(64), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.232 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p64.231), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9524 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.9523, bf16[4096,6144]{0,1} %transpose.232), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9525 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.9524), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9526 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.9525), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.9611 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9526), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.9612 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9611), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.9613 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9612), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.9614 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.9613), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.9625 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.9614), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p577.9584 = bf16[32768,128]{1,0} parameter(577), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.9585 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p577.9584), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.9578 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9579 = s64[1,310]{1,0} broadcast(s64[] %constant.9578), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.9580 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9579), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9573 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9574 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9573), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9575 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9574), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9576 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9575), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.9577 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9576), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.9581 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9580, s64[1,310]{1,0} %add.9577, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9582 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9581), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.9583 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9582), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.9586 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9585, s64[1,310,1]{2,1,0} %concatenate.9583), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9587 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9586), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.9624 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9587), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9626 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9624), metadata={op_type="aten__mul" op_name="aten__mul.500/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9627 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9626), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.500/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9628 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.9625, f32[1,32,310,128]{3,2,1,0} %broadcast.9627), metadata={op_type="aten__mul" op_name="aten__mul.500/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9629 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9628), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.9616 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9614), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9617 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.9616), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9615 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9614), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9618 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.9617, bf16[1,32,310,64]{3,2,1,0} %slice.9615), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9619 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.9618), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p576.9555 = bf16[32768,128]{1,0} parameter(576), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.9556 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p576.9555), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.9549 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9550 = s64[1,310]{1,0} broadcast(s64[] %constant.9549), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.9551 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9550), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9544 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9545 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9544), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9546 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9545), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9547 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9546), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.9548 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9547), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.9552 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9551, s64[1,310]{1,0} %add.9548, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9553 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9552), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.9554 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9553), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.9557 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9556, s64[1,310,1]{2,1,0} %concatenate.9554), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9558 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9557), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.9610 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9558), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9620 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9610), metadata={op_type="aten__mul" op_name="aten__mul.501/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9621 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9620), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.501/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9622 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.9619, f32[1,32,310,128]{3,2,1,0} %broadcast.9621), metadata={op_type="aten__mul" op_name="aten__mul.501/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9623 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9622), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.9609 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9630 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.9609), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.502/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9631 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.9623, bf16[1,32,310,128]{3,2,1,0} %broadcast.9630), metadata={op_type="aten__add" op_name="aten__add.502/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.9632 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.9629, bf16[1,32,310,128]{3,2,1,0} %multiply.9631), metadata={op_type="aten__add" op_name="aten__add.502/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9633 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.9632), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9634 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9633), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.9560 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9526), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.9561 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9560), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.9562 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9561), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.9563 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9562), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.9589 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.9563), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9588 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9587), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9590 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9588), metadata={op_type="aten__mul" op_name="aten__mul.503/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9591 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9590), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.503/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9592 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.9589, f32[1,8,310,128]{3,2,1,0} %broadcast.9591), metadata={op_type="aten__mul" op_name="aten__mul.503/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9593 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9592), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9565 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9563), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9566 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.9565), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9564 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9563), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9567 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.9566, bf16[1,8,310,64]{3,2,1,0} %slice.9564), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9568 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.9567), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9559 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9558), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9569 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9559), metadata={op_type="aten__mul" op_name="aten__mul.504/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9570 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9569), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.504/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9571 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.9568, f32[1,8,310,128]{3,2,1,0} %broadcast.9570), metadata={op_type="aten__mul" op_name="aten__mul.504/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9572 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9571), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.9543 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9594 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.9543), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.505/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9595 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.9572, bf16[1,8,310,128]{3,2,1,0} %broadcast.9594), metadata={op_type="aten__add" op_name="aten__add.505/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.9596 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.9593, bf16[1,8,310,128]{3,2,1,0} %multiply.9595), metadata={op_type="aten__add" op_name="aten__add.505/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9597 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.9596), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9598 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9597), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9599 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9598), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9600 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9599), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9601 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9600), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9602 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9601), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9603 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9602), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9604 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9603), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9605 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9604), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.9606 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9605), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9607 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.9606), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9608 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.9607), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.9635 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.9634, bf16[32,128,310]{2,1,0} %reshape.9608), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9636 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.9635), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9637 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.9638 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.9636, bf16[1,32,310,310]{3,2,1,0} %broadcast.9637), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.9542 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9639 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.9542), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.506/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.9640 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.9639), metadata={op_type="aten__add" op_name="aten__add.506/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.9641 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.9640), metadata={op_type="aten__add" op_name="aten__add.506/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9642 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.9641), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.506/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.9643 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.9638, bf16[1,32,310,310]{3,2,1,0} %broadcast.9642), metadata={op_type="aten__add" op_name="aten__add.506/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.9644 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.9643), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9645 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9650 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.9644, f32[] %constant.9645), dimensions={3}, to_apply=%MaxComputation.9646, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9651 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9650), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.9652 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.9644, f32[1,32,310,310]{3,2,1,0} %broadcast.9651), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.9653 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.9652), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9654 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9659 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.9653, f32[] %constant.9654), dimensions={3}, to_apply=%AddComputation.9655, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9660 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9659), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.9661 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.9653, f32[1,32,310,310]{3,2,1,0} %broadcast.9660), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.9662 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.9661), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.9663 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.9662), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9664 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.9663), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.9527 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9526), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.9528 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9527), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.9529 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9528), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.9530 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9529), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.9531 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9530), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9532 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9531), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9533 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9532), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9534 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9533), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9535 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9534), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9536 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9535), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9537 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9536), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9538 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9537), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9539 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9538), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.9540 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.9539), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9541 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9540), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.9665 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.9664, bf16[32,310,128]{2,1,0} %reshape.9541), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9666 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.9665), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.9667 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9666), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.9668 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.9667), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.9669 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.9668), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p63.229 = bf16[4096,4096]{1,0} parameter(63), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.230 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p63.229), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9670 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.9669, bf16[4096,4096]{0,1} %transpose.230), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9671 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9670), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.228 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.9672 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.228), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.507/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.9673 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9671, bf16[1,310,4096]{2,1,0} %broadcast.9672), metadata={op_type="aten__add" op_name="aten__add.507/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.9674 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9487, bf16[1,310,4096]{2,1,0} %multiply.9673), metadata={op_type="aten__add" op_name="aten__add.507/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p578.9705 = bf16[4096]{0} parameter(578), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9706 = f32[4096]{0} convert(bf16[4096]{0} %p578.9705), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9707 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9706), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.510/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9675 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9674), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.227 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9676 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.227), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9677 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9675, f32[1,310,4096]{2,1,0} %broadcast.9676), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9678 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9684 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9677, f32[] %constant.9678), dimensions={2}, to_apply=%AddComputation.9680, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9679 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9685 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9690 = pred[] compare(s32[] %constant.9679, s32[] %constant.9685), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9686 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9688 = f32[] convert(s32[] %constant.9679), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9689 = f32[] divide(f32[] %constant.9686, f32[] %convert.9688), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9687 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9691 = f32[] select(pred[] %compare.9690, f32[] %divide.9689, f32[] %constant.9687), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9692 = f32[1,310]{1,0} broadcast(f32[] %select.9691), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9693 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9684, f32[1,310]{1,0} %broadcast.9692), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9694 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9693), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9695 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9694), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.226 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9696 = f32[] multiply(f32[] %p4.23, f32[] %constant.226), metadata={op_type="aten__add" op_name="aten__add.508/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9697 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9696), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.508/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9698 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9695, f32[1,310,1]{2,1,0} %broadcast.9697), metadata={op_type="aten__add" op_name="aten__add.508/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9699 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9698), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9700 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9699), metadata={op_type="aten__mul" op_name="aten__mul.509/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9701 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9700), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.509/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9702 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9675, f32[1,310,4096]{2,1,0} %broadcast.9701), metadata={op_type="aten__mul" op_name="aten__mul.509/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9703 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9702), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9704 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9703), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9708 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9707, f32[1,310,4096]{2,1,0} %convert.9704), metadata={op_type="aten__mul" op_name="aten__mul.510/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9709 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9708), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9716 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9709), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p579.9714 = bf16[14336,4096]{1,0} parameter(579), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.9715 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p579.9714), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9717 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9716, bf16[4096,14336]{0,1} %transpose.9715), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9718 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9717), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.9719 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.9718), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.9720 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.9718, bf16[1,310,14336]{2,1,0} %logistic.9719), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.9721 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.9720), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9710 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9709), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p62.224 = bf16[14336,4096]{1,0} parameter(62), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.225 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p62.224), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9711 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9710, bf16[4096,14336]{0,1} %transpose.225), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9712 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9711), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.9713 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.9712), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.9722 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.9721, f32[1,310,14336]{2,1,0} %convert.9713), metadata={op_type="aten__mul" op_name="aten__mul.511/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.9723 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.9722), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9724 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.9723), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p61.222 = bf16[4096,14336]{1,0} parameter(61), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.223 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p61.222), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9725 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.9724, bf16[14336,4096]{0,1} %transpose.223), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9726 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9725), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.221 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.9727 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.221), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.512/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.9728 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9726, bf16[1,310,4096]{2,1,0} %broadcast.9727), metadata={op_type="aten__add" op_name="aten__add.512/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.9729 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9674, bf16[1,310,4096]{2,1,0} %multiply.9728), metadata={op_type="aten__add" op_name="aten__add.512/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p580.9760 = bf16[4096]{0} parameter(580), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9761 = f32[4096]{0} convert(bf16[4096]{0} %p580.9760), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9762 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9761), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.515/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9730 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9729), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.220 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9731 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.220), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9732 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9730, f32[1,310,4096]{2,1,0} %broadcast.9731), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9733 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9739 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9732, f32[] %constant.9733), dimensions={2}, to_apply=%AddComputation.9735, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9734 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9740 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9745 = pred[] compare(s32[] %constant.9734, s32[] %constant.9740), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9741 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9743 = f32[] convert(s32[] %constant.9734), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9744 = f32[] divide(f32[] %constant.9741, f32[] %convert.9743), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9742 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9746 = f32[] select(pred[] %compare.9745, f32[] %divide.9744, f32[] %constant.9742), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9747 = f32[1,310]{1,0} broadcast(f32[] %select.9746), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9748 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9739, f32[1,310]{1,0} %broadcast.9747), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9749 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9748), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9750 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9749), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.219 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9751 = f32[] multiply(f32[] %p4.23, f32[] %constant.219), metadata={op_type="aten__add" op_name="aten__add.513/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9752 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9751), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.513/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9753 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9750, f32[1,310,1]{2,1,0} %broadcast.9752), metadata={op_type="aten__add" op_name="aten__add.513/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9754 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9753), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9755 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9754), metadata={op_type="aten__mul" op_name="aten__mul.514/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9756 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9755), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.514/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9757 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9730, f32[1,310,4096]{2,1,0} %broadcast.9756), metadata={op_type="aten__mul" op_name="aten__mul.514/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9758 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9757), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9759 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9758), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9763 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9762, f32[1,310,4096]{2,1,0} %convert.9759), metadata={op_type="aten__mul" op_name="aten__mul.515/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9764 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9763), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9765 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9764), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p60.217 = bf16[6144,4096]{1,0} parameter(60), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.218 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p60.217), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9766 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.9765, bf16[4096,6144]{0,1} %transpose.218), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9767 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.9766), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9768 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.9767), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.9853 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9768), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.9854 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9853), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.9855 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.9854), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.9856 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.9855), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.9867 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.9856), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p582.9826 = bf16[32768,128]{1,0} parameter(582), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.9827 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p582.9826), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.9820 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9821 = s64[1,310]{1,0} broadcast(s64[] %constant.9820), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.9822 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9821), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9815 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9816 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9815), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9817 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9816), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.9818 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9817), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.9819 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9818), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.9823 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9822, s64[1,310]{1,0} %add.9819, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9824 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9823), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.9825 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9824), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.9828 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9827, s64[1,310,1]{2,1,0} %concatenate.9825), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.9829 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9828), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.9866 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9829), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9868 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9866), metadata={op_type="aten__mul" op_name="aten__mul.516/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9869 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9868), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.516/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9870 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.9867, f32[1,32,310,128]{3,2,1,0} %broadcast.9869), metadata={op_type="aten__mul" op_name="aten__mul.516/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9871 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9870), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.9858 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9856), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9859 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.9858), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9857 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.9856), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9860 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.9859, bf16[1,32,310,64]{3,2,1,0} %slice.9857), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9861 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.9860), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p581.9797 = bf16[32768,128]{1,0} parameter(581), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.9798 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p581.9797), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.9791 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9792 = s64[1,310]{1,0} broadcast(s64[] %constant.9791), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.9793 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9792), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9786 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9787 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.9786), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9788 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.9787), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.9789 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.9788), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.9790 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.9789), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.9794 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.9793, s64[1,310]{1,0} %add.9790, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9795 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.9794), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.9796 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.9795), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.9799 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.9798, s64[1,310,1]{2,1,0} %concatenate.9796), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.9800 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.9799), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.9852 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9800), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.9862 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9852), metadata={op_type="aten__mul" op_name="aten__mul.517/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9863 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9862), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.517/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9864 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.9861, f32[1,32,310,128]{3,2,1,0} %broadcast.9863), metadata={op_type="aten__mul" op_name="aten__mul.517/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.9865 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.9864), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.9851 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9872 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.9851), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.518/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.9873 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.9865, bf16[1,32,310,128]{3,2,1,0} %broadcast.9872), metadata={op_type="aten__add" op_name="aten__add.518/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.9874 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.9871, bf16[1,32,310,128]{3,2,1,0} %multiply.9873), metadata={op_type="aten__add" op_name="aten__add.518/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.9875 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.9874), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9876 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9875), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.9802 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9768), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.9803 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9802), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.9804 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9803), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.9805 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9804), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.9831 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.9805), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9830 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9829), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9832 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9830), metadata={op_type="aten__mul" op_name="aten__mul.519/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9833 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9832), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.519/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9834 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.9831, f32[1,8,310,128]{3,2,1,0} %broadcast.9833), metadata={op_type="aten__mul" op_name="aten__mul.519/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9835 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9834), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9807 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9805), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.9808 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.9807), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.9806 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9805), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.9809 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.9808, bf16[1,8,310,64]{3,2,1,0} %slice.9806), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.9810 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.9809), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9801 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.9800), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.9811 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.9801), metadata={op_type="aten__mul" op_name="aten__mul.520/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9812 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.9811), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.520/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9813 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.9810, f32[1,8,310,128]{3,2,1,0} %broadcast.9812), metadata={op_type="aten__mul" op_name="aten__mul.520/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.9814 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.9813), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.9785 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.9836 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.9785), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.9837 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.9814, bf16[1,8,310,128]{3,2,1,0} %broadcast.9836), metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.9838 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.9835, bf16[1,8,310,128]{3,2,1,0} %multiply.9837), metadata={op_type="aten__add" op_name="aten__add.521/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.9839 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.9838), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9840 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9839), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9841 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9840), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9842 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9841), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9843 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9842), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9844 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9843), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9845 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9844), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9846 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9845), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9847 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9846), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.9848 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9847), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9849 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.9848), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9850 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.9849), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.9877 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.9876, bf16[32,128,310]{2,1,0} %reshape.9850), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.9878 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.9877), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.9879 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.9880 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.9878, bf16[1,32,310,310]{3,2,1,0} %broadcast.9879), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.9784 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9881 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.9784), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.522/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.9882 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.9881), metadata={op_type="aten__add" op_name="aten__add.522/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.9883 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.9882), metadata={op_type="aten__add" op_name="aten__add.522/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.9884 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.9883), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.522/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.9885 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.9880, bf16[1,32,310,310]{3,2,1,0} %broadcast.9884), metadata={op_type="aten__add" op_name="aten__add.522/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.9886 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.9885), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9887 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9892 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.9886, f32[] %constant.9887), dimensions={3}, to_apply=%MaxComputation.9888, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9893 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9892), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.9894 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.9886, f32[1,32,310,310]{3,2,1,0} %broadcast.9893), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.9895 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.9894), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.9896 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.9901 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.9895, f32[] %constant.9896), dimensions={3}, to_apply=%AddComputation.9897, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.9902 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.9901), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.9903 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.9895, f32[1,32,310,310]{3,2,1,0} %broadcast.9902), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.9904 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.9903), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.9905 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.9904), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9906 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.9905), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.9769 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.9768), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.9770 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.9769), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.9771 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.9770), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.9772 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.9771), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.9773 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.9772), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9774 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.9773), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9775 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.9774), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9776 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.9775), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.9777 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9776), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9778 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.9777), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9779 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.9778), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.9780 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.9779), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.9781 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.9780), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.9782 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.9781), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9783 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.9782), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.9907 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.9906, bf16[32,310,128]{2,1,0} %reshape.9783), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.9908 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.9907), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.9909 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.9908), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.9910 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.9909), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.9911 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.9910), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p59.215 = bf16[4096,4096]{1,0} parameter(59), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.216 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p59.215), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9912 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.9911, bf16[4096,4096]{0,1} %transpose.216), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9913 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9912), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.214 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.9914 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.214), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.523/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.9915 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9913, bf16[1,310,4096]{2,1,0} %broadcast.9914), metadata={op_type="aten__add" op_name="aten__add.523/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.9916 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9729, bf16[1,310,4096]{2,1,0} %multiply.9915), metadata={op_type="aten__add" op_name="aten__add.523/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p583.9947 = bf16[4096]{0} parameter(583), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.9948 = f32[4096]{0} convert(bf16[4096]{0} %p583.9947), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.9949 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.9948), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.526/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9917 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9916), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.213 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9918 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.213), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9919 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9917, f32[1,310,4096]{2,1,0} %broadcast.9918), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9920 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9926 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9919, f32[] %constant.9920), dimensions={2}, to_apply=%AddComputation.9922, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9921 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9927 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9932 = pred[] compare(s32[] %constant.9921, s32[] %constant.9927), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9928 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9930 = f32[] convert(s32[] %constant.9921), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9931 = f32[] divide(f32[] %constant.9928, f32[] %convert.9930), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9929 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9933 = f32[] select(pred[] %compare.9932, f32[] %divide.9931, f32[] %constant.9929), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9934 = f32[1,310]{1,0} broadcast(f32[] %select.9933), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9935 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9926, f32[1,310]{1,0} %broadcast.9934), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9936 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9935), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9937 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9936), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.212 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9938 = f32[] multiply(f32[] %p4.23, f32[] %constant.212), metadata={op_type="aten__add" op_name="aten__add.524/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9939 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9938), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.524/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9940 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9937, f32[1,310,1]{2,1,0} %broadcast.9939), metadata={op_type="aten__add" op_name="aten__add.524/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9941 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9940), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9942 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9941), metadata={op_type="aten__mul" op_name="aten__mul.525/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9943 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9942), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.525/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9944 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9917, f32[1,310,4096]{2,1,0} %broadcast.9943), metadata={op_type="aten__mul" op_name="aten__mul.525/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.9945 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9944), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9946 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.9945), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.9950 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.9949, f32[1,310,4096]{2,1,0} %convert.9946), metadata={op_type="aten__mul" op_name="aten__mul.526/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9951 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9950), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.9958 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9951), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p584.9956 = bf16[14336,4096]{1,0} parameter(584), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.9957 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p584.9956), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9959 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9958, bf16[4096,14336]{0,1} %transpose.9957), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9960 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9959), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.9961 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.9960), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.9962 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.9960, bf16[1,310,14336]{2,1,0} %logistic.9961), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.9963 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.9962), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9952 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.9951), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p58.210 = bf16[14336,4096]{1,0} parameter(58), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.211 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p58.210), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9953 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.9952, bf16[4096,14336]{0,1} %transpose.211), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9954 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.9953), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.9955 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.9954), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.9964 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.9963, f32[1,310,14336]{2,1,0} %convert.9955), metadata={op_type="aten__mul" op_name="aten__mul.527/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.9965 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.9964), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.9966 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.9965), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p57.208 = bf16[4096,14336]{1,0} parameter(57), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.209 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p57.208), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.9967 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.9966, bf16[14336,4096]{0,1} %transpose.209), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.9968 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.9967), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.207 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.9969 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.207), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.528/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.9970 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.9968, bf16[1,310,4096]{2,1,0} %broadcast.9969), metadata={op_type="aten__add" op_name="aten__add.528/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.9971 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9916, bf16[1,310,4096]{2,1,0} %multiply.9970), metadata={op_type="aten__add" op_name="aten__add.528/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p585.10002 = bf16[4096]{0} parameter(585), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10003 = f32[4096]{0} convert(bf16[4096]{0} %p585.10002), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10004 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10003), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.531/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.9972 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.9971), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.206 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9973 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.206), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.9974 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.9972, f32[1,310,4096]{2,1,0} %broadcast.9973), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9975 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.9981 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.9974, f32[] %constant.9975), dimensions={2}, to_apply=%AddComputation.9977, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9976 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9982 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.9987 = pred[] compare(s32[] %constant.9976, s32[] %constant.9982), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9983 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9985 = f32[] convert(s32[] %constant.9976), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.9986 = f32[] divide(f32[] %constant.9983, f32[] %convert.9985), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.9984 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.9988 = f32[] select(pred[] %compare.9987, f32[] %divide.9986, f32[] %constant.9984), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.9989 = f32[1,310]{1,0} broadcast(f32[] %select.9988), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.9990 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.9981, f32[1,310]{1,0} %broadcast.9989), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.9991 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.9990), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.9992 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.9991), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.205 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9993 = f32[] multiply(f32[] %p4.23, f32[] %constant.205), metadata={op_type="aten__add" op_name="aten__add.529/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9994 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.9993), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.529/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.9995 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.9992, f32[1,310,1]{2,1,0} %broadcast.9994), metadata={op_type="aten__add" op_name="aten__add.529/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.9996 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.9995), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.9997 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.9996), metadata={op_type="aten__mul" op_name="aten__mul.530/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.9998 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.9997), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.530/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.9999 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.9972, f32[1,310,4096]{2,1,0} %broadcast.9998), metadata={op_type="aten__mul" op_name="aten__mul.530/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10000 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.9999), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10001 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10000), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10005 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10004, f32[1,310,4096]{2,1,0} %convert.10001), metadata={op_type="aten__mul" op_name="aten__mul.531/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10006 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10005), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10007 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10006), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p56.203 = bf16[6144,4096]{1,0} parameter(56), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.204 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p56.203), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10008 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.10007, bf16[4096,6144]{0,1} %transpose.204), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10009 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.10008), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10010 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.10009), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.10095 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10010), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.10096 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10095), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.10097 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10096), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.10098 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.10097), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.10109 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.10098), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p587.10068 = bf16[32768,128]{1,0} parameter(587), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.10069 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p587.10068), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.10062 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10063 = s64[1,310]{1,0} broadcast(s64[] %constant.10062), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.10064 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10063), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10057 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10058 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10057), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10059 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10058), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10060 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10059), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.10061 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10060), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.10065 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10064, s64[1,310]{1,0} %add.10061, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10066 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10065), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.10067 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10066), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.10070 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10069, s64[1,310,1]{2,1,0} %concatenate.10067), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10071 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10070), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.10108 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10071), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10110 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10108), metadata={op_type="aten__mul" op_name="aten__mul.532/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10111 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10110), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.532/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10112 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.10109, f32[1,32,310,128]{3,2,1,0} %broadcast.10111), metadata={op_type="aten__mul" op_name="aten__mul.532/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10113 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10112), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.10100 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10098), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10101 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.10100), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10099 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10098), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10102 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.10101, bf16[1,32,310,64]{3,2,1,0} %slice.10099), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10103 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.10102), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p586.10039 = bf16[32768,128]{1,0} parameter(586), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.10040 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p586.10039), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.10033 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10034 = s64[1,310]{1,0} broadcast(s64[] %constant.10033), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.10035 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10034), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10028 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10029 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10028), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10030 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10029), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10031 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10030), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.10032 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10031), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.10036 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10035, s64[1,310]{1,0} %add.10032, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10037 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10036), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.10038 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10037), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.10041 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10040, s64[1,310,1]{2,1,0} %concatenate.10038), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10042 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10041), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.10094 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10042), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10104 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10094), metadata={op_type="aten__mul" op_name="aten__mul.533/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10105 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10104), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.533/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10106 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.10103, f32[1,32,310,128]{3,2,1,0} %broadcast.10105), metadata={op_type="aten__mul" op_name="aten__mul.533/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10107 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10106), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.10093 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10114 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.10093), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.534/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10115 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.10107, bf16[1,32,310,128]{3,2,1,0} %broadcast.10114), metadata={op_type="aten__add" op_name="aten__add.534/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.10116 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.10113, bf16[1,32,310,128]{3,2,1,0} %multiply.10115), metadata={op_type="aten__add" op_name="aten__add.534/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10117 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.10116), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10118 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10117), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.10044 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10010), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.10045 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10044), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.10046 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10045), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.10047 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10046), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.10073 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.10047), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10072 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10071), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10074 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10072), metadata={op_type="aten__mul" op_name="aten__mul.535/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10075 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10074), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.535/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10076 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.10073, f32[1,8,310,128]{3,2,1,0} %broadcast.10075), metadata={op_type="aten__mul" op_name="aten__mul.535/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10077 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10076), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10049 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10047), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10050 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.10049), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10048 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10047), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10051 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.10050, bf16[1,8,310,64]{3,2,1,0} %slice.10048), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10052 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.10051), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10043 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10042), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10053 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10043), metadata={op_type="aten__mul" op_name="aten__mul.536/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10054 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10053), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.536/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10055 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.10052, f32[1,8,310,128]{3,2,1,0} %broadcast.10054), metadata={op_type="aten__mul" op_name="aten__mul.536/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10056 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10055), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.10027 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10078 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.10027), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.537/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10079 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.10056, bf16[1,8,310,128]{3,2,1,0} %broadcast.10078), metadata={op_type="aten__add" op_name="aten__add.537/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.10080 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.10077, bf16[1,8,310,128]{3,2,1,0} %multiply.10079), metadata={op_type="aten__add" op_name="aten__add.537/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10081 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.10080), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10082 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10081), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10083 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10082), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10084 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10083), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10085 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10084), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10086 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10085), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10087 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10086), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10088 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10087), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10089 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10088), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.10090 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10089), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10091 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.10090), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10092 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.10091), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.10119 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.10118, bf16[32,128,310]{2,1,0} %reshape.10092), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10120 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.10119), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10121 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.10122 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.10120, bf16[1,32,310,310]{3,2,1,0} %broadcast.10121), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.10026 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10123 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.10026), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.10124 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.10123), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.10125 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.10124), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10126 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.10125), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.10127 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.10122, bf16[1,32,310,310]{3,2,1,0} %broadcast.10126), metadata={op_type="aten__add" op_name="aten__add.538/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.10128 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.10127), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10129 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10134 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.10128, f32[] %constant.10129), dimensions={3}, to_apply=%MaxComputation.10130, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10135 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10134), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.10136 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.10128, f32[1,32,310,310]{3,2,1,0} %broadcast.10135), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.10137 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.10136), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10138 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10143 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.10137, f32[] %constant.10138), dimensions={3}, to_apply=%AddComputation.10139, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10144 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10143), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.10145 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.10137, f32[1,32,310,310]{3,2,1,0} %broadcast.10144), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.10146 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.10145), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.10147 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.10146), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10148 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.10147), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.10011 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10010), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.10012 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10011), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.10013 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10012), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.10014 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10013), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.10015 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10014), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10016 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10015), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10017 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10016), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10018 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10017), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10019 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10018), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10020 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10019), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10021 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10020), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10022 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10021), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10023 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10022), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.10024 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.10023), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10025 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10024), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.10149 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.10148, bf16[32,310,128]{2,1,0} %reshape.10025), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10150 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.10149), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.10151 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10150), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.10152 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.10151), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.10153 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.10152), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p55.201 = bf16[4096,4096]{1,0} parameter(55), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.202 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p55.201), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10154 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.10153, bf16[4096,4096]{0,1} %transpose.202), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10155 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10154), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.200 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.10156 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.200), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.539/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.10157 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10155, bf16[1,310,4096]{2,1,0} %broadcast.10156), metadata={op_type="aten__add" op_name="aten__add.539/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.10158 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.9971, bf16[1,310,4096]{2,1,0} %multiply.10157), metadata={op_type="aten__add" op_name="aten__add.539/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p588.10189 = bf16[4096]{0} parameter(588), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10190 = f32[4096]{0} convert(bf16[4096]{0} %p588.10189), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10191 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10190), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.542/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10159 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10158), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.199 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10160 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.199), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10161 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10159, f32[1,310,4096]{2,1,0} %broadcast.10160), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10162 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10168 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10161, f32[] %constant.10162), dimensions={2}, to_apply=%AddComputation.10164, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10163 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10169 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10174 = pred[] compare(s32[] %constant.10163, s32[] %constant.10169), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10170 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10172 = f32[] convert(s32[] %constant.10163), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10173 = f32[] divide(f32[] %constant.10170, f32[] %convert.10172), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10171 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10175 = f32[] select(pred[] %compare.10174, f32[] %divide.10173, f32[] %constant.10171), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10176 = f32[1,310]{1,0} broadcast(f32[] %select.10175), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10177 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10168, f32[1,310]{1,0} %broadcast.10176), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10178 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10177), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10179 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10178), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.198 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10180 = f32[] multiply(f32[] %p4.23, f32[] %constant.198), metadata={op_type="aten__add" op_name="aten__add.540/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10181 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10180), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.540/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10182 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10179, f32[1,310,1]{2,1,0} %broadcast.10181), metadata={op_type="aten__add" op_name="aten__add.540/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10183 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10182), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10184 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10183), metadata={op_type="aten__mul" op_name="aten__mul.541/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10185 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10184), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.541/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10186 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10159, f32[1,310,4096]{2,1,0} %broadcast.10185), metadata={op_type="aten__mul" op_name="aten__mul.541/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10187 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10186), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10188 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10187), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10192 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10191, f32[1,310,4096]{2,1,0} %convert.10188), metadata={op_type="aten__mul" op_name="aten__mul.542/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10193 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10192), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10200 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10193), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p589.10198 = bf16[14336,4096]{1,0} parameter(589), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.10199 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p589.10198), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10201 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10200, bf16[4096,14336]{0,1} %transpose.10199), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10202 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10201), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.10203 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.10202), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.10204 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.10202, bf16[1,310,14336]{2,1,0} %logistic.10203), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.10205 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.10204), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10194 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10193), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p54.196 = bf16[14336,4096]{1,0} parameter(54), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.197 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p54.196), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10195 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10194, bf16[4096,14336]{0,1} %transpose.197), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10196 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10195), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.10197 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.10196), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.10206 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.10205, f32[1,310,14336]{2,1,0} %convert.10197), metadata={op_type="aten__mul" op_name="aten__mul.543/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.10207 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.10206), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10208 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.10207), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p53.194 = bf16[4096,14336]{1,0} parameter(53), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.195 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p53.194), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10209 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.10208, bf16[14336,4096]{0,1} %transpose.195), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10210 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10209), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.193 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.10211 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.193), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.544/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.10212 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10210, bf16[1,310,4096]{2,1,0} %broadcast.10211), metadata={op_type="aten__add" op_name="aten__add.544/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.10213 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10158, bf16[1,310,4096]{2,1,0} %multiply.10212), metadata={op_type="aten__add" op_name="aten__add.544/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p590.10244 = bf16[4096]{0} parameter(590), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10245 = f32[4096]{0} convert(bf16[4096]{0} %p590.10244), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10246 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10245), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.547/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10214 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10213), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.192 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10215 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.192), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10216 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10214, f32[1,310,4096]{2,1,0} %broadcast.10215), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10217 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10223 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10216, f32[] %constant.10217), dimensions={2}, to_apply=%AddComputation.10219, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10218 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10224 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10229 = pred[] compare(s32[] %constant.10218, s32[] %constant.10224), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10225 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10227 = f32[] convert(s32[] %constant.10218), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10228 = f32[] divide(f32[] %constant.10225, f32[] %convert.10227), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10226 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10230 = f32[] select(pred[] %compare.10229, f32[] %divide.10228, f32[] %constant.10226), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10231 = f32[1,310]{1,0} broadcast(f32[] %select.10230), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10232 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10223, f32[1,310]{1,0} %broadcast.10231), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10233 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10232), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10234 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10233), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.191 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10235 = f32[] multiply(f32[] %p4.23, f32[] %constant.191), metadata={op_type="aten__add" op_name="aten__add.545/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10236 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10235), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.545/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10237 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10234, f32[1,310,1]{2,1,0} %broadcast.10236), metadata={op_type="aten__add" op_name="aten__add.545/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10238 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10237), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10239 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10238), metadata={op_type="aten__mul" op_name="aten__mul.546/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10240 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10239), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.546/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10241 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10214, f32[1,310,4096]{2,1,0} %broadcast.10240), metadata={op_type="aten__mul" op_name="aten__mul.546/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10242 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10241), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10243 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10242), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10247 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10246, f32[1,310,4096]{2,1,0} %convert.10243), metadata={op_type="aten__mul" op_name="aten__mul.547/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10248 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10247), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10249 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10248), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p52.189 = bf16[6144,4096]{1,0} parameter(52), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.190 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p52.189), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10250 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.10249, bf16[4096,6144]{0,1} %transpose.190), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10251 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.10250), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10252 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.10251), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.10337 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10252), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.10338 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10337), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.10339 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10338), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.10340 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.10339), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.10351 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.10340), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p592.10310 = bf16[32768,128]{1,0} parameter(592), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.10311 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p592.10310), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.10304 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10305 = s64[1,310]{1,0} broadcast(s64[] %constant.10304), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.10306 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10305), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10299 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10300 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10299), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10301 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10300), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10302 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10301), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.10303 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10302), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.10307 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10306, s64[1,310]{1,0} %add.10303, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10308 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10307), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.10309 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10308), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.10312 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10311, s64[1,310,1]{2,1,0} %concatenate.10309), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10313 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10312), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.10350 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10313), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10352 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10350), metadata={op_type="aten__mul" op_name="aten__mul.548/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10353 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10352), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.548/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10354 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.10351, f32[1,32,310,128]{3,2,1,0} %broadcast.10353), metadata={op_type="aten__mul" op_name="aten__mul.548/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10355 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10354), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.10342 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10340), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10343 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.10342), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10341 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10340), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10344 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.10343, bf16[1,32,310,64]{3,2,1,0} %slice.10341), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10345 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.10344), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p591.10281 = bf16[32768,128]{1,0} parameter(591), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.10282 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p591.10281), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.10275 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10276 = s64[1,310]{1,0} broadcast(s64[] %constant.10275), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.10277 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10276), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10270 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10271 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10270), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10272 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10271), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10273 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10272), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.10274 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10273), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.10278 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10277, s64[1,310]{1,0} %add.10274, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10279 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10278), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.10280 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10279), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.10283 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10282, s64[1,310,1]{2,1,0} %concatenate.10280), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10284 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10283), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.10336 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10284), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10346 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10336), metadata={op_type="aten__mul" op_name="aten__mul.549/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10347 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10346), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.549/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10348 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.10345, f32[1,32,310,128]{3,2,1,0} %broadcast.10347), metadata={op_type="aten__mul" op_name="aten__mul.549/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10349 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10348), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.10335 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10356 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.10335), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.550/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10357 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.10349, bf16[1,32,310,128]{3,2,1,0} %broadcast.10356), metadata={op_type="aten__add" op_name="aten__add.550/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.10358 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.10355, bf16[1,32,310,128]{3,2,1,0} %multiply.10357), metadata={op_type="aten__add" op_name="aten__add.550/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10359 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.10358), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10360 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10359), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.10286 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10252), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.10287 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10286), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.10288 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10287), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.10289 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10288), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.10315 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.10289), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10314 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10313), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10316 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10314), metadata={op_type="aten__mul" op_name="aten__mul.551/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10317 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10316), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.551/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10318 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.10315, f32[1,8,310,128]{3,2,1,0} %broadcast.10317), metadata={op_type="aten__mul" op_name="aten__mul.551/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10319 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10318), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10291 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10289), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10292 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.10291), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10290 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10289), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10293 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.10292, bf16[1,8,310,64]{3,2,1,0} %slice.10290), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10294 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.10293), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10285 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10284), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10295 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10285), metadata={op_type="aten__mul" op_name="aten__mul.552/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10296 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10295), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.552/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10297 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.10294, f32[1,8,310,128]{3,2,1,0} %broadcast.10296), metadata={op_type="aten__mul" op_name="aten__mul.552/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10298 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10297), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.10269 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10320 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.10269), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.553/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10321 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.10298, bf16[1,8,310,128]{3,2,1,0} %broadcast.10320), metadata={op_type="aten__add" op_name="aten__add.553/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.10322 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.10319, bf16[1,8,310,128]{3,2,1,0} %multiply.10321), metadata={op_type="aten__add" op_name="aten__add.553/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10323 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.10322), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10324 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10323), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10325 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10324), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10326 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10325), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10327 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10326), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10328 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10327), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10329 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10328), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10330 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10329), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10331 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10330), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.10332 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10331), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10333 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.10332), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10334 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.10333), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.10361 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.10360, bf16[32,128,310]{2,1,0} %reshape.10334), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10362 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.10361), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10363 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.10364 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.10362, bf16[1,32,310,310]{3,2,1,0} %broadcast.10363), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.10268 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10365 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.10268), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.554/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.10366 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.10365), metadata={op_type="aten__add" op_name="aten__add.554/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.10367 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.10366), metadata={op_type="aten__add" op_name="aten__add.554/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10368 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.10367), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.554/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.10369 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.10364, bf16[1,32,310,310]{3,2,1,0} %broadcast.10368), metadata={op_type="aten__add" op_name="aten__add.554/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.10370 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.10369), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10371 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10376 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.10370, f32[] %constant.10371), dimensions={3}, to_apply=%MaxComputation.10372, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10377 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10376), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.10378 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.10370, f32[1,32,310,310]{3,2,1,0} %broadcast.10377), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.10379 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.10378), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10380 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10385 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.10379, f32[] %constant.10380), dimensions={3}, to_apply=%AddComputation.10381, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10386 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10385), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.10387 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.10379, f32[1,32,310,310]{3,2,1,0} %broadcast.10386), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.10388 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.10387), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.10389 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.10388), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10390 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.10389), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.10253 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10252), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.10254 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10253), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.10255 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10254), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.10256 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10255), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.10257 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10256), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10258 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10257), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10259 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10258), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10260 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10259), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10261 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10260), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10262 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10261), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10263 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10262), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10264 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10263), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10265 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10264), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.10266 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.10265), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10267 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10266), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.10391 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.10390, bf16[32,310,128]{2,1,0} %reshape.10267), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10392 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.10391), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.10393 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10392), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.10394 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.10393), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.10395 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.10394), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p51.187 = bf16[4096,4096]{1,0} parameter(51), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.188 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p51.187), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10396 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.10395, bf16[4096,4096]{0,1} %transpose.188), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10397 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10396), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.186 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.10398 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.186), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.555/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.10399 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10397, bf16[1,310,4096]{2,1,0} %broadcast.10398), metadata={op_type="aten__add" op_name="aten__add.555/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.10400 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10213, bf16[1,310,4096]{2,1,0} %multiply.10399), metadata={op_type="aten__add" op_name="aten__add.555/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p593.10431 = bf16[4096]{0} parameter(593), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10432 = f32[4096]{0} convert(bf16[4096]{0} %p593.10431), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10433 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10432), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.558/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10401 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10400), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.185 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10402 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.185), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10403 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10401, f32[1,310,4096]{2,1,0} %broadcast.10402), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10404 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10410 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10403, f32[] %constant.10404), dimensions={2}, to_apply=%AddComputation.10406, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10405 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10411 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10416 = pred[] compare(s32[] %constant.10405, s32[] %constant.10411), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10412 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10414 = f32[] convert(s32[] %constant.10405), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10415 = f32[] divide(f32[] %constant.10412, f32[] %convert.10414), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10413 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10417 = f32[] select(pred[] %compare.10416, f32[] %divide.10415, f32[] %constant.10413), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10418 = f32[1,310]{1,0} broadcast(f32[] %select.10417), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10419 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10410, f32[1,310]{1,0} %broadcast.10418), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10420 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10419), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10421 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10420), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.184 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10422 = f32[] multiply(f32[] %p4.23, f32[] %constant.184), metadata={op_type="aten__add" op_name="aten__add.556/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10423 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10422), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.556/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10424 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10421, f32[1,310,1]{2,1,0} %broadcast.10423), metadata={op_type="aten__add" op_name="aten__add.556/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10425 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10424), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10426 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10425), metadata={op_type="aten__mul" op_name="aten__mul.557/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10427 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10426), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.557/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10428 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10401, f32[1,310,4096]{2,1,0} %broadcast.10427), metadata={op_type="aten__mul" op_name="aten__mul.557/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10429 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10428), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10430 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10429), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10434 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10433, f32[1,310,4096]{2,1,0} %convert.10430), metadata={op_type="aten__mul" op_name="aten__mul.558/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10435 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10434), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10442 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10435), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p594.10440 = bf16[14336,4096]{1,0} parameter(594), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.10441 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p594.10440), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10443 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10442, bf16[4096,14336]{0,1} %transpose.10441), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10444 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10443), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.10445 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.10444), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.10446 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.10444, bf16[1,310,14336]{2,1,0} %logistic.10445), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.10447 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.10446), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10436 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10435), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p50.182 = bf16[14336,4096]{1,0} parameter(50), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.183 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p50.182), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10437 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10436, bf16[4096,14336]{0,1} %transpose.183), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10438 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10437), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.10439 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.10438), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.10448 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.10447, f32[1,310,14336]{2,1,0} %convert.10439), metadata={op_type="aten__mul" op_name="aten__mul.559/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.10449 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.10448), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10450 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.10449), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p49.180 = bf16[4096,14336]{1,0} parameter(49), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.181 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p49.180), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10451 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.10450, bf16[14336,4096]{0,1} %transpose.181), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10452 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10451), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.179 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.10453 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.179), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.560/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.10454 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10452, bf16[1,310,4096]{2,1,0} %broadcast.10453), metadata={op_type="aten__add" op_name="aten__add.560/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.10455 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10400, bf16[1,310,4096]{2,1,0} %multiply.10454), metadata={op_type="aten__add" op_name="aten__add.560/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p595.10486 = bf16[4096]{0} parameter(595), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10487 = f32[4096]{0} convert(bf16[4096]{0} %p595.10486), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10488 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10487), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.563/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10456 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10455), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.178 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10457 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.178), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10458 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10456, f32[1,310,4096]{2,1,0} %broadcast.10457), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10459 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10465 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10458, f32[] %constant.10459), dimensions={2}, to_apply=%AddComputation.10461, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10460 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10466 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10471 = pred[] compare(s32[] %constant.10460, s32[] %constant.10466), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10467 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10469 = f32[] convert(s32[] %constant.10460), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10470 = f32[] divide(f32[] %constant.10467, f32[] %convert.10469), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10468 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10472 = f32[] select(pred[] %compare.10471, f32[] %divide.10470, f32[] %constant.10468), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10473 = f32[1,310]{1,0} broadcast(f32[] %select.10472), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10474 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10465, f32[1,310]{1,0} %broadcast.10473), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10475 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10474), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10476 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10475), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.177 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10477 = f32[] multiply(f32[] %p4.23, f32[] %constant.177), metadata={op_type="aten__add" op_name="aten__add.561/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10478 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10477), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.561/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10479 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10476, f32[1,310,1]{2,1,0} %broadcast.10478), metadata={op_type="aten__add" op_name="aten__add.561/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10480 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10479), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10481 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10480), metadata={op_type="aten__mul" op_name="aten__mul.562/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10482 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10481), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.562/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10483 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10456, f32[1,310,4096]{2,1,0} %broadcast.10482), metadata={op_type="aten__mul" op_name="aten__mul.562/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10484 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10483), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10485 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10484), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10489 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10488, f32[1,310,4096]{2,1,0} %convert.10485), metadata={op_type="aten__mul" op_name="aten__mul.563/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10490 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10489), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10491 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10490), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p48.175 = bf16[6144,4096]{1,0} parameter(48), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.176 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p48.175), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10492 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.10491, bf16[4096,6144]{0,1} %transpose.176), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10493 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.10492), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10494 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.10493), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.10579 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10494), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.10580 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10579), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.10581 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10580), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.10582 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.10581), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.10593 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.10582), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p597.10552 = bf16[32768,128]{1,0} parameter(597), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.10553 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p597.10552), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.10546 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10547 = s64[1,310]{1,0} broadcast(s64[] %constant.10546), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.10548 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10547), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10541 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10542 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10541), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10543 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10542), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10544 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10543), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.10545 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10544), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.10549 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10548, s64[1,310]{1,0} %add.10545, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10550 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10549), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.10551 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10550), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.10554 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10553, s64[1,310,1]{2,1,0} %concatenate.10551), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10555 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10554), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.10592 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10555), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10594 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10592), metadata={op_type="aten__mul" op_name="aten__mul.564/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10595 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10594), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.564/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10596 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.10593, f32[1,32,310,128]{3,2,1,0} %broadcast.10595), metadata={op_type="aten__mul" op_name="aten__mul.564/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10597 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10596), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.10584 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10582), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10585 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.10584), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10583 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10582), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10586 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.10585, bf16[1,32,310,64]{3,2,1,0} %slice.10583), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10587 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.10586), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p596.10523 = bf16[32768,128]{1,0} parameter(596), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.10524 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p596.10523), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.10517 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10518 = s64[1,310]{1,0} broadcast(s64[] %constant.10517), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.10519 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10518), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10512 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10513 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10512), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10514 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10513), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10515 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10514), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.10516 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10515), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.10520 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10519, s64[1,310]{1,0} %add.10516, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10521 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10520), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.10522 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10521), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.10525 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10524, s64[1,310,1]{2,1,0} %concatenate.10522), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10526 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10525), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.10578 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10526), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10588 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10578), metadata={op_type="aten__mul" op_name="aten__mul.565/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10589 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10588), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.565/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10590 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.10587, f32[1,32,310,128]{3,2,1,0} %broadcast.10589), metadata={op_type="aten__mul" op_name="aten__mul.565/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10591 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10590), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.10577 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10598 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.10577), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.566/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10599 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.10591, bf16[1,32,310,128]{3,2,1,0} %broadcast.10598), metadata={op_type="aten__add" op_name="aten__add.566/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.10600 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.10597, bf16[1,32,310,128]{3,2,1,0} %multiply.10599), metadata={op_type="aten__add" op_name="aten__add.566/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10601 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.10600), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10602 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10601), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.10528 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10494), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.10529 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10528), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.10530 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10529), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.10531 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10530), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.10557 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.10531), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10556 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10555), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10558 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10556), metadata={op_type="aten__mul" op_name="aten__mul.567/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10559 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10558), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.567/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10560 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.10557, f32[1,8,310,128]{3,2,1,0} %broadcast.10559), metadata={op_type="aten__mul" op_name="aten__mul.567/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10561 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10560), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10533 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10531), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10534 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.10533), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10532 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10531), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10535 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.10534, bf16[1,8,310,64]{3,2,1,0} %slice.10532), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10536 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.10535), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10527 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10526), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10537 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10527), metadata={op_type="aten__mul" op_name="aten__mul.568/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10538 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10537), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.568/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10539 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.10536, f32[1,8,310,128]{3,2,1,0} %broadcast.10538), metadata={op_type="aten__mul" op_name="aten__mul.568/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10540 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10539), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.10511 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10562 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.10511), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.569/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10563 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.10540, bf16[1,8,310,128]{3,2,1,0} %broadcast.10562), metadata={op_type="aten__add" op_name="aten__add.569/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.10564 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.10561, bf16[1,8,310,128]{3,2,1,0} %multiply.10563), metadata={op_type="aten__add" op_name="aten__add.569/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10565 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.10564), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10566 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10565), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10567 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10566), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10568 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10567), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10569 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10568), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10570 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10569), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10571 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10570), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10572 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10571), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10573 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10572), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.10574 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10573), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10575 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.10574), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10576 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.10575), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.10603 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.10602, bf16[32,128,310]{2,1,0} %reshape.10576), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10604 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.10603), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10605 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.10606 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.10604, bf16[1,32,310,310]{3,2,1,0} %broadcast.10605), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.10510 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10607 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.10510), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.570/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.10608 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.10607), metadata={op_type="aten__add" op_name="aten__add.570/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.10609 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.10608), metadata={op_type="aten__add" op_name="aten__add.570/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10610 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.10609), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.570/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.10611 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.10606, bf16[1,32,310,310]{3,2,1,0} %broadcast.10610), metadata={op_type="aten__add" op_name="aten__add.570/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.10612 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.10611), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10613 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10618 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.10612, f32[] %constant.10613), dimensions={3}, to_apply=%MaxComputation.10614, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10619 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10618), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.10620 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.10612, f32[1,32,310,310]{3,2,1,0} %broadcast.10619), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.10621 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.10620), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10622 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10627 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.10621, f32[] %constant.10622), dimensions={3}, to_apply=%AddComputation.10623, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10628 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10627), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.10629 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.10621, f32[1,32,310,310]{3,2,1,0} %broadcast.10628), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.10630 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.10629), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.10631 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.10630), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10632 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.10631), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.10495 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10494), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.10496 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10495), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.10497 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10496), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.10498 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10497), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.10499 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10498), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10500 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10499), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10501 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10500), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10502 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10501), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10503 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10502), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10504 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10503), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10505 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10504), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10506 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10505), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10507 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10506), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.10508 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.10507), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10509 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10508), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.10633 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.10632, bf16[32,310,128]{2,1,0} %reshape.10509), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10634 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.10633), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.10635 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10634), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.10636 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.10635), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.10637 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.10636), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p47.173 = bf16[4096,4096]{1,0} parameter(47), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.174 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p47.173), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10638 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.10637, bf16[4096,4096]{0,1} %transpose.174), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10639 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10638), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.172 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.10640 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.172), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.571/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.10641 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10639, bf16[1,310,4096]{2,1,0} %broadcast.10640), metadata={op_type="aten__add" op_name="aten__add.571/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.10642 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10455, bf16[1,310,4096]{2,1,0} %multiply.10641), metadata={op_type="aten__add" op_name="aten__add.571/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p598.10673 = bf16[4096]{0} parameter(598), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10674 = f32[4096]{0} convert(bf16[4096]{0} %p598.10673), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10675 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10674), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.574/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10643 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10642), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.171 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10644 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.171), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10645 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10643, f32[1,310,4096]{2,1,0} %broadcast.10644), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10646 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10652 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10645, f32[] %constant.10646), dimensions={2}, to_apply=%AddComputation.10648, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10647 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10653 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10658 = pred[] compare(s32[] %constant.10647, s32[] %constant.10653), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10654 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10656 = f32[] convert(s32[] %constant.10647), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10657 = f32[] divide(f32[] %constant.10654, f32[] %convert.10656), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10655 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10659 = f32[] select(pred[] %compare.10658, f32[] %divide.10657, f32[] %constant.10655), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10660 = f32[1,310]{1,0} broadcast(f32[] %select.10659), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10661 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10652, f32[1,310]{1,0} %broadcast.10660), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10662 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10661), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10663 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10662), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.170 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10664 = f32[] multiply(f32[] %p4.23, f32[] %constant.170), metadata={op_type="aten__add" op_name="aten__add.572/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10665 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10664), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.572/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10666 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10663, f32[1,310,1]{2,1,0} %broadcast.10665), metadata={op_type="aten__add" op_name="aten__add.572/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10667 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10666), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10668 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10667), metadata={op_type="aten__mul" op_name="aten__mul.573/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10669 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10668), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.573/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10670 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10643, f32[1,310,4096]{2,1,0} %broadcast.10669), metadata={op_type="aten__mul" op_name="aten__mul.573/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10671 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10670), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10672 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10671), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10676 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10675, f32[1,310,4096]{2,1,0} %convert.10672), metadata={op_type="aten__mul" op_name="aten__mul.574/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10677 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10676), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10684 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10677), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p599.10682 = bf16[14336,4096]{1,0} parameter(599), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.10683 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p599.10682), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10685 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10684, bf16[4096,14336]{0,1} %transpose.10683), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10686 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10685), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.10687 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.10686), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.10688 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.10686, bf16[1,310,14336]{2,1,0} %logistic.10687), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.10689 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.10688), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10678 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10677), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p46.168 = bf16[14336,4096]{1,0} parameter(46), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.169 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p46.168), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10679 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10678, bf16[4096,14336]{0,1} %transpose.169), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10680 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10679), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.10681 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.10680), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.10690 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.10689, f32[1,310,14336]{2,1,0} %convert.10681), metadata={op_type="aten__mul" op_name="aten__mul.575/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.10691 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.10690), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10692 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.10691), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p45.166 = bf16[4096,14336]{1,0} parameter(45), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.167 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p45.166), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10693 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.10692, bf16[14336,4096]{0,1} %transpose.167), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10694 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10693), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.165 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.10695 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.165), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.576/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.10696 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10694, bf16[1,310,4096]{2,1,0} %broadcast.10695), metadata={op_type="aten__add" op_name="aten__add.576/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.10697 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10642, bf16[1,310,4096]{2,1,0} %multiply.10696), metadata={op_type="aten__add" op_name="aten__add.576/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p600.10728 = bf16[4096]{0} parameter(600), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10729 = f32[4096]{0} convert(bf16[4096]{0} %p600.10728), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10730 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10729), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.579/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10698 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10697), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.164 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10699 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.164), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10700 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10698, f32[1,310,4096]{2,1,0} %broadcast.10699), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10701 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10707 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10700, f32[] %constant.10701), dimensions={2}, to_apply=%AddComputation.10703, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10702 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10708 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10713 = pred[] compare(s32[] %constant.10702, s32[] %constant.10708), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10709 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10711 = f32[] convert(s32[] %constant.10702), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10712 = f32[] divide(f32[] %constant.10709, f32[] %convert.10711), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10710 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10714 = f32[] select(pred[] %compare.10713, f32[] %divide.10712, f32[] %constant.10710), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10715 = f32[1,310]{1,0} broadcast(f32[] %select.10714), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10716 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10707, f32[1,310]{1,0} %broadcast.10715), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10717 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10716), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10718 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10717), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.163 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10719 = f32[] multiply(f32[] %p4.23, f32[] %constant.163), metadata={op_type="aten__add" op_name="aten__add.577/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10720 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10719), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.577/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10721 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10718, f32[1,310,1]{2,1,0} %broadcast.10720), metadata={op_type="aten__add" op_name="aten__add.577/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10722 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10721), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10723 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10722), metadata={op_type="aten__mul" op_name="aten__mul.578/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10724 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10723), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.578/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10725 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10698, f32[1,310,4096]{2,1,0} %broadcast.10724), metadata={op_type="aten__mul" op_name="aten__mul.578/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10726 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10725), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10727 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10726), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10731 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10730, f32[1,310,4096]{2,1,0} %convert.10727), metadata={op_type="aten__mul" op_name="aten__mul.579/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10732 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10731), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10733 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10732), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p44.161 = bf16[6144,4096]{1,0} parameter(44), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.162 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p44.161), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10734 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.10733, bf16[4096,6144]{0,1} %transpose.162), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10735 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.10734), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10736 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.10735), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.10821 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10736), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.10822 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10821), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.10823 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.10822), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.10824 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.10823), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.10835 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.10824), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p602.10794 = bf16[32768,128]{1,0} parameter(602), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.10795 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p602.10794), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.10788 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10789 = s64[1,310]{1,0} broadcast(s64[] %constant.10788), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.10790 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10789), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10783 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10784 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10783), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10785 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10784), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.10786 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10785), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.10787 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10786), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.10791 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10790, s64[1,310]{1,0} %add.10787, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10792 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10791), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.10793 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10792), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.10796 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10795, s64[1,310,1]{2,1,0} %concatenate.10793), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.10797 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10796), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.10834 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10797), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10836 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10834), metadata={op_type="aten__mul" op_name="aten__mul.580/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10837 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10836), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.580/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10838 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.10835, f32[1,32,310,128]{3,2,1,0} %broadcast.10837), metadata={op_type="aten__mul" op_name="aten__mul.580/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10839 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10838), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.10826 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10824), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10827 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.10826), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10825 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.10824), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10828 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.10827, bf16[1,32,310,64]{3,2,1,0} %slice.10825), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10829 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.10828), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p601.10765 = bf16[32768,128]{1,0} parameter(601), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.10766 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p601.10765), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.10759 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10760 = s64[1,310]{1,0} broadcast(s64[] %constant.10759), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.10761 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10760), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10754 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10755 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10754), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10756 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10755), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10757 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10756), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.10758 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10757), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.10762 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.10761, s64[1,310]{1,0} %add.10758, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10763 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.10762), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.10764 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.10763), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.10767 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.10766, s64[1,310,1]{2,1,0} %concatenate.10764), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10768 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.10767), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.10820 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10768), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.10830 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10820), metadata={op_type="aten__mul" op_name="aten__mul.581/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10831 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10830), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.581/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10832 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.10829, f32[1,32,310,128]{3,2,1,0} %broadcast.10831), metadata={op_type="aten__mul" op_name="aten__mul.581/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.10833 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.10832), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.10819 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10840 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.10819), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.582/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.10841 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.10833, bf16[1,32,310,128]{3,2,1,0} %broadcast.10840), metadata={op_type="aten__add" op_name="aten__add.582/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.10842 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.10839, bf16[1,32,310,128]{3,2,1,0} %multiply.10841), metadata={op_type="aten__add" op_name="aten__add.582/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.10843 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.10842), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10844 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10843), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.10770 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10736), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.10771 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10770), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.10772 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10771), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.10773 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10772), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.10799 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.10773), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10798 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10797), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10800 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10798), metadata={op_type="aten__mul" op_name="aten__mul.583/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10801 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10800), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.583/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10802 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.10799, f32[1,8,310,128]{3,2,1,0} %broadcast.10801), metadata={op_type="aten__mul" op_name="aten__mul.583/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10803 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10802), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10775 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10773), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.10776 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.10775), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.10774 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10773), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.10777 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.10776, bf16[1,8,310,64]{3,2,1,0} %slice.10774), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.10778 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.10777), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10769 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.10768), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.10779 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.10769), metadata={op_type="aten__mul" op_name="aten__mul.584/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10780 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.10779), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.584/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10781 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.10778, f32[1,8,310,128]{3,2,1,0} %broadcast.10780), metadata={op_type="aten__mul" op_name="aten__mul.584/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.10782 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.10781), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.10753 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.10804 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.10753), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.585/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.10805 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.10782, bf16[1,8,310,128]{3,2,1,0} %broadcast.10804), metadata={op_type="aten__add" op_name="aten__add.585/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.10806 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.10803, bf16[1,8,310,128]{3,2,1,0} %multiply.10805), metadata={op_type="aten__add" op_name="aten__add.585/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.10807 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.10806), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10808 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10807), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10809 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10808), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10810 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10809), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10811 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10810), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10812 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10811), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10813 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10812), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10814 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10813), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10815 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10814), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.10816 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10815), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10817 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.10816), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10818 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.10817), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.10845 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.10844, bf16[32,128,310]{2,1,0} %reshape.10818), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.10846 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.10845), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.10847 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.10848 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.10846, bf16[1,32,310,310]{3,2,1,0} %broadcast.10847), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.10752 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10849 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.10752), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.586/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.10850 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.10849), metadata={op_type="aten__add" op_name="aten__add.586/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.10851 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.10850), metadata={op_type="aten__add" op_name="aten__add.586/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.10852 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.10851), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.586/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.10853 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.10848, bf16[1,32,310,310]{3,2,1,0} %broadcast.10852), metadata={op_type="aten__add" op_name="aten__add.586/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.10854 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.10853), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10855 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10860 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.10854, f32[] %constant.10855), dimensions={3}, to_apply=%MaxComputation.10856, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10861 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10860), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.10862 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.10854, f32[1,32,310,310]{3,2,1,0} %broadcast.10861), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.10863 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.10862), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.10864 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.10869 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.10863, f32[] %constant.10864), dimensions={3}, to_apply=%AddComputation.10865, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.10870 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.10869), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.10871 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.10863, f32[1,32,310,310]{3,2,1,0} %broadcast.10870), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.10872 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.10871), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.10873 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.10872), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10874 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.10873), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.10737 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10736), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.10738 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10737), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.10739 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10738), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.10740 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10739), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.10741 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10740), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10742 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10741), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10743 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10742), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10744 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10743), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10745 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10744), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10746 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10745), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10747 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10746), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10748 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10747), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10749 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10748), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.10750 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.10749), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10751 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10750), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.10875 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.10874, bf16[32,310,128]{2,1,0} %reshape.10751), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10876 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.10875), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.10877 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.10876), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.10878 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.10877), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.10879 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.10878), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p43.159 = bf16[4096,4096]{1,0} parameter(43), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.160 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p43.159), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10880 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.10879, bf16[4096,4096]{0,1} %transpose.160), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10881 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10880), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.158 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.10882 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.158), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.587/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.10883 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10881, bf16[1,310,4096]{2,1,0} %broadcast.10882), metadata={op_type="aten__add" op_name="aten__add.587/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.10884 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10697, bf16[1,310,4096]{2,1,0} %multiply.10883), metadata={op_type="aten__add" op_name="aten__add.587/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p603.10915 = bf16[4096]{0} parameter(603), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10916 = f32[4096]{0} convert(bf16[4096]{0} %p603.10915), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10917 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10916), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.590/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10885 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10884), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.157 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10886 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.157), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10887 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10885, f32[1,310,4096]{2,1,0} %broadcast.10886), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10888 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10894 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10887, f32[] %constant.10888), dimensions={2}, to_apply=%AddComputation.10890, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10889 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10895 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10900 = pred[] compare(s32[] %constant.10889, s32[] %constant.10895), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10896 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10898 = f32[] convert(s32[] %constant.10889), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10899 = f32[] divide(f32[] %constant.10896, f32[] %convert.10898), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10897 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10901 = f32[] select(pred[] %compare.10900, f32[] %divide.10899, f32[] %constant.10897), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10902 = f32[1,310]{1,0} broadcast(f32[] %select.10901), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10903 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10894, f32[1,310]{1,0} %broadcast.10902), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10904 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10903), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10905 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10904), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.156 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10906 = f32[] multiply(f32[] %p4.23, f32[] %constant.156), metadata={op_type="aten__add" op_name="aten__add.588/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10907 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10906), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.588/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10908 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10905, f32[1,310,1]{2,1,0} %broadcast.10907), metadata={op_type="aten__add" op_name="aten__add.588/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10909 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10908), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10910 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10909), metadata={op_type="aten__mul" op_name="aten__mul.589/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10911 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10910), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.589/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10912 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10885, f32[1,310,4096]{2,1,0} %broadcast.10911), metadata={op_type="aten__mul" op_name="aten__mul.589/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10913 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10912), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10914 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10913), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10918 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10917, f32[1,310,4096]{2,1,0} %convert.10914), metadata={op_type="aten__mul" op_name="aten__mul.590/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10919 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10918), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10926 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10919), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p604.10924 = bf16[14336,4096]{1,0} parameter(604), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.10925 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p604.10924), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10927 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10926, bf16[4096,14336]{0,1} %transpose.10925), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10928 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10927), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.10929 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.10928), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.10930 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.10928, bf16[1,310,14336]{2,1,0} %logistic.10929), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.10931 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.10930), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10920 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10919), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p42.154 = bf16[14336,4096]{1,0} parameter(42), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.155 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p42.154), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10921 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.10920, bf16[4096,14336]{0,1} %transpose.155), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10922 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.10921), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.10923 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.10922), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.10932 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.10931, f32[1,310,14336]{2,1,0} %convert.10923), metadata={op_type="aten__mul" op_name="aten__mul.591/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.10933 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.10932), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.10934 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.10933), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p41.152 = bf16[4096,14336]{1,0} parameter(41), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.153 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p41.152), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10935 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.10934, bf16[14336,4096]{0,1} %transpose.153), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10936 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.10935), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.151 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.10937 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.151), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.10938 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.10936, bf16[1,310,4096]{2,1,0} %broadcast.10937), metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.10939 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10884, bf16[1,310,4096]{2,1,0} %multiply.10938), metadata={op_type="aten__add" op_name="aten__add.592/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p605.10970 = bf16[4096]{0} parameter(605), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.10971 = f32[4096]{0} convert(bf16[4096]{0} %p605.10970), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.10972 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.10971), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.595/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10940 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.10939), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.150 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10941 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.150), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.10942 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.10940, f32[1,310,4096]{2,1,0} %broadcast.10941), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10943 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.10949 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.10942, f32[] %constant.10943), dimensions={2}, to_apply=%AddComputation.10945, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10944 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10950 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.10955 = pred[] compare(s32[] %constant.10944, s32[] %constant.10950), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10951 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10953 = f32[] convert(s32[] %constant.10944), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.10954 = f32[] divide(f32[] %constant.10951, f32[] %convert.10953), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.10952 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.10956 = f32[] select(pred[] %compare.10955, f32[] %divide.10954, f32[] %constant.10952), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.10957 = f32[1,310]{1,0} broadcast(f32[] %select.10956), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.10958 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.10949, f32[1,310]{1,0} %broadcast.10957), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.10959 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.10958), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.10960 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.10959), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.149 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10961 = f32[] multiply(f32[] %p4.23, f32[] %constant.149), metadata={op_type="aten__add" op_name="aten__add.593/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10962 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.10961), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.593/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.10963 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.10960, f32[1,310,1]{2,1,0} %broadcast.10962), metadata={op_type="aten__add" op_name="aten__add.593/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.10964 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.10963), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.10965 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.10964), metadata={op_type="aten__mul" op_name="aten__mul.594/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.10966 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.10965), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.594/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.10967 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.10940, f32[1,310,4096]{2,1,0} %broadcast.10966), metadata={op_type="aten__mul" op_name="aten__mul.594/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.10968 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10967), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10969 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.10968), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.10973 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.10972, f32[1,310,4096]{2,1,0} %convert.10969), metadata={op_type="aten__mul" op_name="aten__mul.595/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.10974 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.10973), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.10975 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.10974), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p40.147 = bf16[6144,4096]{1,0} parameter(40), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.148 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p40.147), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.10976 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.10975, bf16[4096,6144]{0,1} %transpose.148), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10977 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.10976), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.10978 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.10977), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.11063 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10978), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.11064 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11063), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.11065 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11064), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.11066 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.11065), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.11077 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.11066), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p607.11036 = bf16[32768,128]{1,0} parameter(607), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.11037 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p607.11036), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.11030 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11031 = s64[1,310]{1,0} broadcast(s64[] %constant.11030), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.11032 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11031), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11025 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11026 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11025), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11027 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11026), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11028 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11027), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.11029 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11028), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.11033 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11032, s64[1,310]{1,0} %add.11029, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11034 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11033), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.11035 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11034), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.11038 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11037, s64[1,310,1]{2,1,0} %concatenate.11035), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11039 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11038), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.11076 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11039), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11078 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11076), metadata={op_type="aten__mul" op_name="aten__mul.596/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11079 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11078), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.596/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11080 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.11077, f32[1,32,310,128]{3,2,1,0} %broadcast.11079), metadata={op_type="aten__mul" op_name="aten__mul.596/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11081 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11080), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.11068 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11066), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11069 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.11068), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11067 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11066), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11070 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.11069, bf16[1,32,310,64]{3,2,1,0} %slice.11067), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11071 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.11070), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p606.11007 = bf16[32768,128]{1,0} parameter(606), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.11008 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p606.11007), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.11001 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11002 = s64[1,310]{1,0} broadcast(s64[] %constant.11001), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.11003 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11002), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10996 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10997 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.10996), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.10998 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.10997), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.10999 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.10998), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.11000 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.10999), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.11004 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11003, s64[1,310]{1,0} %add.11000, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11005 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11004), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.11006 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11005), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.11009 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11008, s64[1,310,1]{2,1,0} %concatenate.11006), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11010 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11009), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.11062 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11010), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11072 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11062), metadata={op_type="aten__mul" op_name="aten__mul.597/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11073 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11072), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.597/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11074 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.11071, f32[1,32,310,128]{3,2,1,0} %broadcast.11073), metadata={op_type="aten__mul" op_name="aten__mul.597/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11075 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11074), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.11061 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11082 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.11061), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.598/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11083 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.11075, bf16[1,32,310,128]{3,2,1,0} %broadcast.11082), metadata={op_type="aten__add" op_name="aten__add.598/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.11084 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.11081, bf16[1,32,310,128]{3,2,1,0} %multiply.11083), metadata={op_type="aten__add" op_name="aten__add.598/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11085 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.11084), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11086 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11085), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.11012 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10978), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.11013 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11012), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.11014 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11013), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.11015 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11014), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.11041 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.11015), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11040 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11039), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11042 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11040), metadata={op_type="aten__mul" op_name="aten__mul.599/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11043 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11042), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.599/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11044 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.11041, f32[1,8,310,128]{3,2,1,0} %broadcast.11043), metadata={op_type="aten__mul" op_name="aten__mul.599/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11045 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11044), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11017 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11015), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11018 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.11017), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11016 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11015), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11019 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.11018, bf16[1,8,310,64]{3,2,1,0} %slice.11016), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11020 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.11019), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11011 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11010), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11021 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11011), metadata={op_type="aten__mul" op_name="aten__mul.600/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11022 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11021), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.600/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11023 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.11020, f32[1,8,310,128]{3,2,1,0} %broadcast.11022), metadata={op_type="aten__mul" op_name="aten__mul.600/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11024 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11023), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.10995 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11046 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.10995), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.601/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11047 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.11024, bf16[1,8,310,128]{3,2,1,0} %broadcast.11046), metadata={op_type="aten__add" op_name="aten__add.601/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.11048 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.11045, bf16[1,8,310,128]{3,2,1,0} %multiply.11047), metadata={op_type="aten__add" op_name="aten__add.601/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11049 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.11048), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11050 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11049), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11051 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11050), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11052 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11051), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11053 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11052), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11054 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11053), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11055 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11054), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11056 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11055), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11057 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11056), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.11058 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11057), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11059 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.11058), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11060 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.11059), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.11087 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.11086, bf16[32,128,310]{2,1,0} %reshape.11060), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11088 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.11087), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11089 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.11090 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.11088, bf16[1,32,310,310]{3,2,1,0} %broadcast.11089), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.10994 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11091 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.10994), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.602/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.11092 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.11091), metadata={op_type="aten__add" op_name="aten__add.602/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.11093 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.11092), metadata={op_type="aten__add" op_name="aten__add.602/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11094 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.11093), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.602/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.11095 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.11090, bf16[1,32,310,310]{3,2,1,0} %broadcast.11094), metadata={op_type="aten__add" op_name="aten__add.602/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.11096 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.11095), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11097 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11102 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.11096, f32[] %constant.11097), dimensions={3}, to_apply=%MaxComputation.11098, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11103 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11102), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.11104 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.11096, f32[1,32,310,310]{3,2,1,0} %broadcast.11103), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.11105 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.11104), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11106 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11111 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.11105, f32[] %constant.11106), dimensions={3}, to_apply=%AddComputation.11107, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11112 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11111), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.11113 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.11105, f32[1,32,310,310]{3,2,1,0} %broadcast.11112), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.11114 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.11113), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.11115 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.11114), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11116 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.11115), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.10979 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.10978), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.10980 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.10979), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.10981 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.10980), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.10982 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.10981), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.10983 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.10982), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10984 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.10983), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10985 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.10984), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10986 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.10985), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.10987 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10986), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10988 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.10987), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10989 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.10988), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.10990 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.10989), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.10991 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.10990), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.10992 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.10991), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.10993 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.10992), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.11117 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.11116, bf16[32,310,128]{2,1,0} %reshape.10993), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11118 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.11117), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.11119 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11118), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.11120 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.11119), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.11121 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.11120), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p39.145 = bf16[4096,4096]{1,0} parameter(39), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.146 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p39.145), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11122 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.11121, bf16[4096,4096]{0,1} %transpose.146), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11123 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11122), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.144 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.11124 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.144), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.603/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.11125 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11123, bf16[1,310,4096]{2,1,0} %broadcast.11124), metadata={op_type="aten__add" op_name="aten__add.603/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.11126 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.10939, bf16[1,310,4096]{2,1,0} %multiply.11125), metadata={op_type="aten__add" op_name="aten__add.603/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p608.11157 = bf16[4096]{0} parameter(608), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11158 = f32[4096]{0} convert(bf16[4096]{0} %p608.11157), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11159 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11158), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.606/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11127 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11126), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.143 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11128 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.143), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11129 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11127, f32[1,310,4096]{2,1,0} %broadcast.11128), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11130 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11136 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11129, f32[] %constant.11130), dimensions={2}, to_apply=%AddComputation.11132, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11131 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11137 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11142 = pred[] compare(s32[] %constant.11131, s32[] %constant.11137), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11138 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11140 = f32[] convert(s32[] %constant.11131), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11141 = f32[] divide(f32[] %constant.11138, f32[] %convert.11140), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11139 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11143 = f32[] select(pred[] %compare.11142, f32[] %divide.11141, f32[] %constant.11139), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11144 = f32[1,310]{1,0} broadcast(f32[] %select.11143), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11145 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11136, f32[1,310]{1,0} %broadcast.11144), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11146 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11145), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11147 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11146), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.142 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11148 = f32[] multiply(f32[] %p4.23, f32[] %constant.142), metadata={op_type="aten__add" op_name="aten__add.604/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11149 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11148), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.604/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11150 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11147, f32[1,310,1]{2,1,0} %broadcast.11149), metadata={op_type="aten__add" op_name="aten__add.604/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11151 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11150), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11152 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11151), metadata={op_type="aten__mul" op_name="aten__mul.605/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11153 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11152), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.605/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11154 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11127, f32[1,310,4096]{2,1,0} %broadcast.11153), metadata={op_type="aten__mul" op_name="aten__mul.605/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11155 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11154), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11156 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11155), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11160 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11159, f32[1,310,4096]{2,1,0} %convert.11156), metadata={op_type="aten__mul" op_name="aten__mul.606/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11161 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11160), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11168 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11161), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p609.11166 = bf16[14336,4096]{1,0} parameter(609), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.11167 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p609.11166), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11169 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11168, bf16[4096,14336]{0,1} %transpose.11167), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11170 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11169), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.11171 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.11170), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.11172 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.11170, bf16[1,310,14336]{2,1,0} %logistic.11171), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.11173 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.11172), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11162 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11161), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p38.140 = bf16[14336,4096]{1,0} parameter(38), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.141 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p38.140), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11163 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11162, bf16[4096,14336]{0,1} %transpose.141), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11164 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11163), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.11165 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.11164), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.11174 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.11173, f32[1,310,14336]{2,1,0} %convert.11165), metadata={op_type="aten__mul" op_name="aten__mul.607/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.11175 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.11174), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11176 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.11175), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p37.138 = bf16[4096,14336]{1,0} parameter(37), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.139 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p37.138), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11177 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.11176, bf16[14336,4096]{0,1} %transpose.139), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11178 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11177), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.137 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.11179 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.137), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.608/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.11180 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11178, bf16[1,310,4096]{2,1,0} %broadcast.11179), metadata={op_type="aten__add" op_name="aten__add.608/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.11181 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11126, bf16[1,310,4096]{2,1,0} %multiply.11180), metadata={op_type="aten__add" op_name="aten__add.608/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p610.11212 = bf16[4096]{0} parameter(610), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11213 = f32[4096]{0} convert(bf16[4096]{0} %p610.11212), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11214 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11213), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.611/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11182 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11181), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.136 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11183 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.136), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11184 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11182, f32[1,310,4096]{2,1,0} %broadcast.11183), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11185 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11191 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11184, f32[] %constant.11185), dimensions={2}, to_apply=%AddComputation.11187, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11186 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11192 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11197 = pred[] compare(s32[] %constant.11186, s32[] %constant.11192), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11193 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11195 = f32[] convert(s32[] %constant.11186), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11196 = f32[] divide(f32[] %constant.11193, f32[] %convert.11195), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11194 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11198 = f32[] select(pred[] %compare.11197, f32[] %divide.11196, f32[] %constant.11194), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11199 = f32[1,310]{1,0} broadcast(f32[] %select.11198), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11200 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11191, f32[1,310]{1,0} %broadcast.11199), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11201 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11200), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11202 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11201), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.135 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11203 = f32[] multiply(f32[] %p4.23, f32[] %constant.135), metadata={op_type="aten__add" op_name="aten__add.609/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11204 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11203), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.609/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11205 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11202, f32[1,310,1]{2,1,0} %broadcast.11204), metadata={op_type="aten__add" op_name="aten__add.609/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11206 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11205), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11207 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11206), metadata={op_type="aten__mul" op_name="aten__mul.610/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11208 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11207), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.610/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11209 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11182, f32[1,310,4096]{2,1,0} %broadcast.11208), metadata={op_type="aten__mul" op_name="aten__mul.610/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11210 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11209), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11211 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11210), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11215 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11214, f32[1,310,4096]{2,1,0} %convert.11211), metadata={op_type="aten__mul" op_name="aten__mul.611/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11216 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11215), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11217 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11216), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p36.133 = bf16[6144,4096]{1,0} parameter(36), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.134 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p36.133), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11218 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.11217, bf16[4096,6144]{0,1} %transpose.134), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11219 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.11218), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11220 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.11219), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.11305 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11220), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.11306 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11305), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.11307 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11306), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.11308 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.11307), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.11319 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.11308), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p612.11278 = bf16[32768,128]{1,0} parameter(612), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.11279 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p612.11278), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.11272 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11273 = s64[1,310]{1,0} broadcast(s64[] %constant.11272), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.11274 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11273), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11267 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11268 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11267), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11269 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11268), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11270 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11269), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.11271 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11270), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.11275 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11274, s64[1,310]{1,0} %add.11271, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11276 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11275), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.11277 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11276), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.11280 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11279, s64[1,310,1]{2,1,0} %concatenate.11277), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11281 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11280), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.11318 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11281), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11320 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11318), metadata={op_type="aten__mul" op_name="aten__mul.612/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11321 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11320), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.612/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11322 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.11319, f32[1,32,310,128]{3,2,1,0} %broadcast.11321), metadata={op_type="aten__mul" op_name="aten__mul.612/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11323 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11322), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.11310 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11308), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11311 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.11310), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11309 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11308), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11312 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.11311, bf16[1,32,310,64]{3,2,1,0} %slice.11309), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11313 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.11312), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p611.11249 = bf16[32768,128]{1,0} parameter(611), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.11250 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p611.11249), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.11243 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11244 = s64[1,310]{1,0} broadcast(s64[] %constant.11243), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.11245 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11244), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11238 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11239 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11238), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11240 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11239), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11241 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11240), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.11242 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11241), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.11246 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11245, s64[1,310]{1,0} %add.11242, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11247 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11246), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.11248 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11247), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.11251 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11250, s64[1,310,1]{2,1,0} %concatenate.11248), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11252 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11251), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.11304 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11252), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11314 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11304), metadata={op_type="aten__mul" op_name="aten__mul.613/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11315 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11314), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.613/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11316 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.11313, f32[1,32,310,128]{3,2,1,0} %broadcast.11315), metadata={op_type="aten__mul" op_name="aten__mul.613/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11317 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11316), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.11303 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11324 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.11303), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.614/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11325 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.11317, bf16[1,32,310,128]{3,2,1,0} %broadcast.11324), metadata={op_type="aten__add" op_name="aten__add.614/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.11326 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.11323, bf16[1,32,310,128]{3,2,1,0} %multiply.11325), metadata={op_type="aten__add" op_name="aten__add.614/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11327 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.11326), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11328 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11327), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.11254 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11220), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.11255 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11254), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.11256 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11255), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.11257 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11256), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.11283 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.11257), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11282 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11281), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11284 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11282), metadata={op_type="aten__mul" op_name="aten__mul.615/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11285 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11284), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.615/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11286 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.11283, f32[1,8,310,128]{3,2,1,0} %broadcast.11285), metadata={op_type="aten__mul" op_name="aten__mul.615/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11287 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11286), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11259 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11257), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11260 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.11259), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11258 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11257), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11261 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.11260, bf16[1,8,310,64]{3,2,1,0} %slice.11258), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11262 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.11261), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11253 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11252), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11263 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11253), metadata={op_type="aten__mul" op_name="aten__mul.616/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11264 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11263), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.616/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11265 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.11262, f32[1,8,310,128]{3,2,1,0} %broadcast.11264), metadata={op_type="aten__mul" op_name="aten__mul.616/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11266 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11265), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.11237 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11288 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.11237), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.617/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11289 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.11266, bf16[1,8,310,128]{3,2,1,0} %broadcast.11288), metadata={op_type="aten__add" op_name="aten__add.617/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.11290 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.11287, bf16[1,8,310,128]{3,2,1,0} %multiply.11289), metadata={op_type="aten__add" op_name="aten__add.617/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11291 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.11290), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11292 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11291), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11293 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11292), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11294 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11293), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11295 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11294), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11296 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11295), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11297 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11296), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11298 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11297), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11299 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11298), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.11300 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11299), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11301 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.11300), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11302 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.11301), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.11329 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.11328, bf16[32,128,310]{2,1,0} %reshape.11302), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11330 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.11329), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11331 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.11332 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.11330, bf16[1,32,310,310]{3,2,1,0} %broadcast.11331), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.11236 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11333 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.11236), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.618/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.11334 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.11333), metadata={op_type="aten__add" op_name="aten__add.618/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.11335 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.11334), metadata={op_type="aten__add" op_name="aten__add.618/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11336 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.11335), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.618/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.11337 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.11332, bf16[1,32,310,310]{3,2,1,0} %broadcast.11336), metadata={op_type="aten__add" op_name="aten__add.618/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.11338 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.11337), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11339 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11344 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.11338, f32[] %constant.11339), dimensions={3}, to_apply=%MaxComputation.11340, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11345 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11344), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.11346 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.11338, f32[1,32,310,310]{3,2,1,0} %broadcast.11345), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.11347 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.11346), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11348 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11353 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.11347, f32[] %constant.11348), dimensions={3}, to_apply=%AddComputation.11349, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11354 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11353), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.11355 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.11347, f32[1,32,310,310]{3,2,1,0} %broadcast.11354), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.11356 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.11355), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.11357 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.11356), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11358 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.11357), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.11221 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11220), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.11222 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11221), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.11223 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11222), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.11224 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11223), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.11225 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11224), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11226 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11225), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11227 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11226), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11228 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11227), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11229 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11228), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11230 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11229), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11231 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11230), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11232 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11231), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11233 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11232), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.11234 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.11233), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11235 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11234), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.11359 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.11358, bf16[32,310,128]{2,1,0} %reshape.11235), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11360 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.11359), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.11361 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11360), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.11362 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.11361), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.11363 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.11362), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p35.131 = bf16[4096,4096]{1,0} parameter(35), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.132 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p35.131), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11364 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.11363, bf16[4096,4096]{0,1} %transpose.132), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11365 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11364), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.130 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.11366 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.130), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.619/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.11367 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11365, bf16[1,310,4096]{2,1,0} %broadcast.11366), metadata={op_type="aten__add" op_name="aten__add.619/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.11368 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11181, bf16[1,310,4096]{2,1,0} %multiply.11367), metadata={op_type="aten__add" op_name="aten__add.619/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p613.11399 = bf16[4096]{0} parameter(613), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11400 = f32[4096]{0} convert(bf16[4096]{0} %p613.11399), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11401 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11400), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.622/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11369 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11368), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.129 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11370 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.129), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11371 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11369, f32[1,310,4096]{2,1,0} %broadcast.11370), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11372 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11378 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11371, f32[] %constant.11372), dimensions={2}, to_apply=%AddComputation.11374, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11373 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11379 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11384 = pred[] compare(s32[] %constant.11373, s32[] %constant.11379), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11380 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11382 = f32[] convert(s32[] %constant.11373), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11383 = f32[] divide(f32[] %constant.11380, f32[] %convert.11382), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11381 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11385 = f32[] select(pred[] %compare.11384, f32[] %divide.11383, f32[] %constant.11381), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11386 = f32[1,310]{1,0} broadcast(f32[] %select.11385), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11387 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11378, f32[1,310]{1,0} %broadcast.11386), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11388 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11387), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11389 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11388), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.128 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11390 = f32[] multiply(f32[] %p4.23, f32[] %constant.128), metadata={op_type="aten__add" op_name="aten__add.620/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11391 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11390), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.620/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11392 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11389, f32[1,310,1]{2,1,0} %broadcast.11391), metadata={op_type="aten__add" op_name="aten__add.620/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11393 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11392), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11394 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11393), metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11395 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11394), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11396 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11369, f32[1,310,4096]{2,1,0} %broadcast.11395), metadata={op_type="aten__mul" op_name="aten__mul.621/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11397 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11396), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11398 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11397), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11402 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11401, f32[1,310,4096]{2,1,0} %convert.11398), metadata={op_type="aten__mul" op_name="aten__mul.622/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11403 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11402), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11410 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11403), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p614.11408 = bf16[14336,4096]{1,0} parameter(614), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.11409 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p614.11408), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11411 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11410, bf16[4096,14336]{0,1} %transpose.11409), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11412 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11411), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.11413 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.11412), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.11414 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.11412, bf16[1,310,14336]{2,1,0} %logistic.11413), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.11415 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.11414), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11404 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11403), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p34.126 = bf16[14336,4096]{1,0} parameter(34), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.127 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p34.126), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11405 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11404, bf16[4096,14336]{0,1} %transpose.127), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11406 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11405), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.11407 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.11406), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.11416 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.11415, f32[1,310,14336]{2,1,0} %convert.11407), metadata={op_type="aten__mul" op_name="aten__mul.623/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.11417 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.11416), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11418 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.11417), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p33.124 = bf16[4096,14336]{1,0} parameter(33), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.125 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p33.124), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11419 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.11418, bf16[14336,4096]{0,1} %transpose.125), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11420 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11419), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.123 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.11421 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.123), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.624/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.11422 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11420, bf16[1,310,4096]{2,1,0} %broadcast.11421), metadata={op_type="aten__add" op_name="aten__add.624/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.11423 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11368, bf16[1,310,4096]{2,1,0} %multiply.11422), metadata={op_type="aten__add" op_name="aten__add.624/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p615.11454 = bf16[4096]{0} parameter(615), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11455 = f32[4096]{0} convert(bf16[4096]{0} %p615.11454), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11456 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11455), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.627/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11424 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11423), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.122 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11425 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.122), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11426 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11424, f32[1,310,4096]{2,1,0} %broadcast.11425), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11427 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11433 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11426, f32[] %constant.11427), dimensions={2}, to_apply=%AddComputation.11429, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11428 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11434 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11439 = pred[] compare(s32[] %constant.11428, s32[] %constant.11434), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11435 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11437 = f32[] convert(s32[] %constant.11428), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11438 = f32[] divide(f32[] %constant.11435, f32[] %convert.11437), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11436 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11440 = f32[] select(pred[] %compare.11439, f32[] %divide.11438, f32[] %constant.11436), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11441 = f32[1,310]{1,0} broadcast(f32[] %select.11440), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11442 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11433, f32[1,310]{1,0} %broadcast.11441), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11443 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11442), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11444 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11443), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.121 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11445 = f32[] multiply(f32[] %p4.23, f32[] %constant.121), metadata={op_type="aten__add" op_name="aten__add.625/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11446 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11445), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.625/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11447 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11444, f32[1,310,1]{2,1,0} %broadcast.11446), metadata={op_type="aten__add" op_name="aten__add.625/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11448 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11447), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11449 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11448), metadata={op_type="aten__mul" op_name="aten__mul.626/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11450 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11449), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.626/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11451 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11424, f32[1,310,4096]{2,1,0} %broadcast.11450), metadata={op_type="aten__mul" op_name="aten__mul.626/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11452 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11451), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11453 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11452), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11457 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11456, f32[1,310,4096]{2,1,0} %convert.11453), metadata={op_type="aten__mul" op_name="aten__mul.627/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11458 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11457), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11459 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11458), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p32.119 = bf16[6144,4096]{1,0} parameter(32), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.120 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p32.119), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11460 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.11459, bf16[4096,6144]{0,1} %transpose.120), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11461 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.11460), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11462 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.11461), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.11547 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11462), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.11548 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11547), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.11549 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11548), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.11550 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.11549), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.11561 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.11550), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p617.11520 = bf16[32768,128]{1,0} parameter(617), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.11521 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p617.11520), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.11514 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11515 = s64[1,310]{1,0} broadcast(s64[] %constant.11514), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.11516 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11515), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11509 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11510 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11509), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11511 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11510), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11512 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11511), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.11513 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11512), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.11517 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11516, s64[1,310]{1,0} %add.11513, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11518 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11517), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.11519 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11518), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.11522 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11521, s64[1,310,1]{2,1,0} %concatenate.11519), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11523 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11522), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.11560 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11523), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11562 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11560), metadata={op_type="aten__mul" op_name="aten__mul.628/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11563 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11562), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.628/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11564 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.11561, f32[1,32,310,128]{3,2,1,0} %broadcast.11563), metadata={op_type="aten__mul" op_name="aten__mul.628/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11565 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11564), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.11552 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11550), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11553 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.11552), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11551 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11550), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11554 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.11553, bf16[1,32,310,64]{3,2,1,0} %slice.11551), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11555 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.11554), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p616.11491 = bf16[32768,128]{1,0} parameter(616), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.11492 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p616.11491), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.11485 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11486 = s64[1,310]{1,0} broadcast(s64[] %constant.11485), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.11487 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11486), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11480 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11481 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11480), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11482 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11481), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11483 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11482), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.11484 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11483), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.11488 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11487, s64[1,310]{1,0} %add.11484, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11489 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11488), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.11490 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11489), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.11493 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11492, s64[1,310,1]{2,1,0} %concatenate.11490), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11494 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11493), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.11546 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11494), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11556 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11546), metadata={op_type="aten__mul" op_name="aten__mul.629/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11557 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11556), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.629/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11558 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.11555, f32[1,32,310,128]{3,2,1,0} %broadcast.11557), metadata={op_type="aten__mul" op_name="aten__mul.629/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11559 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11558), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.11545 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11566 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.11545), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.630/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11567 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.11559, bf16[1,32,310,128]{3,2,1,0} %broadcast.11566), metadata={op_type="aten__add" op_name="aten__add.630/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.11568 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.11565, bf16[1,32,310,128]{3,2,1,0} %multiply.11567), metadata={op_type="aten__add" op_name="aten__add.630/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11569 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.11568), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11570 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11569), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.11496 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11462), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.11497 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11496), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.11498 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11497), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.11499 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11498), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.11525 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.11499), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11524 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11523), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11526 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11524), metadata={op_type="aten__mul" op_name="aten__mul.631/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11527 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11526), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.631/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11528 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.11525, f32[1,8,310,128]{3,2,1,0} %broadcast.11527), metadata={op_type="aten__mul" op_name="aten__mul.631/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11529 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11528), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11501 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11499), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11502 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.11501), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11500 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11499), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11503 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.11502, bf16[1,8,310,64]{3,2,1,0} %slice.11500), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11504 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.11503), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11495 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11494), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11505 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11495), metadata={op_type="aten__mul" op_name="aten__mul.632/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11506 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11505), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.632/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11507 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.11504, f32[1,8,310,128]{3,2,1,0} %broadcast.11506), metadata={op_type="aten__mul" op_name="aten__mul.632/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11508 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11507), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.11479 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11530 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.11479), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.633/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11531 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.11508, bf16[1,8,310,128]{3,2,1,0} %broadcast.11530), metadata={op_type="aten__add" op_name="aten__add.633/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.11532 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.11529, bf16[1,8,310,128]{3,2,1,0} %multiply.11531), metadata={op_type="aten__add" op_name="aten__add.633/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11533 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.11532), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11534 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11533), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11535 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11534), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11536 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11535), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11537 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11536), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11538 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11537), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11539 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11538), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11540 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11539), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11541 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11540), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.11542 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11541), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11543 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.11542), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11544 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.11543), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.11571 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.11570, bf16[32,128,310]{2,1,0} %reshape.11544), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11572 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.11571), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11573 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.11574 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.11572, bf16[1,32,310,310]{3,2,1,0} %broadcast.11573), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.11478 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11575 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.11478), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.634/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.11576 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.11575), metadata={op_type="aten__add" op_name="aten__add.634/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.11577 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.11576), metadata={op_type="aten__add" op_name="aten__add.634/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11578 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.11577), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.634/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.11579 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.11574, bf16[1,32,310,310]{3,2,1,0} %broadcast.11578), metadata={op_type="aten__add" op_name="aten__add.634/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.11580 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.11579), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11581 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11586 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.11580, f32[] %constant.11581), dimensions={3}, to_apply=%MaxComputation.11582, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11587 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11586), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.11588 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.11580, f32[1,32,310,310]{3,2,1,0} %broadcast.11587), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.11589 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.11588), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11590 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11595 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.11589, f32[] %constant.11590), dimensions={3}, to_apply=%AddComputation.11591, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11596 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11595), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.11597 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.11589, f32[1,32,310,310]{3,2,1,0} %broadcast.11596), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.11598 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.11597), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.11599 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.11598), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11600 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.11599), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.11463 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11462), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.11464 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11463), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.11465 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11464), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.11466 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11465), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.11467 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11466), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11468 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11467), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11469 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11468), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11470 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11469), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11471 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11470), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11472 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11471), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11473 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11472), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11474 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11473), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11475 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11474), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.11476 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.11475), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11477 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11476), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.11601 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.11600, bf16[32,310,128]{2,1,0} %reshape.11477), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11602 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.11601), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.11603 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11602), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.11604 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.11603), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.11605 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.11604), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p31.117 = bf16[4096,4096]{1,0} parameter(31), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.118 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p31.117), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11606 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.11605, bf16[4096,4096]{0,1} %transpose.118), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11607 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11606), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.116 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.11608 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.116), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.635/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.11609 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11607, bf16[1,310,4096]{2,1,0} %broadcast.11608), metadata={op_type="aten__add" op_name="aten__add.635/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.11610 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11423, bf16[1,310,4096]{2,1,0} %multiply.11609), metadata={op_type="aten__add" op_name="aten__add.635/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p618.11641 = bf16[4096]{0} parameter(618), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11642 = f32[4096]{0} convert(bf16[4096]{0} %p618.11641), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11643 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11642), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.638/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11611 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11610), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.115 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11612 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.115), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11613 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11611, f32[1,310,4096]{2,1,0} %broadcast.11612), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11614 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11620 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11613, f32[] %constant.11614), dimensions={2}, to_apply=%AddComputation.11616, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11615 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11621 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11626 = pred[] compare(s32[] %constant.11615, s32[] %constant.11621), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11622 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11624 = f32[] convert(s32[] %constant.11615), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11625 = f32[] divide(f32[] %constant.11622, f32[] %convert.11624), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11623 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11627 = f32[] select(pred[] %compare.11626, f32[] %divide.11625, f32[] %constant.11623), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11628 = f32[1,310]{1,0} broadcast(f32[] %select.11627), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11629 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11620, f32[1,310]{1,0} %broadcast.11628), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11630 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11629), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11631 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11630), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.114 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11632 = f32[] multiply(f32[] %p4.23, f32[] %constant.114), metadata={op_type="aten__add" op_name="aten__add.636/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11633 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11632), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.636/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11634 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11631, f32[1,310,1]{2,1,0} %broadcast.11633), metadata={op_type="aten__add" op_name="aten__add.636/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11635 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11634), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11636 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11635), metadata={op_type="aten__mul" op_name="aten__mul.637/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11637 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11636), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.637/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11638 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11611, f32[1,310,4096]{2,1,0} %broadcast.11637), metadata={op_type="aten__mul" op_name="aten__mul.637/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11639 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11638), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11640 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11639), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11644 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11643, f32[1,310,4096]{2,1,0} %convert.11640), metadata={op_type="aten__mul" op_name="aten__mul.638/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11645 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11644), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11652 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11645), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p619.11650 = bf16[14336,4096]{1,0} parameter(619), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.11651 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p619.11650), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11653 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11652, bf16[4096,14336]{0,1} %transpose.11651), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11654 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11653), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.11655 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.11654), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.11656 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.11654, bf16[1,310,14336]{2,1,0} %logistic.11655), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.11657 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.11656), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11646 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11645), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p30.112 = bf16[14336,4096]{1,0} parameter(30), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.113 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p30.112), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11647 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11646, bf16[4096,14336]{0,1} %transpose.113), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11648 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11647), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.11649 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.11648), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.11658 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.11657, f32[1,310,14336]{2,1,0} %convert.11649), metadata={op_type="aten__mul" op_name="aten__mul.639/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.11659 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.11658), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11660 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.11659), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p29.110 = bf16[4096,14336]{1,0} parameter(29), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.111 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p29.110), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11661 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.11660, bf16[14336,4096]{0,1} %transpose.111), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11662 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11661), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.109 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.11663 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.109), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.640/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.11664 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11662, bf16[1,310,4096]{2,1,0} %broadcast.11663), metadata={op_type="aten__add" op_name="aten__add.640/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.11665 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11610, bf16[1,310,4096]{2,1,0} %multiply.11664), metadata={op_type="aten__add" op_name="aten__add.640/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p620.11696 = bf16[4096]{0} parameter(620), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11697 = f32[4096]{0} convert(bf16[4096]{0} %p620.11696), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11698 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11697), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.643/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11666 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11665), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.108 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11667 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.108), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11668 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11666, f32[1,310,4096]{2,1,0} %broadcast.11667), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11669 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11675 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11668, f32[] %constant.11669), dimensions={2}, to_apply=%AddComputation.11671, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11670 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11676 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11681 = pred[] compare(s32[] %constant.11670, s32[] %constant.11676), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11677 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11679 = f32[] convert(s32[] %constant.11670), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11680 = f32[] divide(f32[] %constant.11677, f32[] %convert.11679), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11678 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11682 = f32[] select(pred[] %compare.11681, f32[] %divide.11680, f32[] %constant.11678), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11683 = f32[1,310]{1,0} broadcast(f32[] %select.11682), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11684 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11675, f32[1,310]{1,0} %broadcast.11683), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11685 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11684), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11686 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11685), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.107 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11687 = f32[] multiply(f32[] %p4.23, f32[] %constant.107), metadata={op_type="aten__add" op_name="aten__add.641/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11688 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11687), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.641/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11689 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11686, f32[1,310,1]{2,1,0} %broadcast.11688), metadata={op_type="aten__add" op_name="aten__add.641/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11690 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11689), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11691 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11690), metadata={op_type="aten__mul" op_name="aten__mul.642/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11692 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11691), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.642/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11693 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11666, f32[1,310,4096]{2,1,0} %broadcast.11692), metadata={op_type="aten__mul" op_name="aten__mul.642/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11694 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11693), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11695 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11694), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11699 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11698, f32[1,310,4096]{2,1,0} %convert.11695), metadata={op_type="aten__mul" op_name="aten__mul.643/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11700 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11699), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11701 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11700), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p28.105 = bf16[6144,4096]{1,0} parameter(28), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.106 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p28.105), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11702 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.11701, bf16[4096,6144]{0,1} %transpose.106), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11703 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.11702), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11704 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.11703), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.11789 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11704), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.11790 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11789), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.11791 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.11790), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.11792 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.11791), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.11803 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.11792), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p622.11762 = bf16[32768,128]{1,0} parameter(622), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.11763 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p622.11762), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.11756 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11757 = s64[1,310]{1,0} broadcast(s64[] %constant.11756), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.11758 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11757), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11751 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11752 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11751), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11753 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11752), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11754 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11753), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.11755 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11754), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.11759 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11758, s64[1,310]{1,0} %add.11755, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11760 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11759), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.11761 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11760), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.11764 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11763, s64[1,310,1]{2,1,0} %concatenate.11761), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11765 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11764), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.11802 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11765), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11804 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11802), metadata={op_type="aten__mul" op_name="aten__mul.644/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11805 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11804), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.644/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11806 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.11803, f32[1,32,310,128]{3,2,1,0} %broadcast.11805), metadata={op_type="aten__mul" op_name="aten__mul.644/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11807 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11806), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.11794 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11792), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11795 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.11794), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11793 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.11792), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11796 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.11795, bf16[1,32,310,64]{3,2,1,0} %slice.11793), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11797 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.11796), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p621.11733 = bf16[32768,128]{1,0} parameter(621), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.11734 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p621.11733), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.11727 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11728 = s64[1,310]{1,0} broadcast(s64[] %constant.11727), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.11729 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11728), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11722 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11723 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11722), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11724 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11723), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11725 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11724), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.11726 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11725), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.11730 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11729, s64[1,310]{1,0} %add.11726, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11731 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11730), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.11732 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11731), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.11735 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11734, s64[1,310,1]{2,1,0} %concatenate.11732), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11736 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11735), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.11788 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11736), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.11798 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11788), metadata={op_type="aten__mul" op_name="aten__mul.645/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11799 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11798), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.645/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11800 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.11797, f32[1,32,310,128]{3,2,1,0} %broadcast.11799), metadata={op_type="aten__mul" op_name="aten__mul.645/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.11801 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.11800), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.11787 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11808 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.11787), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.646/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.11809 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.11801, bf16[1,32,310,128]{3,2,1,0} %broadcast.11808), metadata={op_type="aten__add" op_name="aten__add.646/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.11810 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.11807, bf16[1,32,310,128]{3,2,1,0} %multiply.11809), metadata={op_type="aten__add" op_name="aten__add.646/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.11811 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.11810), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11812 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11811), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.11738 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11704), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.11739 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11738), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.11740 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11739), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.11741 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11740), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.11767 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.11741), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11766 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11765), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11768 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11766), metadata={op_type="aten__mul" op_name="aten__mul.647/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11769 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11768), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.647/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11770 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.11767, f32[1,8,310,128]{3,2,1,0} %broadcast.11769), metadata={op_type="aten__mul" op_name="aten__mul.647/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11771 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11770), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11743 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11741), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11744 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.11743), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11742 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11741), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11745 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.11744, bf16[1,8,310,64]{3,2,1,0} %slice.11742), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11746 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.11745), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11737 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11736), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11747 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11737), metadata={op_type="aten__mul" op_name="aten__mul.648/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11748 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11747), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.648/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11749 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.11746, f32[1,8,310,128]{3,2,1,0} %broadcast.11748), metadata={op_type="aten__mul" op_name="aten__mul.648/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11750 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11749), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.11721 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11772 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.11721), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.649/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11773 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.11750, bf16[1,8,310,128]{3,2,1,0} %broadcast.11772), metadata={op_type="aten__add" op_name="aten__add.649/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.11774 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.11771, bf16[1,8,310,128]{3,2,1,0} %multiply.11773), metadata={op_type="aten__add" op_name="aten__add.649/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11775 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.11774), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11776 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11775), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11777 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11776), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11778 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11777), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11779 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11778), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11780 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11779), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11781 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11780), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11782 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11781), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11783 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11782), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.11784 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11783), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11785 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.11784), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11786 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.11785), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.11813 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.11812, bf16[32,128,310]{2,1,0} %reshape.11786), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.11814 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.11813), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.11815 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.11816 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.11814, bf16[1,32,310,310]{3,2,1,0} %broadcast.11815), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.11720 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11817 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.11720), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.650/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.11818 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.11817), metadata={op_type="aten__add" op_name="aten__add.650/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.11819 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.11818), metadata={op_type="aten__add" op_name="aten__add.650/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.11820 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.11819), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.650/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.11821 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.11816, bf16[1,32,310,310]{3,2,1,0} %broadcast.11820), metadata={op_type="aten__add" op_name="aten__add.650/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.11822 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.11821), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11823 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11828 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.11822, f32[] %constant.11823), dimensions={3}, to_apply=%MaxComputation.11824, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11829 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11828), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.11830 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.11822, f32[1,32,310,310]{3,2,1,0} %broadcast.11829), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.11831 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.11830), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.11832 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.11837 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.11831, f32[] %constant.11832), dimensions={3}, to_apply=%AddComputation.11833, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.11838 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.11837), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.11839 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.11831, f32[1,32,310,310]{3,2,1,0} %broadcast.11838), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.11840 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.11839), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.11841 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.11840), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11842 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.11841), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.11705 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11704), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.11706 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11705), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.11707 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11706), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.11708 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11707), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.11709 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11708), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11710 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11709), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11711 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11710), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11712 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11711), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11713 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11712), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11714 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11713), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11715 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11714), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11716 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11715), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11717 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11716), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.11718 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.11717), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11719 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11718), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.11843 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.11842, bf16[32,310,128]{2,1,0} %reshape.11719), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11844 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.11843), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.11845 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.11844), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.11846 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.11845), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.11847 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.11846), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p27.103 = bf16[4096,4096]{1,0} parameter(27), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.104 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p27.103), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11848 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.11847, bf16[4096,4096]{0,1} %transpose.104), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11849 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11848), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.102 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.11850 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.651/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.11851 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11849, bf16[1,310,4096]{2,1,0} %broadcast.11850), metadata={op_type="aten__add" op_name="aten__add.651/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.11852 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11665, bf16[1,310,4096]{2,1,0} %multiply.11851), metadata={op_type="aten__add" op_name="aten__add.651/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p623.11883 = bf16[4096]{0} parameter(623), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11884 = f32[4096]{0} convert(bf16[4096]{0} %p623.11883), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11885 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11884), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.654/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11853 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11852), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.101 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11854 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.101), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11855 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11853, f32[1,310,4096]{2,1,0} %broadcast.11854), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11856 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11862 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11855, f32[] %constant.11856), dimensions={2}, to_apply=%AddComputation.11858, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11857 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11863 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11868 = pred[] compare(s32[] %constant.11857, s32[] %constant.11863), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11864 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11866 = f32[] convert(s32[] %constant.11857), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11867 = f32[] divide(f32[] %constant.11864, f32[] %convert.11866), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11865 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11869 = f32[] select(pred[] %compare.11868, f32[] %divide.11867, f32[] %constant.11865), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11870 = f32[1,310]{1,0} broadcast(f32[] %select.11869), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11871 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11862, f32[1,310]{1,0} %broadcast.11870), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11872 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11871), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11873 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11872), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.100 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11874 = f32[] multiply(f32[] %p4.23, f32[] %constant.100), metadata={op_type="aten__add" op_name="aten__add.652/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11875 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11874), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.652/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11876 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11873, f32[1,310,1]{2,1,0} %broadcast.11875), metadata={op_type="aten__add" op_name="aten__add.652/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11877 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11876), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11878 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11877), metadata={op_type="aten__mul" op_name="aten__mul.653/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11879 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11878), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.653/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11880 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11853, f32[1,310,4096]{2,1,0} %broadcast.11879), metadata={op_type="aten__mul" op_name="aten__mul.653/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11881 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11880), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11882 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11881), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11886 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11885, f32[1,310,4096]{2,1,0} %convert.11882), metadata={op_type="aten__mul" op_name="aten__mul.654/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11887 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11886), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11894 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11887), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p624.11892 = bf16[14336,4096]{1,0} parameter(624), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.11893 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p624.11892), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11895 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11894, bf16[4096,14336]{0,1} %transpose.11893), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11896 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11895), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.11897 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.11896), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.11898 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.11896, bf16[1,310,14336]{2,1,0} %logistic.11897), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.11899 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.11898), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11888 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11887), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p26.98 = bf16[14336,4096]{1,0} parameter(26), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.99 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p26.98), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11889 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.11888, bf16[4096,14336]{0,1} %transpose.99), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11890 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.11889), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.11891 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.11890), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.11900 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.11899, f32[1,310,14336]{2,1,0} %convert.11891), metadata={op_type="aten__mul" op_name="aten__mul.655/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.11901 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.11900), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.11902 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.11901), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p25.96 = bf16[4096,14336]{1,0} parameter(25), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.97 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p25.96), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11903 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.11902, bf16[14336,4096]{0,1} %transpose.97), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11904 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.11903), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.95 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.11905 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.95), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.656/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.11906 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.11904, bf16[1,310,4096]{2,1,0} %broadcast.11905), metadata={op_type="aten__add" op_name="aten__add.656/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.11907 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11852, bf16[1,310,4096]{2,1,0} %multiply.11906), metadata={op_type="aten__add" op_name="aten__add.656/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p625.11938 = bf16[4096]{0} parameter(625), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.11939 = f32[4096]{0} convert(bf16[4096]{0} %p625.11938), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.11940 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.11939), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.659/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11908 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.11907), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.94 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11909 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.94), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.11910 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.11908, f32[1,310,4096]{2,1,0} %broadcast.11909), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11911 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.11917 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.11910, f32[] %constant.11911), dimensions={2}, to_apply=%AddComputation.11913, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11912 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11918 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.11923 = pred[] compare(s32[] %constant.11912, s32[] %constant.11918), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11919 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11921 = f32[] convert(s32[] %constant.11912), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.11922 = f32[] divide(f32[] %constant.11919, f32[] %convert.11921), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.11920 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.11924 = f32[] select(pred[] %compare.11923, f32[] %divide.11922, f32[] %constant.11920), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.11925 = f32[1,310]{1,0} broadcast(f32[] %select.11924), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.11926 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.11917, f32[1,310]{1,0} %broadcast.11925), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.11927 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.11926), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.11928 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.11927), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.93 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11929 = f32[] multiply(f32[] %p4.23, f32[] %constant.93), metadata={op_type="aten__add" op_name="aten__add.657/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11930 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.11929), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.657/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.11931 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.11928, f32[1,310,1]{2,1,0} %broadcast.11930), metadata={op_type="aten__add" op_name="aten__add.657/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.11932 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.11931), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.11933 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.11932), metadata={op_type="aten__mul" op_name="aten__mul.658/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.11934 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.11933), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.658/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.11935 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.11908, f32[1,310,4096]{2,1,0} %broadcast.11934), metadata={op_type="aten__mul" op_name="aten__mul.658/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.11936 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11935), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11937 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.11936), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.11941 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.11940, f32[1,310,4096]{2,1,0} %convert.11937), metadata={op_type="aten__mul" op_name="aten__mul.659/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.11942 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.11941), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.11943 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.11942), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p24.91 = bf16[6144,4096]{1,0} parameter(24), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.92 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p24.91), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.11944 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.11943, bf16[4096,6144]{0,1} %transpose.92), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11945 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.11944), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.11946 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.11945), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.12031 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11946), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.12032 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12031), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.12033 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12032), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.12034 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.12033), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.12045 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.12034), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p627.12004 = bf16[32768,128]{1,0} parameter(627), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.12005 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p627.12004), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.11998 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11999 = s64[1,310]{1,0} broadcast(s64[] %constant.11998), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.12000 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11999), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11993 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11994 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11993), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.11995 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11994), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.11996 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11995), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.11997 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11996), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.12001 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12000, s64[1,310]{1,0} %add.11997, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12002 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12001), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.12003 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12002), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.12006 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12005, s64[1,310,1]{2,1,0} %concatenate.12003), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12007 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12006), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.12044 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12007), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12046 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12044), metadata={op_type="aten__mul" op_name="aten__mul.660/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12047 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12046), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.660/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12048 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.12045, f32[1,32,310,128]{3,2,1,0} %broadcast.12047), metadata={op_type="aten__mul" op_name="aten__mul.660/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12049 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12048), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.12036 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12034), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12037 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.12036), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12035 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12034), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12038 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.12037, bf16[1,32,310,64]{3,2,1,0} %slice.12035), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12039 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.12038), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p626.11975 = bf16[32768,128]{1,0} parameter(626), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.11976 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p626.11975), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.11969 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11970 = s64[1,310]{1,0} broadcast(s64[] %constant.11969), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.11971 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11970), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11964 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11965 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.11964), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11966 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.11965), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.11967 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.11966), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.11968 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.11967), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.11972 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.11971, s64[1,310]{1,0} %add.11968, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11973 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.11972), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.11974 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.11973), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.11977 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.11976, s64[1,310,1]{2,1,0} %concatenate.11974), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.11978 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.11977), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.12030 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11978), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12040 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12030), metadata={op_type="aten__mul" op_name="aten__mul.661/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12041 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12040), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.661/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12042 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.12039, f32[1,32,310,128]{3,2,1,0} %broadcast.12041), metadata={op_type="aten__mul" op_name="aten__mul.661/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12043 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12042), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.12029 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12050 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.12029), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.662/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12051 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.12043, bf16[1,32,310,128]{3,2,1,0} %broadcast.12050), metadata={op_type="aten__add" op_name="aten__add.662/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.12052 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.12049, bf16[1,32,310,128]{3,2,1,0} %multiply.12051), metadata={op_type="aten__add" op_name="aten__add.662/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12053 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.12052), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12054 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12053), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.11980 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11946), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.11981 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11980), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.11982 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11981), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.11983 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11982), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.12009 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.11983), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12008 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12007), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12010 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12008), metadata={op_type="aten__mul" op_name="aten__mul.663/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12011 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12010), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.663/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12012 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.12009, f32[1,8,310,128]{3,2,1,0} %broadcast.12011), metadata={op_type="aten__mul" op_name="aten__mul.663/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12013 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12012), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.11985 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11983), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.11986 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.11985), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.11984 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11983), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.11987 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.11986, bf16[1,8,310,64]{3,2,1,0} %slice.11984), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.11988 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.11987), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11979 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.11978), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.11989 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.11979), metadata={op_type="aten__mul" op_name="aten__mul.664/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.11990 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.11989), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.664/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.11991 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.11988, f32[1,8,310,128]{3,2,1,0} %broadcast.11990), metadata={op_type="aten__mul" op_name="aten__mul.664/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.11992 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.11991), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.11963 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12014 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.11963), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.665/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12015 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.11992, bf16[1,8,310,128]{3,2,1,0} %broadcast.12014), metadata={op_type="aten__add" op_name="aten__add.665/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.12016 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.12013, bf16[1,8,310,128]{3,2,1,0} %multiply.12015), metadata={op_type="aten__add" op_name="aten__add.665/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12017 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.12016), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12018 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12017), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12019 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12018), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12020 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12019), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12021 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12020), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12022 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12021), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12023 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12022), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12024 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12023), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12025 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12024), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.12026 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12025), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12027 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.12026), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12028 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.12027), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.12055 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.12054, bf16[32,128,310]{2,1,0} %reshape.12028), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12056 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.12055), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12057 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.12058 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.12056, bf16[1,32,310,310]{3,2,1,0} %broadcast.12057), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.11962 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12059 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.11962), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.666/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.12060 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.12059), metadata={op_type="aten__add" op_name="aten__add.666/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.12061 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.12060), metadata={op_type="aten__add" op_name="aten__add.666/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12062 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.12061), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.666/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.12063 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.12058, bf16[1,32,310,310]{3,2,1,0} %broadcast.12062), metadata={op_type="aten__add" op_name="aten__add.666/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.12064 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.12063), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12065 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12070 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.12064, f32[] %constant.12065), dimensions={3}, to_apply=%MaxComputation.12066, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12071 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12070), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.12072 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.12064, f32[1,32,310,310]{3,2,1,0} %broadcast.12071), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.12073 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.12072), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12074 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12079 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.12073, f32[] %constant.12074), dimensions={3}, to_apply=%AddComputation.12075, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12080 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12079), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.12081 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.12073, f32[1,32,310,310]{3,2,1,0} %broadcast.12080), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.12082 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.12081), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.12083 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.12082), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12084 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.12083), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.11947 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.11946), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.11948 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.11947), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.11949 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.11948), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.11950 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.11949), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.11951 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.11950), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11952 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.11951), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11953 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.11952), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11954 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.11953), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.11955 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11954), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11956 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.11955), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11957 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.11956), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.11958 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.11957), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.11959 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.11958), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.11960 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.11959), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.11961 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.11960), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.12085 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.12084, bf16[32,310,128]{2,1,0} %reshape.11961), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12086 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.12085), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.12087 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12086), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.12088 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.12087), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.12089 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.12088), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p23.89 = bf16[4096,4096]{1,0} parameter(23), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.90 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p23.89), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12090 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.12089, bf16[4096,4096]{0,1} %transpose.90), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12091 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12090), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.88 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.12092 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.88), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.667/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.12093 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12091, bf16[1,310,4096]{2,1,0} %broadcast.12092), metadata={op_type="aten__add" op_name="aten__add.667/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.12094 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.11907, bf16[1,310,4096]{2,1,0} %multiply.12093), metadata={op_type="aten__add" op_name="aten__add.667/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p628.12125 = bf16[4096]{0} parameter(628), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12126 = f32[4096]{0} convert(bf16[4096]{0} %p628.12125), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12127 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12126), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.670/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12095 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12094), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.87 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12096 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.87), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12097 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12095, f32[1,310,4096]{2,1,0} %broadcast.12096), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12098 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12104 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12097, f32[] %constant.12098), dimensions={2}, to_apply=%AddComputation.12100, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12099 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12105 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12110 = pred[] compare(s32[] %constant.12099, s32[] %constant.12105), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12106 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12108 = f32[] convert(s32[] %constant.12099), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12109 = f32[] divide(f32[] %constant.12106, f32[] %convert.12108), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12107 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12111 = f32[] select(pred[] %compare.12110, f32[] %divide.12109, f32[] %constant.12107), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12112 = f32[1,310]{1,0} broadcast(f32[] %select.12111), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12113 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12104, f32[1,310]{1,0} %broadcast.12112), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12114 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12113), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12115 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12114), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.86 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12116 = f32[] multiply(f32[] %p4.23, f32[] %constant.86), metadata={op_type="aten__add" op_name="aten__add.668/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12117 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12116), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.668/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12118 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12115, f32[1,310,1]{2,1,0} %broadcast.12117), metadata={op_type="aten__add" op_name="aten__add.668/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12119 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12118), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12120 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12119), metadata={op_type="aten__mul" op_name="aten__mul.669/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12121 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12120), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.669/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12122 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12095, f32[1,310,4096]{2,1,0} %broadcast.12121), metadata={op_type="aten__mul" op_name="aten__mul.669/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12123 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12122), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12124 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12123), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12128 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12127, f32[1,310,4096]{2,1,0} %convert.12124), metadata={op_type="aten__mul" op_name="aten__mul.670/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12129 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12128), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12136 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12129), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p629.12134 = bf16[14336,4096]{1,0} parameter(629), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.12135 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p629.12134), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12137 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12136, bf16[4096,14336]{0,1} %transpose.12135), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12138 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12137), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.12139 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.12138), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.12140 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.12138, bf16[1,310,14336]{2,1,0} %logistic.12139), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.12141 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.12140), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12130 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12129), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p22.84 = bf16[14336,4096]{1,0} parameter(22), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.85 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p22.84), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12131 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12130, bf16[4096,14336]{0,1} %transpose.85), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12132 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12131), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.12133 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.12132), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.12142 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.12141, f32[1,310,14336]{2,1,0} %convert.12133), metadata={op_type="aten__mul" op_name="aten__mul.671/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.12143 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.12142), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12144 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.12143), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p21.82 = bf16[4096,14336]{1,0} parameter(21), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.83 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p21.82), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12145 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.12144, bf16[14336,4096]{0,1} %transpose.83), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12146 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12145), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.81 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.12147 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.81), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.672/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.12148 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12146, bf16[1,310,4096]{2,1,0} %broadcast.12147), metadata={op_type="aten__add" op_name="aten__add.672/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.12149 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12094, bf16[1,310,4096]{2,1,0} %multiply.12148), metadata={op_type="aten__add" op_name="aten__add.672/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p630.12180 = bf16[4096]{0} parameter(630), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12181 = f32[4096]{0} convert(bf16[4096]{0} %p630.12180), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12182 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12181), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.675/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12150 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12149), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.80 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12151 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.80), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12152 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12150, f32[1,310,4096]{2,1,0} %broadcast.12151), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12153 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12159 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12152, f32[] %constant.12153), dimensions={2}, to_apply=%AddComputation.12155, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12154 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12160 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12165 = pred[] compare(s32[] %constant.12154, s32[] %constant.12160), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12161 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12163 = f32[] convert(s32[] %constant.12154), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12164 = f32[] divide(f32[] %constant.12161, f32[] %convert.12163), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12162 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12166 = f32[] select(pred[] %compare.12165, f32[] %divide.12164, f32[] %constant.12162), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12167 = f32[1,310]{1,0} broadcast(f32[] %select.12166), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12168 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12159, f32[1,310]{1,0} %broadcast.12167), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12169 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12168), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12170 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12169), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.79 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12171 = f32[] multiply(f32[] %p4.23, f32[] %constant.79), metadata={op_type="aten__add" op_name="aten__add.673/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12172 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12171), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.673/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12173 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12170, f32[1,310,1]{2,1,0} %broadcast.12172), metadata={op_type="aten__add" op_name="aten__add.673/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12174 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12173), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12175 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12174), metadata={op_type="aten__mul" op_name="aten__mul.674/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12176 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12175), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.674/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12177 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12150, f32[1,310,4096]{2,1,0} %broadcast.12176), metadata={op_type="aten__mul" op_name="aten__mul.674/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12178 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12177), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12179 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12178), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12183 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12182, f32[1,310,4096]{2,1,0} %convert.12179), metadata={op_type="aten__mul" op_name="aten__mul.675/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12184 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12183), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12185 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12184), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p20.77 = bf16[6144,4096]{1,0} parameter(20), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.78 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p20.77), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12186 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.12185, bf16[4096,6144]{0,1} %transpose.78), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12187 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.12186), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12188 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.12187), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.12273 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12188), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.12274 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12273), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.12275 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12274), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.12276 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.12275), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.12287 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.12276), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p632.12246 = bf16[32768,128]{1,0} parameter(632), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.12247 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p632.12246), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.12240 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12241 = s64[1,310]{1,0} broadcast(s64[] %constant.12240), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.12242 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12241), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12235 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12236 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12235), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12237 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12236), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12238 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12237), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.12239 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12238), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.12243 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12242, s64[1,310]{1,0} %add.12239, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12244 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12243), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.12245 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12244), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.12248 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12247, s64[1,310,1]{2,1,0} %concatenate.12245), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12249 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12248), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.12286 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12249), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12288 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12286), metadata={op_type="aten__mul" op_name="aten__mul.676/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12289 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12288), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.676/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12290 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.12287, f32[1,32,310,128]{3,2,1,0} %broadcast.12289), metadata={op_type="aten__mul" op_name="aten__mul.676/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12291 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12290), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.12278 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12276), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12279 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.12278), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12277 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12276), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12280 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.12279, bf16[1,32,310,64]{3,2,1,0} %slice.12277), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12281 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.12280), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p631.12217 = bf16[32768,128]{1,0} parameter(631), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.12218 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p631.12217), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.12211 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12212 = s64[1,310]{1,0} broadcast(s64[] %constant.12211), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.12213 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12212), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12206 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12207 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12206), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12208 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12207), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12209 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12208), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.12210 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12209), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.12214 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12213, s64[1,310]{1,0} %add.12210, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12215 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12214), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.12216 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12215), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.12219 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12218, s64[1,310,1]{2,1,0} %concatenate.12216), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12220 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12219), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.12272 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12220), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12282 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12272), metadata={op_type="aten__mul" op_name="aten__mul.677/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12283 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12282), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.677/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12284 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.12281, f32[1,32,310,128]{3,2,1,0} %broadcast.12283), metadata={op_type="aten__mul" op_name="aten__mul.677/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12285 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12284), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.12271 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12292 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.12271), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.678/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12293 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.12285, bf16[1,32,310,128]{3,2,1,0} %broadcast.12292), metadata={op_type="aten__add" op_name="aten__add.678/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.12294 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.12291, bf16[1,32,310,128]{3,2,1,0} %multiply.12293), metadata={op_type="aten__add" op_name="aten__add.678/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12295 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.12294), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12296 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12295), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.12222 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12188), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.12223 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12222), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.12224 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12223), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.12225 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12224), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.12251 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.12225), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12250 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12249), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12252 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12250), metadata={op_type="aten__mul" op_name="aten__mul.679/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12253 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12252), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.679/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12254 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.12251, f32[1,8,310,128]{3,2,1,0} %broadcast.12253), metadata={op_type="aten__mul" op_name="aten__mul.679/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12255 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12254), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12227 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12225), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12228 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.12227), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12226 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12225), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12229 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.12228, bf16[1,8,310,64]{3,2,1,0} %slice.12226), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12230 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.12229), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12221 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12220), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12231 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12221), metadata={op_type="aten__mul" op_name="aten__mul.680/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12232 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12231), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.680/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12233 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.12230, f32[1,8,310,128]{3,2,1,0} %broadcast.12232), metadata={op_type="aten__mul" op_name="aten__mul.680/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12234 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12233), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.12205 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12256 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.12205), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.681/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12257 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.12234, bf16[1,8,310,128]{3,2,1,0} %broadcast.12256), metadata={op_type="aten__add" op_name="aten__add.681/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.12258 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.12255, bf16[1,8,310,128]{3,2,1,0} %multiply.12257), metadata={op_type="aten__add" op_name="aten__add.681/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12259 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.12258), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12260 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12259), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12261 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12260), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12262 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12261), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12263 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12262), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12264 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12263), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12265 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12264), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12266 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12265), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12267 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12266), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.12268 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12267), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12269 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.12268), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12270 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.12269), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.12297 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.12296, bf16[32,128,310]{2,1,0} %reshape.12270), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12298 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.12297), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12299 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.12300 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.12298, bf16[1,32,310,310]{3,2,1,0} %broadcast.12299), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.12204 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12301 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.12204), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.682/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.12302 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.12301), metadata={op_type="aten__add" op_name="aten__add.682/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.12303 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.12302), metadata={op_type="aten__add" op_name="aten__add.682/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12304 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.12303), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.682/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.12305 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.12300, bf16[1,32,310,310]{3,2,1,0} %broadcast.12304), metadata={op_type="aten__add" op_name="aten__add.682/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.12306 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.12305), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12307 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12312 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.12306, f32[] %constant.12307), dimensions={3}, to_apply=%MaxComputation.12308, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12313 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12312), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.12314 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.12306, f32[1,32,310,310]{3,2,1,0} %broadcast.12313), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.12315 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.12314), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12316 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12321 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.12315, f32[] %constant.12316), dimensions={3}, to_apply=%AddComputation.12317, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12322 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12321), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.12323 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.12315, f32[1,32,310,310]{3,2,1,0} %broadcast.12322), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.12324 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.12323), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.12325 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.12324), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12326 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.12325), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.12189 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12188), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.12190 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12189), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.12191 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12190), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.12192 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12191), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.12193 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12192), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12194 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12193), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12195 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12194), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12196 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12195), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12197 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12196), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12198 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12197), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12199 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12198), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12200 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12199), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12201 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12200), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.12202 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.12201), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12203 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12202), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.12327 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.12326, bf16[32,310,128]{2,1,0} %reshape.12203), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12328 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.12327), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.12329 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12328), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.12330 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.12329), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.12331 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.12330), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p19.75 = bf16[4096,4096]{1,0} parameter(19), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.76 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p19.75), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12332 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.12331, bf16[4096,4096]{0,1} %transpose.76), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12333 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12332), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.74 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.12334 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.74), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.683/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.12335 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12333, bf16[1,310,4096]{2,1,0} %broadcast.12334), metadata={op_type="aten__add" op_name="aten__add.683/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.12336 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12149, bf16[1,310,4096]{2,1,0} %multiply.12335), metadata={op_type="aten__add" op_name="aten__add.683/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p633.12367 = bf16[4096]{0} parameter(633), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12368 = f32[4096]{0} convert(bf16[4096]{0} %p633.12367), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12369 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12368), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.686/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12337 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12336), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.73 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12338 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.73), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12339 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12337, f32[1,310,4096]{2,1,0} %broadcast.12338), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12340 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12346 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12339, f32[] %constant.12340), dimensions={2}, to_apply=%AddComputation.12342, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12341 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12347 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12352 = pred[] compare(s32[] %constant.12341, s32[] %constant.12347), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12348 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12350 = f32[] convert(s32[] %constant.12341), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12351 = f32[] divide(f32[] %constant.12348, f32[] %convert.12350), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12349 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12353 = f32[] select(pred[] %compare.12352, f32[] %divide.12351, f32[] %constant.12349), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12354 = f32[1,310]{1,0} broadcast(f32[] %select.12353), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12355 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12346, f32[1,310]{1,0} %broadcast.12354), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12356 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12355), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12357 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12356), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.72 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12358 = f32[] multiply(f32[] %p4.23, f32[] %constant.72), metadata={op_type="aten__add" op_name="aten__add.684/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12359 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12358), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.684/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12360 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12357, f32[1,310,1]{2,1,0} %broadcast.12359), metadata={op_type="aten__add" op_name="aten__add.684/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12361 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12360), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12362 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12361), metadata={op_type="aten__mul" op_name="aten__mul.685/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12363 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12362), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.685/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12364 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12337, f32[1,310,4096]{2,1,0} %broadcast.12363), metadata={op_type="aten__mul" op_name="aten__mul.685/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12365 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12364), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12366 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12365), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12370 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12369, f32[1,310,4096]{2,1,0} %convert.12366), metadata={op_type="aten__mul" op_name="aten__mul.686/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12371 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12370), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12378 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12371), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p634.12376 = bf16[14336,4096]{1,0} parameter(634), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.12377 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p634.12376), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12379 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12378, bf16[4096,14336]{0,1} %transpose.12377), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12380 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12379), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.12381 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.12380), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.12382 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.12380, bf16[1,310,14336]{2,1,0} %logistic.12381), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.12383 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.12382), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12372 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12371), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p18.70 = bf16[14336,4096]{1,0} parameter(18), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.71 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p18.70), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12373 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12372, bf16[4096,14336]{0,1} %transpose.71), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12374 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12373), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.12375 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.12374), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.12384 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.12383, f32[1,310,14336]{2,1,0} %convert.12375), metadata={op_type="aten__mul" op_name="aten__mul.687/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.12385 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.12384), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12386 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.12385), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p17.68 = bf16[4096,14336]{1,0} parameter(17), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.69 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p17.68), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12387 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.12386, bf16[14336,4096]{0,1} %transpose.69), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12388 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12387), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.67 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.12389 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.67), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.688/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.12390 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12388, bf16[1,310,4096]{2,1,0} %broadcast.12389), metadata={op_type="aten__add" op_name="aten__add.688/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.12391 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12336, bf16[1,310,4096]{2,1,0} %multiply.12390), metadata={op_type="aten__add" op_name="aten__add.688/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p635.12422 = bf16[4096]{0} parameter(635), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12423 = f32[4096]{0} convert(bf16[4096]{0} %p635.12422), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12424 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12423), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.691/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12392 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12391), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.66 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12393 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.66), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12394 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12392, f32[1,310,4096]{2,1,0} %broadcast.12393), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12395 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12401 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12394, f32[] %constant.12395), dimensions={2}, to_apply=%AddComputation.12397, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12396 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12402 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12407 = pred[] compare(s32[] %constant.12396, s32[] %constant.12402), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12403 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12405 = f32[] convert(s32[] %constant.12396), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12406 = f32[] divide(f32[] %constant.12403, f32[] %convert.12405), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12404 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12408 = f32[] select(pred[] %compare.12407, f32[] %divide.12406, f32[] %constant.12404), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12409 = f32[1,310]{1,0} broadcast(f32[] %select.12408), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12410 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12401, f32[1,310]{1,0} %broadcast.12409), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12411 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12410), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12412 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12411), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.65 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12413 = f32[] multiply(f32[] %p4.23, f32[] %constant.65), metadata={op_type="aten__add" op_name="aten__add.689/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12414 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12413), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.689/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12415 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12412, f32[1,310,1]{2,1,0} %broadcast.12414), metadata={op_type="aten__add" op_name="aten__add.689/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12416 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12415), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12417 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12416), metadata={op_type="aten__mul" op_name="aten__mul.690/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12418 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12417), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.690/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12419 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12392, f32[1,310,4096]{2,1,0} %broadcast.12418), metadata={op_type="aten__mul" op_name="aten__mul.690/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12420 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12419), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12421 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12420), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12425 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12424, f32[1,310,4096]{2,1,0} %convert.12421), metadata={op_type="aten__mul" op_name="aten__mul.691/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12426 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12425), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12427 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12426), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p16.63 = bf16[6144,4096]{1,0} parameter(16), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.64 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p16.63), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12428 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.12427, bf16[4096,6144]{0,1} %transpose.64), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12429 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.12428), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12430 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.12429), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.12515 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12430), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.12516 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12515), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.12517 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12516), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.12518 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.12517), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.12529 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.12518), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p637.12488 = bf16[32768,128]{1,0} parameter(637), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.12489 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p637.12488), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.12482 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12483 = s64[1,310]{1,0} broadcast(s64[] %constant.12482), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.12484 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12483), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12477 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12478 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12477), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12479 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12478), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12480 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12479), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.12481 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12480), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.12485 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12484, s64[1,310]{1,0} %add.12481, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12486 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12485), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.12487 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12486), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.12490 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12489, s64[1,310,1]{2,1,0} %concatenate.12487), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12491 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12490), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.12528 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12491), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12530 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12528), metadata={op_type="aten__mul" op_name="aten__mul.692/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12531 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12530), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.692/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12532 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.12529, f32[1,32,310,128]{3,2,1,0} %broadcast.12531), metadata={op_type="aten__mul" op_name="aten__mul.692/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12533 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12532), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.12520 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12518), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12521 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.12520), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12519 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12518), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12522 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.12521, bf16[1,32,310,64]{3,2,1,0} %slice.12519), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12523 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.12522), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p636.12459 = bf16[32768,128]{1,0} parameter(636), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.12460 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p636.12459), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.12453 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12454 = s64[1,310]{1,0} broadcast(s64[] %constant.12453), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.12455 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12454), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12448 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12449 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12448), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12450 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12449), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12451 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12450), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.12452 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12451), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.12456 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12455, s64[1,310]{1,0} %add.12452, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12457 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12456), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.12458 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12457), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.12461 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12460, s64[1,310,1]{2,1,0} %concatenate.12458), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12462 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12461), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.12514 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12462), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12524 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12514), metadata={op_type="aten__mul" op_name="aten__mul.693/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12525 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12524), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.693/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12526 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.12523, f32[1,32,310,128]{3,2,1,0} %broadcast.12525), metadata={op_type="aten__mul" op_name="aten__mul.693/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12527 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12526), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.12513 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12534 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.12513), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.694/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12535 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.12527, bf16[1,32,310,128]{3,2,1,0} %broadcast.12534), metadata={op_type="aten__add" op_name="aten__add.694/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.12536 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.12533, bf16[1,32,310,128]{3,2,1,0} %multiply.12535), metadata={op_type="aten__add" op_name="aten__add.694/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12537 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.12536), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12538 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12537), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.12464 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12430), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.12465 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12464), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.12466 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12465), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.12467 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12466), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.12493 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.12467), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12492 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12491), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12494 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12492), metadata={op_type="aten__mul" op_name="aten__mul.695/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12495 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12494), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.695/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12496 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.12493, f32[1,8,310,128]{3,2,1,0} %broadcast.12495), metadata={op_type="aten__mul" op_name="aten__mul.695/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12497 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12496), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12469 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12467), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12470 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.12469), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12468 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12467), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12471 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.12470, bf16[1,8,310,64]{3,2,1,0} %slice.12468), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12472 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.12471), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12463 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12462), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12473 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12463), metadata={op_type="aten__mul" op_name="aten__mul.696/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12474 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12473), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.696/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12475 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.12472, f32[1,8,310,128]{3,2,1,0} %broadcast.12474), metadata={op_type="aten__mul" op_name="aten__mul.696/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12476 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12475), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.12447 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12498 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.12447), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.697/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12499 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.12476, bf16[1,8,310,128]{3,2,1,0} %broadcast.12498), metadata={op_type="aten__add" op_name="aten__add.697/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.12500 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.12497, bf16[1,8,310,128]{3,2,1,0} %multiply.12499), metadata={op_type="aten__add" op_name="aten__add.697/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12501 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.12500), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12502 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12501), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12503 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12502), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12504 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12503), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12505 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12504), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12506 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12505), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12507 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12506), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12508 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12507), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12509 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12508), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.12510 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12509), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12511 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.12510), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12512 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.12511), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.12539 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.12538, bf16[32,128,310]{2,1,0} %reshape.12512), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12540 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.12539), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12541 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.12542 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.12540, bf16[1,32,310,310]{3,2,1,0} %broadcast.12541), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.12446 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12543 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.12446), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.698/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.12544 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.12543), metadata={op_type="aten__add" op_name="aten__add.698/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.12545 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.12544), metadata={op_type="aten__add" op_name="aten__add.698/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12546 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.12545), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.698/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.12547 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.12542, bf16[1,32,310,310]{3,2,1,0} %broadcast.12546), metadata={op_type="aten__add" op_name="aten__add.698/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.12548 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.12547), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12549 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12554 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.12548, f32[] %constant.12549), dimensions={3}, to_apply=%MaxComputation.12550, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12555 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12554), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.12556 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.12548, f32[1,32,310,310]{3,2,1,0} %broadcast.12555), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.12557 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.12556), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12558 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12563 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.12557, f32[] %constant.12558), dimensions={3}, to_apply=%AddComputation.12559, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12564 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12563), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.12565 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.12557, f32[1,32,310,310]{3,2,1,0} %broadcast.12564), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.12566 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.12565), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.12567 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.12566), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12568 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.12567), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.12431 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12430), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.12432 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12431), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.12433 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12432), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.12434 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12433), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.12435 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12434), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12436 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12435), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12437 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12436), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12438 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12437), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12439 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12438), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12440 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12439), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12441 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12440), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12442 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12441), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12443 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12442), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.12444 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.12443), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12445 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12444), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.12569 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.12568, bf16[32,310,128]{2,1,0} %reshape.12445), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12570 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.12569), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.12571 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12570), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.12572 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.12571), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.12573 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.12572), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p15.61 = bf16[4096,4096]{1,0} parameter(15), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.62 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p15.61), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12574 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.12573, bf16[4096,4096]{0,1} %transpose.62), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12575 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12574), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.60 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.12576 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.60), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.699/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.12577 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12575, bf16[1,310,4096]{2,1,0} %broadcast.12576), metadata={op_type="aten__add" op_name="aten__add.699/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.12578 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12391, bf16[1,310,4096]{2,1,0} %multiply.12577), metadata={op_type="aten__add" op_name="aten__add.699/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p638.12609 = bf16[4096]{0} parameter(638), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12610 = f32[4096]{0} convert(bf16[4096]{0} %p638.12609), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12611 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12610), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.702/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12579 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12578), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.59 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12580 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.59), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12581 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12579, f32[1,310,4096]{2,1,0} %broadcast.12580), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12582 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12588 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12581, f32[] %constant.12582), dimensions={2}, to_apply=%AddComputation.12584, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12583 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12589 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12594 = pred[] compare(s32[] %constant.12583, s32[] %constant.12589), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12590 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12592 = f32[] convert(s32[] %constant.12583), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12593 = f32[] divide(f32[] %constant.12590, f32[] %convert.12592), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12591 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12595 = f32[] select(pred[] %compare.12594, f32[] %divide.12593, f32[] %constant.12591), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12596 = f32[1,310]{1,0} broadcast(f32[] %select.12595), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12597 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12588, f32[1,310]{1,0} %broadcast.12596), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12598 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12597), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12599 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12598), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.58 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12600 = f32[] multiply(f32[] %p4.23, f32[] %constant.58), metadata={op_type="aten__add" op_name="aten__add.700/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12601 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12600), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.700/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12602 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12599, f32[1,310,1]{2,1,0} %broadcast.12601), metadata={op_type="aten__add" op_name="aten__add.700/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12603 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12602), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12604 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12603), metadata={op_type="aten__mul" op_name="aten__mul.701/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12605 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12604), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.701/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12606 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12579, f32[1,310,4096]{2,1,0} %broadcast.12605), metadata={op_type="aten__mul" op_name="aten__mul.701/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12607 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12606), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12608 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12607), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12612 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12611, f32[1,310,4096]{2,1,0} %convert.12608), metadata={op_type="aten__mul" op_name="aten__mul.702/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12613 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12612), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12620 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12613), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p639.12618 = bf16[14336,4096]{1,0} parameter(639), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.12619 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p639.12618), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12621 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12620, bf16[4096,14336]{0,1} %transpose.12619), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12622 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12621), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.12623 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.12622), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.12624 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.12622, bf16[1,310,14336]{2,1,0} %logistic.12623), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.12625 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.12624), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12614 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12613), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p14.56 = bf16[14336,4096]{1,0} parameter(14), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.57 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p14.56), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12615 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12614, bf16[4096,14336]{0,1} %transpose.57), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12616 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12615), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.12617 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.12616), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.12626 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.12625, f32[1,310,14336]{2,1,0} %convert.12617), metadata={op_type="aten__mul" op_name="aten__mul.703/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.12627 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.12626), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12628 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.12627), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p13.54 = bf16[4096,14336]{1,0} parameter(13), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.55 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p13.54), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12629 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.12628, bf16[14336,4096]{0,1} %transpose.55), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12630 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12629), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.53 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.12631 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.53), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.704/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.12632 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12630, bf16[1,310,4096]{2,1,0} %broadcast.12631), metadata={op_type="aten__add" op_name="aten__add.704/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.12633 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12578, bf16[1,310,4096]{2,1,0} %multiply.12632), metadata={op_type="aten__add" op_name="aten__add.704/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p640.12664 = bf16[4096]{0} parameter(640), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12665 = f32[4096]{0} convert(bf16[4096]{0} %p640.12664), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12666 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12665), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.707/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12634 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12633), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.52 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12635 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.52), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12636 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12634, f32[1,310,4096]{2,1,0} %broadcast.12635), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12637 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12643 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12636, f32[] %constant.12637), dimensions={2}, to_apply=%AddComputation.12639, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12638 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12644 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12649 = pred[] compare(s32[] %constant.12638, s32[] %constant.12644), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12645 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12647 = f32[] convert(s32[] %constant.12638), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12648 = f32[] divide(f32[] %constant.12645, f32[] %convert.12647), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12646 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12650 = f32[] select(pred[] %compare.12649, f32[] %divide.12648, f32[] %constant.12646), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12651 = f32[1,310]{1,0} broadcast(f32[] %select.12650), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12652 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12643, f32[1,310]{1,0} %broadcast.12651), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12653 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12652), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12654 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12653), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.51 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12655 = f32[] multiply(f32[] %p4.23, f32[] %constant.51), metadata={op_type="aten__add" op_name="aten__add.705/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12656 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12655), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.705/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12657 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12654, f32[1,310,1]{2,1,0} %broadcast.12656), metadata={op_type="aten__add" op_name="aten__add.705/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12658 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12657), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12659 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12658), metadata={op_type="aten__mul" op_name="aten__mul.706/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12660 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12659), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.706/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12661 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12634, f32[1,310,4096]{2,1,0} %broadcast.12660), metadata={op_type="aten__mul" op_name="aten__mul.706/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12662 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12661), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12663 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12662), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12667 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12666, f32[1,310,4096]{2,1,0} %convert.12663), metadata={op_type="aten__mul" op_name="aten__mul.707/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12668 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12667), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12669 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12668), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p12.49 = bf16[6144,4096]{1,0} parameter(12), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.50 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p12.49), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12670 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.12669, bf16[4096,6144]{0,1} %transpose.50), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12671 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.12670), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12672 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.12671), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.12757 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12672), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.12758 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12757), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.12759 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12758), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.12760 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.12759), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.12771 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.12760), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p642.12730 = bf16[32768,128]{1,0} parameter(642), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.12731 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p642.12730), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.12724 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12725 = s64[1,310]{1,0} broadcast(s64[] %constant.12724), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.12726 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12725), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12719 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12720 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12719), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12721 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12720), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12722 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12721), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.12723 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12722), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.12727 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12726, s64[1,310]{1,0} %add.12723, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12728 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12727), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.12729 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12728), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.12732 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12731, s64[1,310,1]{2,1,0} %concatenate.12729), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12733 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12732), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.12770 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12733), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12772 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12770), metadata={op_type="aten__mul" op_name="aten__mul.708/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12773 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12772), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.708/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12774 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.12771, f32[1,32,310,128]{3,2,1,0} %broadcast.12773), metadata={op_type="aten__mul" op_name="aten__mul.708/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12775 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12774), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.12762 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12760), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12763 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.12762), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12761 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.12760), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12764 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.12763, bf16[1,32,310,64]{3,2,1,0} %slice.12761), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12765 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.12764), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p641.12701 = bf16[32768,128]{1,0} parameter(641), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.12702 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p641.12701), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.12695 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12696 = s64[1,310]{1,0} broadcast(s64[] %constant.12695), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.12697 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12696), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12690 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12691 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12690), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12692 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12691), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12693 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12692), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.12694 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12693), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.12698 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12697, s64[1,310]{1,0} %add.12694, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12699 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12698), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.12700 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12699), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.12703 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12702, s64[1,310,1]{2,1,0} %concatenate.12700), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12704 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12703), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.12756 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12704), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.12766 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12756), metadata={op_type="aten__mul" op_name="aten__mul.709/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12767 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12766), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.709/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12768 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.12765, f32[1,32,310,128]{3,2,1,0} %broadcast.12767), metadata={op_type="aten__mul" op_name="aten__mul.709/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.12769 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.12768), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.12755 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12776 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.12755), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.710/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.12777 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.12769, bf16[1,32,310,128]{3,2,1,0} %broadcast.12776), metadata={op_type="aten__add" op_name="aten__add.710/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.12778 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.12775, bf16[1,32,310,128]{3,2,1,0} %multiply.12777), metadata={op_type="aten__add" op_name="aten__add.710/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.12779 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.12778), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12780 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12779), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.12706 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12672), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.12707 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12706), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.12708 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12707), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.12709 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12708), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.12735 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.12709), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12734 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12733), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12736 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12734), metadata={op_type="aten__mul" op_name="aten__mul.711/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12737 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12736), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.711/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12738 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.12735, f32[1,8,310,128]{3,2,1,0} %broadcast.12737), metadata={op_type="aten__mul" op_name="aten__mul.711/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12739 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12738), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12711 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12709), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12712 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.12711), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12710 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12709), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12713 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.12712, bf16[1,8,310,64]{3,2,1,0} %slice.12710), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12714 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.12713), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12705 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12704), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12715 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12705), metadata={op_type="aten__mul" op_name="aten__mul.712/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12716 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12715), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.712/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12717 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.12714, f32[1,8,310,128]{3,2,1,0} %broadcast.12716), metadata={op_type="aten__mul" op_name="aten__mul.712/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12718 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12717), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.12689 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12740 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.12689), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.713/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12741 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.12718, bf16[1,8,310,128]{3,2,1,0} %broadcast.12740), metadata={op_type="aten__add" op_name="aten__add.713/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.12742 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.12739, bf16[1,8,310,128]{3,2,1,0} %multiply.12741), metadata={op_type="aten__add" op_name="aten__add.713/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12743 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.12742), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12744 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12743), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12745 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12744), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12746 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12745), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12747 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12746), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12748 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12747), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12749 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12748), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12750 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12749), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12751 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12750), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.12752 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12751), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12753 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.12752), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12754 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.12753), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.12781 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.12780, bf16[32,128,310]{2,1,0} %reshape.12754), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12782 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.12781), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12783 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.12784 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.12782, bf16[1,32,310,310]{3,2,1,0} %broadcast.12783), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.12688 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12785 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.12688), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.714/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.12786 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.12785), metadata={op_type="aten__add" op_name="aten__add.714/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.12787 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.12786), metadata={op_type="aten__add" op_name="aten__add.714/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.12788 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.12787), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.714/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.12789 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.12784, bf16[1,32,310,310]{3,2,1,0} %broadcast.12788), metadata={op_type="aten__add" op_name="aten__add.714/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.12790 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.12789), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12791 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12796 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.12790, f32[] %constant.12791), dimensions={3}, to_apply=%MaxComputation.12792, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12797 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12796), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.12798 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.12790, f32[1,32,310,310]{3,2,1,0} %broadcast.12797), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.12799 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.12798), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.12800 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.12805 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.12799, f32[] %constant.12800), dimensions={3}, to_apply=%AddComputation.12801, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.12806 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.12805), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.12807 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.12799, f32[1,32,310,310]{3,2,1,0} %broadcast.12806), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.12808 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.12807), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.12809 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.12808), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12810 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.12809), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.12673 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12672), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.12674 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12673), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.12675 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12674), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.12676 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12675), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.12677 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12676), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12678 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12677), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12679 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12678), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12680 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12679), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12681 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12680), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12682 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12681), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12683 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12682), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12684 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12683), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12685 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12684), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.12686 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.12685), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12687 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12686), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.12811 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.12810, bf16[32,310,128]{2,1,0} %reshape.12687), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12812 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.12811), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.12813 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12812), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.12814 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.12813), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.12815 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.12814), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p11.47 = bf16[4096,4096]{1,0} parameter(11), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.48 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p11.47), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12816 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.12815, bf16[4096,4096]{0,1} %transpose.48), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12817 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12816), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.46 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.12818 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.46), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.715/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.12819 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12817, bf16[1,310,4096]{2,1,0} %broadcast.12818), metadata={op_type="aten__add" op_name="aten__add.715/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.12820 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12633, bf16[1,310,4096]{2,1,0} %multiply.12819), metadata={op_type="aten__add" op_name="aten__add.715/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p643.12851 = bf16[4096]{0} parameter(643), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12852 = f32[4096]{0} convert(bf16[4096]{0} %p643.12851), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12853 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12852), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.718/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12821 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12820), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.45 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12822 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.45), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12823 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12821, f32[1,310,4096]{2,1,0} %broadcast.12822), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12824 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12830 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12823, f32[] %constant.12824), dimensions={2}, to_apply=%AddComputation.12826, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12825 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12831 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12836 = pred[] compare(s32[] %constant.12825, s32[] %constant.12831), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12832 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12834 = f32[] convert(s32[] %constant.12825), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12835 = f32[] divide(f32[] %constant.12832, f32[] %convert.12834), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12833 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12837 = f32[] select(pred[] %compare.12836, f32[] %divide.12835, f32[] %constant.12833), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12838 = f32[1,310]{1,0} broadcast(f32[] %select.12837), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12839 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12830, f32[1,310]{1,0} %broadcast.12838), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12840 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12839), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12841 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12840), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.44 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12842 = f32[] multiply(f32[] %p4.23, f32[] %constant.44), metadata={op_type="aten__add" op_name="aten__add.716/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12843 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12842), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.716/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12844 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12841, f32[1,310,1]{2,1,0} %broadcast.12843), metadata={op_type="aten__add" op_name="aten__add.716/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12845 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12844), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12846 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12845), metadata={op_type="aten__mul" op_name="aten__mul.717/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12847 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12846), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.717/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12848 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12821, f32[1,310,4096]{2,1,0} %broadcast.12847), metadata={op_type="aten__mul" op_name="aten__mul.717/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12849 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12848), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12850 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12849), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12854 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12853, f32[1,310,4096]{2,1,0} %convert.12850), metadata={op_type="aten__mul" op_name="aten__mul.718/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12855 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12854), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12862 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12855), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p644.12860 = bf16[14336,4096]{1,0} parameter(644), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.12861 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p644.12860), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12863 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12862, bf16[4096,14336]{0,1} %transpose.12861), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12864 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12863), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.12865 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.12864), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.12866 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.12864, bf16[1,310,14336]{2,1,0} %logistic.12865), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.12867 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.12866), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12856 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12855), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p10.42 = bf16[14336,4096]{1,0} parameter(10), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.43 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p10.42), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12857 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.12856, bf16[4096,14336]{0,1} %transpose.43), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12858 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.12857), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.12859 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.12858), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.12868 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.12867, f32[1,310,14336]{2,1,0} %convert.12859), metadata={op_type="aten__mul" op_name="aten__mul.719/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.12869 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.12868), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.12870 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.12869), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p9.40 = bf16[4096,14336]{1,0} parameter(9), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.41 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p9.40), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12871 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.12870, bf16[14336,4096]{0,1} %transpose.41), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12872 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.12871), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.39 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.12873 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.39), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.720/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.12874 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.12872, bf16[1,310,4096]{2,1,0} %broadcast.12873), metadata={op_type="aten__add" op_name="aten__add.720/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.12875 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12820, bf16[1,310,4096]{2,1,0} %multiply.12874), metadata={op_type="aten__add" op_name="aten__add.720/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %p645.12906 = bf16[4096]{0} parameter(645), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.12907 = f32[4096]{0} convert(bf16[4096]{0} %p645.12906), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.12908 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.12907), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.723/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12876 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.12875), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.38 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12877 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.38), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.12878 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.12876, f32[1,310,4096]{2,1,0} %broadcast.12877), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12879 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.12885 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.12878, f32[] %constant.12879), dimensions={2}, to_apply=%AddComputation.12881, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12880 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12886 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.12891 = pred[] compare(s32[] %constant.12880, s32[] %constant.12886), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12887 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12889 = f32[] convert(s32[] %constant.12880), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.12890 = f32[] divide(f32[] %constant.12887, f32[] %convert.12889), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.12888 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.12892 = f32[] select(pred[] %compare.12891, f32[] %divide.12890, f32[] %constant.12888), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.12893 = f32[1,310]{1,0} broadcast(f32[] %select.12892), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.12894 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.12885, f32[1,310]{1,0} %broadcast.12893), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.12895 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.12894), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.12896 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.12895), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.37 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12897 = f32[] multiply(f32[] %p4.23, f32[] %constant.37), metadata={op_type="aten__add" op_name="aten__add.721/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12898 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.12897), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.721/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.12899 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.12896, f32[1,310,1]{2,1,0} %broadcast.12898), metadata={op_type="aten__add" op_name="aten__add.721/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.12900 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.12899), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.12901 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.12900), metadata={op_type="aten__mul" op_name="aten__mul.722/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.12902 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.12901), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.722/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.12903 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.12876, f32[1,310,4096]{2,1,0} %broadcast.12902), metadata={op_type="aten__mul" op_name="aten__mul.722/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.12904 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12903), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12905 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.12904), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.12909 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.12908, f32[1,310,4096]{2,1,0} %convert.12905), metadata={op_type="aten__mul" op_name="aten__mul.723/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.12910 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.12909), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.12911 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.12910), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p8.35 = bf16[6144,4096]{1,0} parameter(8), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.36 = bf16[4096,6144]{0,1} transpose(bf16[6144,4096]{1,0} %p8.35), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.12912 = bf16[310,6144]{1,0} dot(bf16[310,4096]{1,0} %reshape.12911, bf16[4096,6144]{0,1} %transpose.36), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12913 = bf16[1,310,6144]{2,1,0} reshape(bf16[310,6144]{1,0} %dot.12912), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.12914 = bf16[1,310,8,6,128]{4,3,2,1,0} reshape(bf16[1,310,6144]{2,1,0} %reshape.12913), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %slice.12999 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12914), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %slice.13000 = bf16[1,310,8,4,128]{4,3,2,1,0} slice(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.12999), slice={[0:1], [0:310], [0:8], [0:4], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=368}
  %reshape.13001 = bf16[1,310,32,128]{3,2,1,0} reshape(bf16[1,310,8,4,128]{4,3,2,1,0} %slice.13000), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/einops/_backends.py" source_line=92}
  %transpose.13002 = bf16[1,32,310,128]{3,1,2,0} transpose(bf16[1,310,32,128]{3,2,1,0} %reshape.13001), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=373}
  %convert.13013 = f32[1,32,310,128]{3,1,2,0} convert(bf16[1,32,310,128]{3,1,2,0} %transpose.13002), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p647.12972 = bf16[32768,128]{1,0} parameter(647), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %slice.12973 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p647.12972), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=178}
  %constant.12966 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12967 = s64[1,310]{1,0} broadcast(s64[] %constant.12966), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %compare.12968 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12967), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12961 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12962 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12961), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12963 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12962), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %broadcast.12964 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12963), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %add.12965 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12964), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %select.12969 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12968, s64[1,310]{1,0} %add.12965, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12970 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12969), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %concatenate.12971 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12970), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %gather.12974 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12973, s64[1,310,1]{2,1,0} %concatenate.12971), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %reshape.12975 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12974), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=243}
  %convert.13012 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12975), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.13014 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.13012), metadata={op_type="aten__mul" op_name="aten__mul.724/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.13015 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.13014), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.724/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.13016 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,1,2,0} %convert.13013, f32[1,32,310,128]{3,2,1,0} %broadcast.13015), metadata={op_type="aten__mul" op_name="aten__mul.724/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.13017 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.13016), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %slice.13004 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.13002), slice={[0:1], [0:32], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.13005 = bf16[1,32,310,64]{3,2,1,0} negate(bf16[1,32,310,64]{3,2,1,0} %slice.13004), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.13003 = bf16[1,32,310,64]{3,2,1,0} slice(bf16[1,32,310,128]{3,1,2,0} %transpose.13002), slice={[0:1], [0:32], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.13006 = bf16[1,32,310,128]{3,2,1,0} concatenate(bf16[1,32,310,64]{3,2,1,0} %negate.13005, bf16[1,32,310,64]{3,2,1,0} %slice.13003), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.13007 = f32[1,32,310,128]{3,2,1,0} convert(bf16[1,32,310,128]{3,2,1,0} %concatenate.13006), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %p646.12943 = bf16[32768,128]{1,0} parameter(646), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %slice.12944 = bf16[310,128]{1,0} slice(bf16[32768,128]{1,0} %p646.12943), slice={[0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=179}
  %constant.12937 = s64[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12938 = s64[1,310]{1,0} broadcast(s64[] %constant.12937), dimensions={}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %compare.12939 = pred[1,310]{1,0} compare(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12938), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12932 = s64[1,1]{1,0} reshape(s64[] %p483.5263), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12933 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.12932), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12934 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.12933), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %broadcast.12935 = s64[1,310]{1,0} broadcast(s64[1]{0} %reshape.12934), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %add.12936 = s64[1,310]{1,0} add(s64[1,310]{1,0} %select.5429, s64[1,310]{1,0} %broadcast.12935), metadata={op_type="aten__add" op_name="aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %select.12940 = s64[1,310]{1,0} select(pred[1,310]{1,0} %compare.12939, s64[1,310]{1,0} %add.12936, s64[1,310]{1,0} %select.5429), metadata={op_type="aten__where" op_name="aten__where" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12941 = s64[1,310,1]{2,1,0} reshape(s64[1,310]{1,0} %select.12940), metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %concatenate.12942 = s64[1,310,1]{2,1,0} concatenate(s64[1,310,1]{2,1,0} %reshape.12941), dimensions={2}, metadata={op_type="aten__stack" op_name="aten__stack" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %gather.12945 = bf16[1,310,128]{2,1,0} gather(bf16[310,128]{1,0} %slice.12944, s64[1,310,1]{2,1,0} %concatenate.12942), offset_dims={2}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=2, slice_sizes={1,128}, metadata={op_type="aten__index" op_name="aten__index" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %reshape.12946 = bf16[1,1,310,128]{3,2,1,0} reshape(bf16[1,310,128]{2,1,0} %gather.12945), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=244}
  %convert.12998 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12946), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %reshape.13008 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12998), metadata={op_type="aten__mul" op_name="aten__mul.725/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.13009 = f32[1,32,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.13008), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.725/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.13010 = f32[1,32,310,128]{3,2,1,0} multiply(f32[1,32,310,128]{3,2,1,0} %convert.13007, f32[1,32,310,128]{3,2,1,0} %broadcast.13009), metadata={op_type="aten__mul" op_name="aten__mul.725/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %convert.13011 = bf16[1,32,310,128]{3,2,1,0} convert(f32[1,32,310,128]{3,2,1,0} %multiply.13010), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %constant.12997 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.13018 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[] %constant.12997), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.726/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %multiply.13019 = bf16[1,32,310,128]{3,2,1,0} multiply(bf16[1,32,310,128]{3,2,1,0} %convert.13011, bf16[1,32,310,128]{3,2,1,0} %broadcast.13018), metadata={op_type="aten__add" op_name="aten__add.726/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %add.13020 = bf16[1,32,310,128]{3,2,1,0} add(bf16[1,32,310,128]{3,2,1,0} %convert.13017, bf16[1,32,310,128]{3,2,1,0} %multiply.13019), metadata={op_type="aten__add" op_name="aten__add.726/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=245}
  %broadcast.13021 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %add.13020), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.13022 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.13021), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %slice.12948 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12914), slice={[0:1], [0:310], [0:8], [4:5], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %reshape.12949 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12948), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %slice.12950 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12949), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=370}
  %transpose.12951 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12950), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=374}
  %convert.12977 = f32[1,8,310,128]{3,1,2,0} convert(bf16[1,8,310,128]{3,1,2,0} %transpose.12951), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12976 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12975), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12978 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12976), metadata={op_type="aten__mul" op_name="aten__mul.727/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12979 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12978), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.727/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12980 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,1,2,0} %convert.12977, f32[1,8,310,128]{3,2,1,0} %broadcast.12979), metadata={op_type="aten__mul" op_name="aten__mul.727/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12981 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12980), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12953 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12951), slice={[0:1], [0:8], [0:310], [64:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=236}
  %negate.12954 = bf16[1,8,310,64]{3,2,1,0} negate(bf16[1,8,310,64]{3,2,1,0} %slice.12953), metadata={op_type="aten__neg" op_name="aten__neg" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %slice.12952 = bf16[1,8,310,64]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12951), slice={[0:1], [0:8], [0:310], [0:64]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=235}
  %concatenate.12955 = bf16[1,8,310,128]{3,2,1,0} concatenate(bf16[1,8,310,64]{3,2,1,0} %negate.12954, bf16[1,8,310,64]{3,2,1,0} %slice.12952), dimensions={3}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=237}
  %convert.12956 = f32[1,8,310,128]{3,2,1,0} convert(bf16[1,8,310,128]{3,2,1,0} %concatenate.12955), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12947 = f32[1,1,310,128]{3,2,1,0} convert(bf16[1,1,310,128]{3,2,1,0} %reshape.12946), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %reshape.12957 = f32[1,310,128]{2,1,0} reshape(f32[1,1,310,128]{3,2,1,0} %convert.12947), metadata={op_type="aten__mul" op_name="aten__mul.728/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12958 = f32[1,8,310,128]{3,2,1,0} broadcast(f32[1,310,128]{2,1,0} %reshape.12957), dimensions={0,2,3}, metadata={op_type="aten__mul" op_name="aten__mul.728/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12959 = f32[1,8,310,128]{3,2,1,0} multiply(f32[1,8,310,128]{3,2,1,0} %convert.12956, f32[1,8,310,128]{3,2,1,0} %broadcast.12958), metadata={op_type="aten__mul" op_name="aten__mul.728/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %convert.12960 = bf16[1,8,310,128]{3,2,1,0} convert(f32[1,8,310,128]{3,2,1,0} %multiply.12959), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %constant.12931 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %broadcast.12982 = bf16[1,8,310,128]{3,2,1,0} broadcast(bf16[] %constant.12931), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.729/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %multiply.12983 = bf16[1,8,310,128]{3,2,1,0} multiply(bf16[1,8,310,128]{3,2,1,0} %convert.12960, bf16[1,8,310,128]{3,2,1,0} %broadcast.12982), metadata={op_type="aten__add" op_name="aten__add.729/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %add.12984 = bf16[1,8,310,128]{3,2,1,0} add(bf16[1,8,310,128]{3,2,1,0} %convert.12981, bf16[1,8,310,128]{3,2,1,0} %multiply.12983), metadata={op_type="aten__add" op_name="aten__add.729/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=246}
  %slice.12985 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %add.12984), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12986 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12985), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12987 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12986), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12988 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12987), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12989 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12988), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12990 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12989), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12991 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12990), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12992 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12991), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12993 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12992), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %transpose.12994 = bf16[1,32,128,310]{2,3,1,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.12993), dimensions={0,1,3,2}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.12995 = bf16[1,32,128,310]{3,2,1,0} broadcast(bf16[1,32,128,310]{2,3,1,0} %transpose.12994), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.12996 = bf16[32,128,310]{2,1,0} reshape(bf16[1,32,128,310]{3,2,1,0} %broadcast.12995), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %dot.13023 = bf16[32,310,310]{2,1,0} dot(bf16[32,310,128]{2,1,0} %reshape.13022, bf16[32,128,310]{2,1,0} %reshape.12996), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %reshape.13024 = bf16[1,32,310,310]{3,2,1,0} reshape(bf16[32,310,310]{2,1,0} %dot.13023), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %broadcast.13025 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[] %p490.5406), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %divide.13026 = bf16[1,32,310,310]{3,2,1,0} divide(bf16[1,32,310,310]{3,2,1,0} %reshape.13024, bf16[1,32,310,310]{3,2,1,0} %broadcast.13025), metadata={op_type="aten__div" op_name="aten__div" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=393}
  %constant.12930 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.13027 = bf16[1,1,310,310]{3,2,1,0} broadcast(bf16[] %constant.12930), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.730/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %multiply.13028 = bf16[1,1,310,310]{3,2,1,0} multiply(bf16[1,1,310,310]{3,2,1,0} %add.5405, bf16[1,1,310,310]{3,2,1,0} %broadcast.13027), metadata={op_type="aten__add" op_name="aten__add.730/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %reshape.13029 = bf16[1,310,310]{2,1,0} reshape(bf16[1,1,310,310]{3,2,1,0} %multiply.13028), metadata={op_type="aten__add" op_name="aten__add.730/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %broadcast.13030 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,310,310]{2,1,0} %reshape.13029), dimensions={0,2,3}, metadata={op_type="aten__add" op_name="aten__add.730/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %add.13031 = bf16[1,32,310,310]{3,2,1,0} add(bf16[1,32,310,310]{3,2,1,0} %divide.13026, bf16[1,32,310,310]{3,2,1,0} %broadcast.13030), metadata={op_type="aten__add" op_name="aten__add.730/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=406}
  %convert.13032 = f32[1,32,310,310]{3,2,1,0} convert(bf16[1,32,310,310]{3,2,1,0} %add.13031), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.13033 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.13038 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %convert.13032, f32[] %constant.13033), dimensions={3}, to_apply=%MaxComputation.13034, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.13039 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.13038), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %subtract.13040 = f32[1,32,310,310]{3,2,1,0} subtract(f32[1,32,310,310]{3,2,1,0} %convert.13032, f32[1,32,310,310]{3,2,1,0} %broadcast.13039), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %exponential.13041 = f32[1,32,310,310]{3,2,1,0} exponential(f32[1,32,310,310]{3,2,1,0} %subtract.13040), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %constant.13042 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %reduce.13047 = f32[1,32,310]{2,1,0} reduce(f32[1,32,310,310]{3,2,1,0} %exponential.13041, f32[] %constant.13042), dimensions={3}, to_apply=%AddComputation.13043, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %broadcast.13048 = f32[1,32,310,310]{3,2,1,0} broadcast(f32[1,32,310]{2,1,0} %reduce.13047), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %divide.13049 = f32[1,32,310,310]{3,2,1,0} divide(f32[1,32,310,310]{3,2,1,0} %exponential.13041, f32[1,32,310,310]{3,2,1,0} %broadcast.13048), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2142}
  %convert.13050 = bf16[1,32,310,310]{3,2,1,0} convert(f32[1,32,310,310]{3,2,1,0} %divide.13049), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=409}
  %broadcast.13051 = bf16[1,32,310,310]{3,2,1,0} broadcast(bf16[1,32,310,310]{3,2,1,0} %convert.13050), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.13052 = bf16[32,310,310]{2,1,0} reshape(bf16[1,32,310,310]{3,2,1,0} %broadcast.13051), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %slice.12915 = bf16[1,310,8,1,128]{4,3,2,1,0} slice(bf16[1,310,8,6,128]{4,3,2,1,0} %reshape.12914), slice={[0:1], [0:310], [0:8], [5:6], [0:128]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %reshape.12916 = bf16[1,310,8,128]{3,2,1,0} reshape(bf16[1,310,8,1,128]{4,3,2,1,0} %slice.12915), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %slice.12917 = bf16[1,310,8,128]{3,2,1,0} slice(bf16[1,310,8,128]{3,2,1,0} %reshape.12916), slice={[0:1], [0:310], [0:8], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=371}
  %transpose.12918 = bf16[1,8,310,128]{3,1,2,0} transpose(bf16[1,310,8,128]{3,2,1,0} %slice.12917), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=375}
  %slice.12919 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,1,2,0} %transpose.12918), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12920 = bf16[1,8,310,128]{3,2,1,0} slice(bf16[1,8,310,128]{3,2,1,0} %slice.12919), slice={[0:1], [0:8], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12921 = bf16[1,8,1,310,128]{4,3,2,1,0} reshape(bf16[1,8,310,128]{3,2,1,0} %slice.12920), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12922 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %reshape.12921), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %slice.12923 = bf16[1,8,1,310,128]{4,3,2,1,0} slice(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12922), slice={[0:1], [0:8], [0:1], [0:310], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12924 = bf16[1,8,1,310,128]{4,3,2,1,0} broadcast(bf16[1,8,1,310,128]{4,3,2,1,0} %slice.12923), dimensions={0,1,2,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12925 = bf16[1,8,310,128]{3,2,1,0} reshape(bf16[1,8,1,310,128]{4,3,2,1,0} %broadcast.12924), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %broadcast.12926 = bf16[1,8,4,310,128]{4,3,2,1,0} broadcast(bf16[1,8,310,128]{3,2,1,0} %reshape.12925), dimensions={0,1,3,4}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=276}
  %reshape.12927 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[1,8,4,310,128]{4,3,2,1,0} %broadcast.12926), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=277}
  %broadcast.12928 = bf16[1,32,310,128]{3,2,1,0} broadcast(bf16[1,32,310,128]{3,2,1,0} %reshape.12927), dimensions={0,1,2,3}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.12929 = bf16[32,310,128]{2,1,0} reshape(bf16[1,32,310,128]{3,2,1,0} %broadcast.12928), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %dot.13053 = bf16[32,310,128]{2,1,0} dot(bf16[32,310,310]{2,1,0} %reshape.13052, bf16[32,310,128]{2,1,0} %reshape.12929), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %reshape.13054 = bf16[1,32,310,128]{3,2,1,0} reshape(bf16[32,310,128]{2,1,0} %dot.13053), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=410}
  %transpose.13055 = bf16[1,310,32,128]{3,1,2,0} transpose(bf16[1,32,310,128]{3,2,1,0} %reshape.13054), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=418}
  %reshape.13056 = bf16[1,310,4096]{2,1,0} reshape(bf16[1,310,32,128]{3,1,2,0} %transpose.13055), metadata={op_type="aten__view" op_name="aten__view" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=419}
  %reshape.13057 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %reshape.13056), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p7.33 = bf16[4096,4096]{1,0} parameter(7), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.34 = bf16[4096,4096]{0,1} transpose(bf16[4096,4096]{1,0} %p7.33), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.13058 = bf16[310,4096]{1,0} dot(bf16[310,4096]{1,0} %reshape.13057, bf16[4096,4096]{0,1} %transpose.34), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.13059 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.13058), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.32 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %broadcast.13060 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.32), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.731/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %multiply.13061 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.13059, bf16[1,310,4096]{2,1,0} %broadcast.13060), metadata={op_type="aten__add" op_name="aten__add.731/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %add.13062 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.12875, bf16[1,310,4096]{2,1,0} %multiply.13061), metadata={op_type="aten__add" op_name="aten__add.731/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=665}
  %p648.13093 = bf16[4096]{0} parameter(648), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %convert.13094 = f32[4096]{0} convert(bf16[4096]{0} %p648.13093), sharding={devices=[8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %broadcast.13095 = f32[1,310,4096]{2,1,0} broadcast(f32[4096]{0} %convert.13094), dimensions={2}, metadata={op_type="aten__mul" op_name="aten__mul.734/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.13063 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.13062), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.31 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.13064 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.31), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.13065 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.13063, f32[1,310,4096]{2,1,0} %broadcast.13064), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13066 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.13072 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.13065, f32[] %constant.13066), dimensions={2}, to_apply=%AddComputation.13068, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13067 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13073 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.13078 = pred[] compare(s32[] %constant.13067, s32[] %constant.13073), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13074 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.13076 = f32[] convert(s32[] %constant.13067), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.13077 = f32[] divide(f32[] %constant.13074, f32[] %convert.13076), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13075 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.13079 = f32[] select(pred[] %compare.13078, f32[] %divide.13077, f32[] %constant.13075), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.13080 = f32[1,310]{1,0} broadcast(f32[] %select.13079), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.13081 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.13072, f32[1,310]{1,0} %broadcast.13080), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.13082 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.13081), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.13083 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.13082), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.30 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.13084 = f32[] multiply(f32[] %p4.23, f32[] %constant.30), metadata={op_type="aten__add" op_name="aten__add.732/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.13085 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.13084), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.732/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.13086 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.13083, f32[1,310,1]{2,1,0} %broadcast.13085), metadata={op_type="aten__add" op_name="aten__add.732/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.13087 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.13086), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.13088 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.13087), metadata={op_type="aten__mul" op_name="aten__mul.733/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.13089 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.13088), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.733/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.13090 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.13063, f32[1,310,4096]{2,1,0} %broadcast.13089), metadata={op_type="aten__mul" op_name="aten__mul.733/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.13091 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.13090), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.13092 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.13091), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.13096 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.13095, f32[1,310,4096]{2,1,0} %convert.13092), metadata={op_type="aten__mul" op_name="aten__mul.734/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.13097 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.13096), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.13104 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.13097), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p649.13102 = bf16[14336,4096]{1,0} parameter(649), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.13103 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p649.13102), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.13105 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.13104, bf16[4096,14336]{0,1} %transpose.13103), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.13106 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.13105), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %logistic.13107 = bf16[1,310,14336]{2,1,0} logistic(bf16[1,310,14336]{2,1,0} %reshape.13106), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %multiply.13108 = bf16[1,310,14336]{2,1,0} multiply(bf16[1,310,14336]{2,1,0} %reshape.13106, bf16[1,310,14336]{2,1,0} %logistic.13107), metadata={op_type="aten__silu" op_name="aten__silu" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2380}
  %convert.13109 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %multiply.13108), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.13098 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.13097), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p6.28 = bf16[14336,4096]{1,0} parameter(6), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.29 = bf16[4096,14336]{0,1} transpose(bf16[14336,4096]{1,0} %p6.28), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.13099 = bf16[310,14336]{1,0} dot(bf16[310,4096]{1,0} %reshape.13098, bf16[4096,14336]{0,1} %transpose.29), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.13100 = bf16[1,310,14336]{2,1,0} reshape(bf16[310,14336]{1,0} %dot.13099), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.13101 = f32[1,310,14336]{2,1,0} convert(bf16[1,310,14336]{2,1,0} %reshape.13100), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %multiply.13110 = f32[1,310,14336]{2,1,0} multiply(f32[1,310,14336]{2,1,0} %convert.13109, f32[1,310,14336]{2,1,0} %convert.13101), metadata={op_type="aten__mul" op_name="aten__mul.735/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %convert.13111 = bf16[1,310,14336]{2,1,0} convert(f32[1,310,14336]{2,1,0} %multiply.13110), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=262}
  %reshape.13112 = bf16[310,14336]{1,0} reshape(bf16[1,310,14336]{2,1,0} %convert.13111), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p5.26 = bf16[4096,14336]{1,0} parameter(5), sharding={devices=[1,8]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.27 = bf16[14336,4096]{0,1} transpose(bf16[4096,14336]{1,0} %p5.26), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.13113 = bf16[310,4096]{1,0} dot(bf16[310,14336]{1,0} %reshape.13112, bf16[14336,4096]{0,1} %transpose.27), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.13114 = bf16[1,310,4096]{2,1,0} reshape(bf16[310,4096]{1,0} %dot.13113), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %constant.25 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %broadcast.13115 = bf16[1,310,4096]{2,1,0} broadcast(bf16[] %constant.25), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.736/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %multiply.13116 = bf16[1,310,4096]{2,1,0} multiply(bf16[1,310,4096]{2,1,0} %reshape.13114, bf16[1,310,4096]{2,1,0} %broadcast.13115), metadata={op_type="aten__add" op_name="aten__add.736/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %add.13117 = bf16[1,310,4096]{2,1,0} add(bf16[1,310,4096]{2,1,0} %add.13062, bf16[1,310,4096]{2,1,0} %multiply.13116), metadata={op_type="aten__add" op_name="aten__add.736/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=671}
  %convert.13118 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %add.13117), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=140}
  %constant.24 = f32[] constant(2), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.13119 = f32[1,310,4096]{2,1,0} broadcast(f32[] %constant.24), dimensions={}, metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %power.13120 = f32[1,310,4096]{2,1,0} power(f32[1,310,4096]{2,1,0} %convert.13118, f32[1,310,4096]{2,1,0} %broadcast.13119), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13121 = f32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reduce.13127 = f32[1,310]{1,0} reduce(f32[1,310,4096]{2,1,0} %power.13120, f32[] %constant.13121), dimensions={2}, to_apply=%AddComputation.13123, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13122 = s32[] constant(4096), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13128 = s32[] constant(0), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %compare.13133 = pred[] compare(s32[] %constant.13122, s32[] %constant.13128), direction=NE, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13129 = f32[] constant(1), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.13131 = f32[] convert(s32[] %constant.13122), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %divide.13132 = f32[] divide(f32[] %constant.13129, f32[] %convert.13131), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.13130 = f32[] constant(nan), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %select.13134 = f32[] select(pred[] %compare.13133, f32[] %divide.13132, f32[] %constant.13130), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %broadcast.13135 = f32[1,310]{1,0} broadcast(f32[] %select.13134), dimensions={}, metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %multiply.13136 = f32[1,310]{1,0} multiply(f32[1,310]{1,0} %reduce.13127, f32[1,310]{1,0} %broadcast.13135), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %reshape.13137 = f32[1,310,1]{2,1,0} reshape(f32[1,310]{1,0} %multiply.13136), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %convert.13138 = f32[1,310,1]{2,1,0} convert(f32[1,310,1]{2,1,0} %reshape.13137), metadata={op_type="aten__mean" op_name="aten__mean" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=141}
  %constant.22 = f32[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.13139 = f32[] multiply(f32[] %p4.23, f32[] %constant.22), metadata={op_type="aten__add" op_name="aten__add.737/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.13140 = f32[1,310,1]{2,1,0} broadcast(f32[] %multiply.13139), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.737/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %add.13141 = f32[1,310,1]{2,1,0} add(f32[1,310,1]{2,1,0} %convert.13138, f32[1,310,1]{2,1,0} %broadcast.13140), metadata={op_type="aten__add" op_name="aten__add.737/aten__add" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %rsqrt.13142 = f32[1,310,1]{2,1,0} rsqrt(f32[1,310,1]{2,1,0} %add.13141), metadata={op_type="aten__rsqrt" op_name="aten__rsqrt" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %reshape.13143 = f32[1,310]{1,0} reshape(f32[1,310,1]{2,1,0} %rsqrt.13142), metadata={op_type="aten__mul" op_name="aten__mul.738/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %broadcast.13144 = f32[1,310,4096]{2,1,0} broadcast(f32[1,310]{1,0} %reshape.13143), dimensions={0,1}, metadata={op_type="aten__mul" op_name="aten__mul.738/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %multiply.13145 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %convert.13118, f32[1,310,4096]{2,1,0} %broadcast.13144), metadata={op_type="aten__mul" op_name="aten__mul.738/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=142}
  %convert.13146 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.13145), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.13147 = f32[1,310,4096]{2,1,0} convert(bf16[1,310,4096]{2,1,0} %convert.13146), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %multiply.13151 = f32[1,310,4096]{2,1,0} multiply(f32[1,310,4096]{2,1,0} %broadcast.13150, f32[1,310,4096]{2,1,0} %convert.13147), metadata={op_type="aten__mul" op_name="aten__mul.739/aten__mul" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %convert.13152 = bf16[1,310,4096]{2,1,0} convert(f32[1,310,4096]{2,1,0} %multiply.13151), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=143}
  %reshape.13153 = bf16[310,4096]{1,0} reshape(bf16[1,310,4096]{2,1,0} %convert.13152), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %p3.20 = bf16[92553,4096]{1,0} parameter(3), sharding={devices=[8,1]0,1,2,3,4,5,6,7}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch_xla/distributed/spmd/xla_sharding.py" source_line=624}
  %transpose.21 = bf16[4096,92553]{0,1} transpose(bf16[92553,4096]{1,0} %p3.20), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %dot.13154 = bf16[310,92553]{1,0} dot(bf16[310,4096]{1,0} %reshape.13153, bf16[4096,92553]{0,1} %transpose.21), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %reshape.13155 = bf16[1,310,92553]{2,1,0} reshape(bf16[310,92553]{1,0} %dot.13154), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py" source_line=125}
  %convert.13156 = f32[1,310,92553]{2,1,0} convert(bf16[1,310,92553]{2,1,0} %reshape.13155), metadata={op_type="xla__cast" op_name="xla__cast" source_file="/dev/shm/modules/transformers_modules/radna/XLA-InternVL2-8B/746cd35e611234c48f8dc5c61dbe30b5a782a208/modeling_internlm2.py" source_line=1082}
  %slice.13157 = f32[1,310,92553]{2,1,0} slice(f32[1,310,92553]{2,1,0} %convert.13156), slice={[0:1], [0:310], [0:92553]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2969}
  %slice.13158 = f32[1,1,92553]{2,1,0} slice(f32[1,310,92553]{2,1,0} %slice.13157), slice={[0:1], [309:310], [0:92553]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2969}
  %reshape.13159 = f32[1,92553]{1,0} reshape(f32[1,1,92553]{2,1,0} %slice.13158), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2969}
  %slice.13160 = f32[1,92553]{1,0} slice(f32[1,92553]{1,0} %reshape.13159), slice={[0:1], [0:92553]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2969}
  %iota.13161 = s32[1,92553]{1,0} iota(), iota_dimension=1, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %sort.13168 = (f32[1,92553]{1,0}, s32[1,92553]{1,0}) sort(f32[1,92553]{1,0} %slice.13160, s32[1,92553]{1,0} %iota.13161), dimensions={1}, to_apply=%compare-greater-than.13162, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %get-tuple-element.13171 = s32[1,92553]{1,0} get-tuple-element((f32[1,92553]{1,0}, s32[1,92553]{1,0}) %sort.13168), index=1, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %slice.13172 = s32[1,50]{1,0} slice(s32[1,92553]{1,0} %get-tuple-element.13171), slice={[0:1], [0:50]}, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %convert.13173 = s64[1,50]{1,0} convert(s32[1,50]{1,0} %slice.13172), metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %constant.17 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.15 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %p1.14 = s64[] parameter(1), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %multiply.16 = s64[] multiply(s64[] %constant.15, s64[] %p1.14), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %add.18 = s64[] add(s64[] %constant.17, s64[] %multiply.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %convert.13221 = u64[] convert(s64[] %add.18), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13223 = u64[1]{0} reshape(u64[] %convert.13221), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13222 = u64[] constant(0), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13224 = u64[1]{0} reshape(u64[] %constant.13222), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %concatenate.13225 = u64[2]{0} concatenate(u64[1]{0} %reshape.13223, u64[1]{0} %reshape.13224), dimensions={0}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %rng-bit-generator.13226 = (u64[2]{0}, u32[1,1]{1,0}) rng-bit-generator(u64[2]{0} %concatenate.13225), algorithm=rng_default, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %get-tuple-element.13228 = u64[2]{0} get-tuple-element((u64[2]{0}, u32[1,1]{1,0}) %rng-bit-generator.13226), index=0, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13244 = s32[] constant(92553), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13257 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=455}
  %reshape.13258 = s64[1,1]{1,0} reshape(s64[] %constant.13257), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=455}
  %broadcast.13259 = s64[1,1]{1,0} broadcast(s64[1,1]{1,0} %reshape.13258), dimensions={0,1}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=455}
  %reshape.13260 = s64[1]{0} reshape(s64[1,1]{1,0} %broadcast.13259), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=455}
  %broadcast.13261 = s64[1,0]{1,0} broadcast(s64[1]{0} %reshape.13260), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=455}
  %get-tuple-element.13227 = u32[1,1]{1,0} get-tuple-element((u64[2]{0}, u32[1,1]{1,0}) %rng-bit-generator.13226), index=1, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13229 = u32[] constant(9), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13230 = u32[1,1]{1,0} broadcast(u32[] %constant.13229), dimensions={}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %shift-right-logical.13231 = u32[1,1]{1,0} shift-right-logical(u32[1,1]{1,0} %get-tuple-element.13227, u32[1,1]{1,0} %broadcast.13230), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %convert.13232 = f32[1,1]{1,0} convert(u32[1,1]{1,0} %shift-right-logical.13231), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13233 = f32[] constant(1.1920929e-07), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13234 = f32[1,1]{1,0} broadcast(f32[] %constant.13233), dimensions={}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %multiply.13235 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %convert.13232, f32[1,1]{1,0} %broadcast.13234), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13206 = f32[] constant(1), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13219 = f32[1,1]{1,0} reshape(f32[] %constant.13206), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13220 = f32[1,1]{1,0} broadcast(f32[1,1]{1,0} %reshape.13219), dimensions={0,1}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13205 = f32[] constant(0), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13217 = f32[1,1]{1,0} reshape(f32[] %constant.13205), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13218 = f32[1,1]{1,0} broadcast(f32[1,1]{1,0} %reshape.13217), dimensions={0,1}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %subtract.13236 = f32[1,1]{1,0} subtract(f32[1,1]{1,0} %broadcast.13220, f32[1,1]{1,0} %broadcast.13218), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %multiply.13237 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %multiply.13235, f32[1,1]{1,0} %subtract.13236), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %add.13238 = f32[1,1]{1,0} add(f32[1,1]{1,0} %multiply.13237, f32[1,1]{1,0} %broadcast.13218), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13240 = f32[1,92553,1]{2,1,0} broadcast(f32[1,1]{1,0} %add.13238), dimensions={0,2}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %get-tuple-element.13169 = f32[1,92553]{1,0} get-tuple-element((f32[1,92553]{1,0}, s32[1,92553]{1,0}) %sort.13168), index=0, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %slice.13170 = f32[1,50]{1,0} slice(f32[1,92553]{1,0} %get-tuple-element.13169), slice={[0:1], [0:50]}, metadata={op_type="aten__topk" op_name="aten__topk" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %slice.13174 = f32[1,1]{1,0} slice(f32[1,50]{1,0} %slice.13170), slice={[0:1], [49:50]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %reshape.13175 = f32[1]{0} reshape(f32[1,1]{1,0} %slice.13174), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %reshape.13176 = f32[1,1]{1,0} reshape(f32[1]{0} %reshape.13175), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %reshape.13177 = f32[1]{0} reshape(f32[1,1]{1,0} %reshape.13176), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %broadcast.13178 = f32[1,92553]{1,0} broadcast(f32[1]{0} %reshape.13177), dimensions={0}, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %compare.13179 = pred[1,92553]{1,0} compare(f32[1,92553]{1,0} %slice.13160, f32[1,92553]{1,0} %broadcast.13178), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=532}
  %broadcast.13181 = pred[1,92553]{1,0} broadcast(pred[1,92553]{1,0} %compare.13179), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %constant.13182 = pred[] constant(false), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %broadcast.13183 = pred[1,92553]{1,0} broadcast(pred[] %constant.13182), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %compare.13184 = pred[1,92553]{1,0} compare(pred[1,92553]{1,0} %broadcast.13181, pred[1,92553]{1,0} %broadcast.13183), direction=NE, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %p2.19 = f64[] parameter(2), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %convert.13185 = f32[] convert(f64[] %p2.19), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %broadcast.13186 = f32[1,92553]{1,0} broadcast(f32[] %convert.13185), dimensions={}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %broadcast.13180 = f32[1,92553]{1,0} broadcast(f32[1,92553]{1,0} %slice.13160), dimensions={0,1}, metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %select.13187 = f32[1,92553]{1,0} select(pred[1,92553]{1,0} %compare.13184, f32[1,92553]{1,0} %broadcast.13186, f32[1,92553]{1,0} %broadcast.13180), metadata={op_type="aten__masked_fill" op_name="aten__masked_fill" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/logits_process.py" source_line=533}
  %constant.13188 = f32[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %reduce.13193 = f32[1]{0} reduce(f32[1,92553]{1,0} %select.13187, f32[] %constant.13188), dimensions={1}, to_apply=%MaxComputation.13189, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %broadcast.13194 = f32[1,92553]{1,0} broadcast(f32[1]{0} %reduce.13193), dimensions={0}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %subtract.13195 = f32[1,92553]{1,0} subtract(f32[1,92553]{1,0} %select.13187, f32[1,92553]{1,0} %broadcast.13194), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %exponential.13196 = f32[1,92553]{1,0} exponential(f32[1,92553]{1,0} %subtract.13195), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %constant.13197 = f32[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %reduce.13202 = f32[1]{0} reduce(f32[1,92553]{1,0} %exponential.13196, f32[] %constant.13197), dimensions={1}, to_apply=%AddComputation.13198, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %broadcast.13203 = f32[1,92553]{1,0} broadcast(f32[1]{0} %reduce.13202), dimensions={0}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %divide.13204 = f32[1,92553]{1,0} divide(f32[1,92553]{1,0} %exponential.13196, f32[1,92553]{1,0} %broadcast.13203), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/nn/functional.py" source_line=2140}
  %reduce-window.13211 = f32[1,92553]{1,0} reduce-window(f32[1,92553]{1,0} %divide.13204, f32[] %constant.13205), window={size=1x92553 pad=0_0x92552_0}, to_apply=%AddComputation.13207, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %slice.13212 = f32[1,1]{1,0} slice(f32[1,92553]{1,0} %reduce-window.13211), slice={[0:1], [92552:92553]}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13213 = f32[1,1]{1,0} broadcast(f32[1,1]{1,0} %slice.13212), dimensions={0,1}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13214 = f32[1]{0} reshape(f32[1,1]{1,0} %broadcast.13213), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13215 = f32[1,92553]{1,0} broadcast(f32[1]{0} %reshape.13214), dimensions={0}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %divide.13216 = f32[1,92553]{1,0} divide(f32[1,92553]{1,0} %reduce-window.13211, f32[1,92553]{1,0} %broadcast.13215), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %broadcast.13239 = f32[1,92553,1]{2,1,0} broadcast(f32[1,92553]{1,0} %divide.13216), dimensions={0,1}, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %compare.13241 = pred[1,92553,1]{2,1,0} compare(f32[1,92553,1]{2,1,0} %broadcast.13240, f32[1,92553,1]{2,1,0} %broadcast.13239), direction=GT, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %convert.13242 = s64[1,92553,1]{2,1,0} convert(pred[1,92553,1]{2,1,0} %compare.13241), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.13243 = s64[] constant(0), metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reduce.13249 = s64[1,1]{1,0} reduce(s64[1,92553,1]{2,1,0} %convert.13242, s64[] %constant.13243), dimensions={1}, to_apply=%AddComputation.13245, metadata={op_type="aten__multinomial" op_name="aten__multinomial" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %reshape.13250 = s64[1]{0} reshape(s64[1,1]{1,0} %reduce.13249), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2998}
  %constant.4 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2947}
  %reshape.5 = s64[1]{0} reshape(s64[] %constant.4), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2947}
  %broadcast.6 = s64[1]{0} broadcast(s64[1]{0} %reshape.5), dimensions={0}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=2947}
  %multiply.13251 = s64[1]{0} multiply(s64[1]{0} %reshape.13250, s64[1]{0} %broadcast.6), metadata={op_type="aten__mul" op_name="aten__mul.740/aten__mul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %p0.11 = s64[] parameter(0), sharding={replicated}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %broadcast.12 = s64[1]{0} broadcast(s64[] %p0.11), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul.742/aten__mul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %constant.3 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %broadcast.9 = s64[1]{0} broadcast(s64[] %constant.3), dimensions={}, metadata={op_type="aten__rsub" op_name="aten__rsub.741/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %constant.2 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %broadcast.7 = s64[1]{0} broadcast(s64[] %constant.2), dimensions={}, metadata={op_type="aten__rsub" op_name="aten__rsub.741/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %multiply.8 = s64[1]{0} multiply(s64[1]{0} %broadcast.6, s64[1]{0} %broadcast.7), metadata={op_type="aten__rsub" op_name="aten__rsub.741/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %subtract.10 = s64[1]{0} subtract(s64[1]{0} %broadcast.9, s64[1]{0} %multiply.8), metadata={op_type="aten__rsub" op_name="aten__rsub.741/aten__rsub" source_file="/home/kojoe/.local/lib/python3.10/site-packages/torch/_tensor.py" source_line=1019}
  %multiply.13 = s64[1]{0} multiply(s64[1]{0} %broadcast.12, s64[1]{0} %subtract.10), metadata={op_type="aten__mul" op_name="aten__mul.742/aten__mul" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %constant.1 = s64[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %broadcast.13252 = s64[1]{0} broadcast(s64[] %constant.1), dimensions={}, metadata={op_type="aten__add" op_name="aten__add.743/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %multiply.13253 = s64[1]{0} multiply(s64[1]{0} %multiply.13, s64[1]{0} %broadcast.13252), metadata={op_type="aten__add" op_name="aten__add.743/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %add.13254 = s64[1]{0} add(s64[1]{0} %multiply.13251, s64[1]{0} %multiply.13253), metadata={op_type="aten__add" op_name="aten__add.743/aten__add" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3004}
  %slice.13255 = s64[1]{0} slice(s64[1]{0} %add.13254), slice={[0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3007}
  %reshape.13256 = s64[1,1]{1,0} reshape(s64[1]{0} %slice.13255), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3007}
  %concatenate.13262 = s64[1,1]{1,0} concatenate(s64[1,0]{1,0} %broadcast.13261, s64[1,1]{1,0} %reshape.13256), dimensions={1}, metadata={op_type="aten__cat" op_name="aten__cat" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/utils.py" source_line=3007}
  %slice.13263 = s64[1,1]{1,0} slice(s64[1,1]{1,0} %concatenate.13262), slice={[0:1], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py" source_line=466}
  %slice.13264 = s64[1,1]{1,0} slice(s64[1,1]{1,0} %slice.13263), slice={[0:1], [0:1]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py" source_line=466}
  %reshape.13265 = s64[1]{0} reshape(s64[1,1]{1,0} %slice.13264), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/kojoe/.local/lib/python3.10/site-packages/transformers/generation/stopping_criteria.py" source_line=466}
  ROOT %tuple.13266 = (s64[1]{0}) tuple(s64[1]{0} %reshape.13265)
}


Graph Hash: 7482f58e5da6fbf0236ad9bd066af997

## END_GRAPH

